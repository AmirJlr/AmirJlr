{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1925553ec09943d2ac76957371b93672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5325972027842c08d24f6a74cf36fac",
              "IPY_MODEL_5f7aa2e0089142afa5fe0a2bd46e854e",
              "IPY_MODEL_f92536f53250491180f1d4c5a3c12636"
            ],
            "layout": "IPY_MODEL_7f3cc60a750a4ae891f21fda04e3ce49"
          }
        },
        "f5325972027842c08d24f6a74cf36fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454feacc6335407fa165a6776dc85fab",
            "placeholder": "​",
            "style": "IPY_MODEL_911708a28ebd4a5e99069d094eef7154",
            "value": "modules.json: 100%"
          }
        },
        "5f7aa2e0089142afa5fe0a2bd46e854e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68980d2429734933aa93db984690311e",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac775420e6224629846bc64eacd28e43",
            "value": 349
          }
        },
        "f92536f53250491180f1d4c5a3c12636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ea59f502724dbc8dd584b8cbc2b52d",
            "placeholder": "​",
            "style": "IPY_MODEL_027d848aa4d44aa6b2adc9dee73dead9",
            "value": " 349/349 [00:00&lt;00:00, 36.1kB/s]"
          }
        },
        "7f3cc60a750a4ae891f21fda04e3ce49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454feacc6335407fa165a6776dc85fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911708a28ebd4a5e99069d094eef7154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68980d2429734933aa93db984690311e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac775420e6224629846bc64eacd28e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85ea59f502724dbc8dd584b8cbc2b52d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027d848aa4d44aa6b2adc9dee73dead9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66008c7741de438db49a25d31bf88224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14e37c5bf67b44389bb33b950c9872da",
              "IPY_MODEL_a6736bb7dcdc4916bcbe6bea0cb4cf78",
              "IPY_MODEL_ba4f034d630b4707b23ceee43ae51d3c"
            ],
            "layout": "IPY_MODEL_9ee75708de174447b2dddbfcf54c06b3"
          }
        },
        "14e37c5bf67b44389bb33b950c9872da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d3f60e48eb34db48351479ec318511f",
            "placeholder": "​",
            "style": "IPY_MODEL_c7e6eba155da4e1e8869bc2fa701699e",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a6736bb7dcdc4916bcbe6bea0cb4cf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5935d5824d424f34b35e08da4c85b38d",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87c60f690fe64c3eb3d017b12e477d22",
            "value": 116
          }
        },
        "ba4f034d630b4707b23ceee43ae51d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3482737466c04ed3a849aafe799afd21",
            "placeholder": "​",
            "style": "IPY_MODEL_5570b21e0e2a4f52a7192f74700e87f1",
            "value": " 116/116 [00:00&lt;00:00, 8.95kB/s]"
          }
        },
        "9ee75708de174447b2dddbfcf54c06b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d3f60e48eb34db48351479ec318511f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e6eba155da4e1e8869bc2fa701699e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5935d5824d424f34b35e08da4c85b38d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c60f690fe64c3eb3d017b12e477d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3482737466c04ed3a849aafe799afd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5570b21e0e2a4f52a7192f74700e87f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb7a5507878a49358e7c6ff8c5b24ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f51f940291f4e32bae72b385dc257a4",
              "IPY_MODEL_5996df04d075465186ded6bf36f651f5",
              "IPY_MODEL_b03541d6056d4551a662ad4c85b1237d"
            ],
            "layout": "IPY_MODEL_5d626df0e4a242db97a6674186488ccc"
          }
        },
        "7f51f940291f4e32bae72b385dc257a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b5749866614c0e98fed0258cf83eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_8130f06599f4412eb4a42ed3ce751fba",
            "value": "README.md: 100%"
          }
        },
        "5996df04d075465186ded6bf36f651f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd60c7987f94ab78e2aaf3694413cd3",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a124a56769b44988ae3a64625f11b17c",
            "value": 10454
          }
        },
        "b03541d6056d4551a662ad4c85b1237d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783e020a8a234320bcffec9c7d805296",
            "placeholder": "​",
            "style": "IPY_MODEL_56ddde3b28ff4efdac10e9109e5268de",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 985kB/s]"
          }
        },
        "5d626df0e4a242db97a6674186488ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b5749866614c0e98fed0258cf83eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8130f06599f4412eb4a42ed3ce751fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbd60c7987f94ab78e2aaf3694413cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a124a56769b44988ae3a64625f11b17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "783e020a8a234320bcffec9c7d805296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ddde3b28ff4efdac10e9109e5268de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f16015a3f03745d7b3e9a2c12b6ba811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c48e6905873c44d791d734ac34cc5eb1",
              "IPY_MODEL_67d0a489f53049c29b29f6904a7edc26",
              "IPY_MODEL_32ca4d279842437aa7a23b315e762441"
            ],
            "layout": "IPY_MODEL_f40d155498314df0a8d9973ebdc0e2e9"
          }
        },
        "c48e6905873c44d791d734ac34cc5eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f54a45a21b4e9c8d441a133d4940a5",
            "placeholder": "​",
            "style": "IPY_MODEL_a7efcea284ff4495848a5ba72fe00f51",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "67d0a489f53049c29b29f6904a7edc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29cde28dcc24762ad13d7af4449b5cb",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffcc3341b065441d869ff9efa7b2cf62",
            "value": 53
          }
        },
        "32ca4d279842437aa7a23b315e762441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b1541678a84ceaadfab7e8141d44e8",
            "placeholder": "​",
            "style": "IPY_MODEL_d148bbf433c342aaaf940a65d0bd3b30",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.16kB/s]"
          }
        },
        "f40d155498314df0a8d9973ebdc0e2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f54a45a21b4e9c8d441a133d4940a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7efcea284ff4495848a5ba72fe00f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b29cde28dcc24762ad13d7af4449b5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcc3341b065441d869ff9efa7b2cf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1b1541678a84ceaadfab7e8141d44e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d148bbf433c342aaaf940a65d0bd3b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334fe36b6d194ce89113947a455884fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c28aba6ba2f4bec905029d572a82242",
              "IPY_MODEL_c8b7aae3a83c4e9bbadf93fe5a3ab6d6",
              "IPY_MODEL_1562e3f3db444a5287ae7916f2ee50f2"
            ],
            "layout": "IPY_MODEL_86162672b29247d5be63271fe4694e10"
          }
        },
        "0c28aba6ba2f4bec905029d572a82242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e9054a3b61417190439d35f41d5188",
            "placeholder": "​",
            "style": "IPY_MODEL_2e606d476c034ae8847f759754df4e1e",
            "value": "config.json: 100%"
          }
        },
        "c8b7aae3a83c4e9bbadf93fe5a3ab6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8afcce2c4474edda1beb927a4b1ca69",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e56592b120544958a2d5f2c433cc9ee7",
            "value": 612
          }
        },
        "1562e3f3db444a5287ae7916f2ee50f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3bf7b8679e4294b47d78c45f35f08e",
            "placeholder": "​",
            "style": "IPY_MODEL_730ce02218174ee8ad37e49f24e6310e",
            "value": " 612/612 [00:00&lt;00:00, 58.8kB/s]"
          }
        },
        "86162672b29247d5be63271fe4694e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e9054a3b61417190439d35f41d5188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e606d476c034ae8847f759754df4e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8afcce2c4474edda1beb927a4b1ca69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56592b120544958a2d5f2c433cc9ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3bf7b8679e4294b47d78c45f35f08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730ce02218174ee8ad37e49f24e6310e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aea888f7a9d4996af9c5b93500977a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcc7b2cba90a4c5e85a4b6a934d28283",
              "IPY_MODEL_cbc0ab7fb191448eb585b9bdb5caba09",
              "IPY_MODEL_fd1e52ac33524845865a141a75340ac7"
            ],
            "layout": "IPY_MODEL_a661af118f3845c6b6faec6881f1c568"
          }
        },
        "fcc7b2cba90a4c5e85a4b6a934d28283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649c09db7fd248148473508216c9c550",
            "placeholder": "​",
            "style": "IPY_MODEL_b8494651ff00425ab65c7b02f9546f0f",
            "value": "model.safetensors: 100%"
          }
        },
        "cbc0ab7fb191448eb585b9bdb5caba09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df210aefed704d39940ce58f5d67fcf3",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e46a0d3e4b34aa09aa8098a3b2540f9",
            "value": 90868376
          }
        },
        "fd1e52ac33524845865a141a75340ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc80cd8d93845fc98f779864288c34d",
            "placeholder": "​",
            "style": "IPY_MODEL_0280b33683a74eaabea8ec7226458e60",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 72.2MB/s]"
          }
        },
        "a661af118f3845c6b6faec6881f1c568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649c09db7fd248148473508216c9c550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8494651ff00425ab65c7b02f9546f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df210aefed704d39940ce58f5d67fcf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e46a0d3e4b34aa09aa8098a3b2540f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cc80cd8d93845fc98f779864288c34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0280b33683a74eaabea8ec7226458e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86760231ca049c6b40d427664426495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af3dec08a62448a4bbbaa46edd73b319",
              "IPY_MODEL_551999a2822741279e1db32f3c1af476",
              "IPY_MODEL_5679106956d241069639465056828e44"
            ],
            "layout": "IPY_MODEL_1b829c0ea7234d2d9f2400dd6cdfefc4"
          }
        },
        "af3dec08a62448a4bbbaa46edd73b319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd6c38bd00044e7b3dfdceaf5b3316d",
            "placeholder": "​",
            "style": "IPY_MODEL_9d2516b0e3764eb5b70fee9b5d728e05",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "551999a2822741279e1db32f3c1af476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2639fb9e814d01b1fea82ce79e88ab",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0612a8b3b2ff4dacb35f27096210abdf",
            "value": 350
          }
        },
        "5679106956d241069639465056828e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303d662bb380431db483dde4fee03f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_c318529a9aca498595802dcf71e34077",
            "value": " 350/350 [00:00&lt;00:00, 19.4kB/s]"
          }
        },
        "1b829c0ea7234d2d9f2400dd6cdfefc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd6c38bd00044e7b3dfdceaf5b3316d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2516b0e3764eb5b70fee9b5d728e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff2639fb9e814d01b1fea82ce79e88ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0612a8b3b2ff4dacb35f27096210abdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "303d662bb380431db483dde4fee03f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c318529a9aca498595802dcf71e34077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e77201de99c481bb83b6bc573df44f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_467d44984a4f4e5ea267bd0a0e89b165",
              "IPY_MODEL_9095e132bfaf4d0c8d5622b7575d1559",
              "IPY_MODEL_f38dad0a7c49486b8684dbc9e65e37e8"
            ],
            "layout": "IPY_MODEL_69688a3de27b4c789b02ba5374c4dfa4"
          }
        },
        "467d44984a4f4e5ea267bd0a0e89b165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f541e685804e2a9dbf3f4b95ba70e7",
            "placeholder": "​",
            "style": "IPY_MODEL_7b62fbfc4d814702bc5a6562c9a2fe6a",
            "value": "vocab.txt: 100%"
          }
        },
        "9095e132bfaf4d0c8d5622b7575d1559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21fb05e916ed4d39bd7868f082edc8a0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e70013e56ce34b4ab2e3a49873b5c8b0",
            "value": 231508
          }
        },
        "f38dad0a7c49486b8684dbc9e65e37e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5fb3d643caa40d2b4cba4d263e43ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_afc490253cdf4cb4b452f22c1b755e10",
            "value": " 232k/232k [00:00&lt;00:00, 519kB/s]"
          }
        },
        "69688a3de27b4c789b02ba5374c4dfa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f541e685804e2a9dbf3f4b95ba70e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b62fbfc4d814702bc5a6562c9a2fe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21fb05e916ed4d39bd7868f082edc8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70013e56ce34b4ab2e3a49873b5c8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5fb3d643caa40d2b4cba4d263e43ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc490253cdf4cb4b452f22c1b755e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbc208f77b20412382ecc7c1acd60778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e98d6aa431f4f4ba122a164a515e35f",
              "IPY_MODEL_526df554e6e346eabfb09d99ed8ba254",
              "IPY_MODEL_9f2903ef396b44ca9516a64d09e68fb6"
            ],
            "layout": "IPY_MODEL_644b97cef15b4a049a85bf52bae23f7d"
          }
        },
        "6e98d6aa431f4f4ba122a164a515e35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3921cbb84243cc91bf05f62127b535",
            "placeholder": "​",
            "style": "IPY_MODEL_f16cd7badb31405fa96365b701621a40",
            "value": "tokenizer.json: 100%"
          }
        },
        "526df554e6e346eabfb09d99ed8ba254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5dd754ef7d4c28965f34ae95f853f4",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65a5e71a321944609a650ede3c802f9c",
            "value": 466247
          }
        },
        "9f2903ef396b44ca9516a64d09e68fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6754b1a8ec8a48b28269454cb34ed986",
            "placeholder": "​",
            "style": "IPY_MODEL_6eedd218c30144f18340277ecb083860",
            "value": " 466k/466k [00:00&lt;00:00, 34.2MB/s]"
          }
        },
        "644b97cef15b4a049a85bf52bae23f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3921cbb84243cc91bf05f62127b535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16cd7badb31405fa96365b701621a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5dd754ef7d4c28965f34ae95f853f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a5e71a321944609a650ede3c802f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6754b1a8ec8a48b28269454cb34ed986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eedd218c30144f18340277ecb083860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7340335035774d149db430c551ca10ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbdb66aed19f4bb7819acd88a58c74a3",
              "IPY_MODEL_9d9cb351114c4f2992cd6faa475a8c2c",
              "IPY_MODEL_71436919495b416fbd96ba74c4f81eb1"
            ],
            "layout": "IPY_MODEL_fd1df45e9aa6423fb637bf9d09237f76"
          }
        },
        "cbdb66aed19f4bb7819acd88a58c74a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc8aa34e6c3403bae78e0e293fa167f",
            "placeholder": "​",
            "style": "IPY_MODEL_14c765b111a54392970cac1d11b4786c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9d9cb351114c4f2992cd6faa475a8c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb7f29e437644118f5ad66797c705ee",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeb17456d75243b2912a2526af345134",
            "value": 112
          }
        },
        "71436919495b416fbd96ba74c4f81eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f700e6080a3f452b8ca15dd3af76ae71",
            "placeholder": "​",
            "style": "IPY_MODEL_83801ba4b3cb4702b93d6949b000a632",
            "value": " 112/112 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "fd1df45e9aa6423fb637bf9d09237f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc8aa34e6c3403bae78e0e293fa167f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c765b111a54392970cac1d11b4786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb7f29e437644118f5ad66797c705ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb17456d75243b2912a2526af345134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f700e6080a3f452b8ca15dd3af76ae71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83801ba4b3cb4702b93d6949b000a632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3c4669582c4f6888069b904cad2db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5283f2ee11a0419dbf5444327f3bf04f",
              "IPY_MODEL_7ee9ad281384493caf0b2baa30c4a64f",
              "IPY_MODEL_314c4d61e89e4ecb8e10b6c21e6ad385"
            ],
            "layout": "IPY_MODEL_9da014db65be4b139079d60d7bf3f149"
          }
        },
        "5283f2ee11a0419dbf5444327f3bf04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61783f82d0f4d02b871b424465af98d",
            "placeholder": "​",
            "style": "IPY_MODEL_814706abd10245f9b97415707c6d429d",
            "value": "config.json: 100%"
          }
        },
        "7ee9ad281384493caf0b2baa30c4a64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e906244cc34f6a970bee9ca64641d7",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592892ef111f4476b313b645b93aa0fb",
            "value": 190
          }
        },
        "314c4d61e89e4ecb8e10b6c21e6ad385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79ca214bb09441938664c81a5cdfdbae",
            "placeholder": "​",
            "style": "IPY_MODEL_86a94e636c09467bb45284832dc50520",
            "value": " 190/190 [00:00&lt;00:00, 20.5kB/s]"
          }
        },
        "9da014db65be4b139079d60d7bf3f149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d61783f82d0f4d02b871b424465af98d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814706abd10245f9b97415707c6d429d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05e906244cc34f6a970bee9ca64641d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592892ef111f4476b313b645b93aa0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79ca214bb09441938664c81a5cdfdbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a94e636c09467bb45284832dc50520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb1ba58c4e984dcaba1010ce9896ba96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_521e59af90574c75917297648c8be6eb",
              "IPY_MODEL_0c29a77df4ab4035900a5fd5eeb257de",
              "IPY_MODEL_7f94e09c80f747d8b1c700a87a2e7ec1"
            ],
            "layout": "IPY_MODEL_b5ed0b58d48744d1ada86cafeca0d805"
          }
        },
        "521e59af90574c75917297648c8be6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8679bb2df0bc405c8899bce90b954392",
            "placeholder": "​",
            "style": "IPY_MODEL_5eebb2acfc58417296061065296adfe5",
            "value": "Batches: 100%"
          }
        },
        "0c29a77df4ab4035900a5fd5eeb257de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ecc530c90ab4ab99ea3a7b9c62aa70f",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb99de21f7c4337b850bcf4681e2cf5",
            "value": 14
          }
        },
        "7f94e09c80f747d8b1c700a87a2e7ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec79ef4d1ea44bd8cd03bc4bf442950",
            "placeholder": "​",
            "style": "IPY_MODEL_672792cd2426456aa9969ab5075ffcd9",
            "value": " 14/14 [00:01&lt;00:00, 16.11it/s]"
          }
        },
        "b5ed0b58d48744d1ada86cafeca0d805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8679bb2df0bc405c8899bce90b954392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eebb2acfc58417296061065296adfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ecc530c90ab4ab99ea3a7b9c62aa70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb99de21f7c4337b850bcf4681e2cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec79ef4d1ea44bd8cd03bc4bf442950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672792cd2426456aa9969ab5075ffcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirJlr/AmirJlr/blob/main/04_recommender_system_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# A very high level overview\n",
        "\n",
        "In this project, we build a knowledge graph-based recommendation system for educational videos where the nodes represent individual videos and edges capture their relationships. We start by processing video metadata **(titles, descriptions, durations)** using NLP techniques - specifically:\n",
        "\n",
        "-  We use spaCy for extracting key concepts and SentenceTransformer for generating semantic embeddings. These embeddings help us understand video relationships as we can calculate similarity scores between them.\n",
        "\n",
        "When building the graph with NetworkX,\n",
        "\n",
        "- We create edges based on both semantic similarity and logical prerequisites, while nodes store various attributes like difficulty level, topics covered, and duration.\n",
        "\n",
        "<p>\n",
        "\n",
        "After building the graph,\n",
        "\n",
        "- We perform various analyses and visualizations using NetworkX and PyVis - including generating learning paths, visualizing topic relationships, and analyzing video prerequisites.\n",
        "\n",
        "Then, for demo purposes,\n",
        "- We serialize and save this graph structure into a SQLite database, storing nodes, edges, and embeddings in separate tables.\n",
        "\n",
        "This is just for learning purposes only so you can learn how to serialize the graph, load it back and build a graph again. After loading the database, to perform further analysis, we don't actually query the SQL database directly - instead, we load the data back into a NetworkX graph structure using load_recommendation_system().\n",
        "\n",
        "We do have some basic SQL query functions (query_videos_by_topic, get_video_prerequisites), again for learning purposes. The main analytical work like finding learning paths and analyzing relationships still happens using NetworkX methods after reconstructing the graph from the database. This approach suggests we might want to reconsider either making better use of SQL capabilities or exploring graph databases that could maintain the graph structure natively.\n"
      ],
      "metadata": {
        "id": "mWxgYko0b494"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an Educational Content Recommender System Using Knowledge Graphs and NLP\n",
        "\n",
        "This code is designed to illustrate the power of knowledge graphs especially when combined with NLP as a great recommender system for educational content.\n",
        "\n",
        "\n",
        "## Initial Data Processing\n",
        "\n",
        "The first stage involves loading and preprocessing the video data from the CSV file. The `load_video_data` function handles this initial step, where we:\n",
        "1. Convert video durations from milliseconds to minutes for better readability\n",
        "2. Convert timestamp strings to proper datetime objects for temporal analysis\n",
        "3. Prepare the data for further processing\n",
        "\n",
        "\n",
        "## Text Processing and Feature Extraction\n",
        "\n",
        "The next stage is processing the video titles and descriptions using Natural Language Processing (NLP). This is where the automation magic begins to happen. If you checked out the previous tutorial, this is where we manually defined our graph using python learning topic names. Let us extract these details using NLP. In the `process_video_data` function, we use several NLP techniques:\n",
        "\n",
        "### 1. Text Cleaning\n",
        "- We clean all text by converting to lowercase and removing special characters\n",
        "- Handle any missing values (NaN) in titles or descriptions\n",
        "- Remove extra whitespace and standardize the text format\n",
        "\n",
        "### 2. Semantic Understanding using Sentence Transformers\n",
        "- We use the 'all-MiniLM-L6-v2' model from the sentence-transformers library\n",
        "- This model converts our text into high-dimensional vector embeddings\n",
        "- Each video's title and description are combined and transformed into a vector that captures its semantic meaning\n",
        "- These embeddings allow us to measure semantic similarity between videos, even if they don't share exact words\n",
        "\n",
        "### 3. Concept Extraction using spaCy\n",
        "The `extract_key_concepts` function uses spaCy's powerful NLP capabilities to:\n",
        "- Identify noun phrases that represent key concepts in the video content\n",
        "- Extract named entities (like Python, OpenCV, etc.)\n",
        "- Focus on phrases of 3 words or less to capture concise, meaningful concepts\n",
        "- Remove duplicates and clean the extracted concepts\n",
        "\n",
        "This process helps us understand what each video is about at a conceptual level. For example, from a video titled \"Introduction to Python Image Processing with OpenCV\", it might extract concepts like:\n",
        "- python\n",
        "- image processing\n",
        "- opencv\n",
        "- introduction\n",
        "These concepts become crucial for building relationships between videos.\n",
        "\n",
        "### 4. Topic Identification\n",
        "Again, in the previous tutorial we manually defined a few topics but here we will assign our YouTube videos into one of these several topics. The `extract_video_topics` function categorizes videos into predefined topics like:\n",
        "- Python basics\n",
        "- Image processing\n",
        "- Machine learning\n",
        "- Computer vision\n",
        "- Bio applications\n",
        "This categorization is done by looking for specific keywords in the title and description, helping us organize content into meaningful groups.\n",
        "\n",
        "### 5. Difficulty Assessment\n",
        "We automatically infer video difficulty levels (beginner, intermediate, advanced) based on several factors:\n",
        "- Explicit indicators in the title (like \"introduction\", \"advanced\")\n",
        "- Video sequence number (earlier videos tend to be more basic)\n",
        "- Number of technical concepts covered\n",
        "- Complexity of the content\n",
        "\n",
        "This way of automatic processing of the video content creates the foundation for building our knowledge graph. The extracted features, concepts, and relationships will determine how videos are connected and how we can navigate between them effectively.\n",
        "\n",
        "## Building the Knowledge Graph\n",
        "\n",
        "After processing our video content, we construct a knowledge graph that represents the relationships between videos. This is where our system becomes truly powerful, as it captures not just the content of videos, but how they relate to each other in meaningful ways.\n",
        "\n",
        "### Graph Construction Process\n",
        "\n",
        "The knowledge graph is built using NetworkX, with each video becoming a node in the graph. The `build_knowledge_graph` function handles this process:\n",
        "\n",
        "1. **Node Creation**\n",
        "   - Each video becomes a node in our graph\n",
        "   - Node attributes include:\n",
        "     - Title\n",
        "     - Description\n",
        "     - Difficulty level\n",
        "     - Duration\n",
        "     - Key concepts\n",
        "     - Topics covered\n",
        "     - Video number (if part of a series)\n",
        "   These rich attributes allow us to understand each video's content and context thoroughly.\n",
        "\n",
        "2. **Edge Creation**\n",
        "   The most interesting part is how we automatically create edges between videos. We use multiple factors:\n",
        "\n",
        "   a) **Semantic Similarity**\n",
        "   - Use the cosine similarity between video embeddings\n",
        "   - Connect videos if their similarity exceeds a threshold (default for now is 0.5)\n",
        "   - This catches semantic relationships even when videos don't share exact keywords\n",
        "\n",
        "   b) **Relationship Type Determination**\n",
        "   The `determine_relationship` function assigns relationship types between videos:\n",
        "   - **Prerequisite**: Video A should be watched before Video B\n",
        "   - **Advanced**: Video B builds upon concepts in Video A\n",
        "   - **Related**: Videos cover related topics but don't have a strict order\n",
        "\n",
        "   Relationships are determined based on:\n",
        "   - Video sequence numbers (if part of a series)\n",
        "   - Difficulty levels (beginner → intermediate → advanced)\n",
        "   - Topic relationships (e.g., Python basics are prerequisites for advanced topics)\n",
        "\n",
        "### Graph Visualization\n",
        "\n",
        "We create several types of visualizations to understand our knowledge graph:\n",
        "\n",
        "1. **Complete Knowledge Graph** (`visualize_knowledge_graph`)\n",
        "   - Shows all videos and their relationships\n",
        "   - Color-coded by difficulty level:\n",
        "     - Light green for beginner\n",
        "     - Light blue for intermediate\n",
        "     - Light pink for advanced\n",
        "   - Interactive visualization where you can:\n",
        "     - Hover over nodes to see video details\n",
        "     - Drag nodes to explore relationships\n",
        "     - Zoom in/out to focus on specific areas\n",
        "\n",
        "2. **Topic Subgraphs** (`visualize_topic_subgraph`)\n",
        "   - Shows videos related to specific topics (e.g., 'python_basics', 'image_processing')\n",
        "   - Helps understand the structure within each topic area\n",
        "   - Useful for seeing prerequisite chains within a topic\n",
        "\n",
        "3. **Simplified Graph** (`visualize_simplified_graph`)\n",
        "   - Two versions:\n",
        "     - Strong connections only (high similarity weight)\n",
        "     - Python basics structure (foundational content)\n",
        "   - Helps see the core structure of the content\n",
        "   - Reduces visual complexity for better understanding\n",
        "\n",
        "4. **Learning Path Visualization** (`visualize_learning_path`)\n",
        "   - Shows the recommended sequence of videos for a specific learning goal\n",
        "   - Highlights the progression from prerequisites to advanced content\n",
        "   - Color-coded to show difficulty progression\n",
        "\n",
        "All visualizations are saved as interactive HTML files using the pyvis library, which allows for:\n",
        "- Zooming and panning\n",
        "- Node dragging for better arrangement\n",
        "- Hovering for detailed information\n",
        "- Physics-based layout for natural clustering\n",
        "\n",
        "These visualizations not only help us understand the structure of our educational content but also validate the relationships our system has identified. They're particularly useful for:\n",
        "- Identifying gaps in content\n",
        "- Ensuring proper prerequisite chains\n",
        "- Finding isolated content that needs better integration\n",
        "- Understanding the overall structure of the educational material\n",
        "\n",
        "## Learning Path Generation and Recommendations\n",
        "\n",
        "Once our knowledge graph is built, we can use it to generate personalized learning paths and make intelligent recommendations. This is where the system demonstrates its real power in educational content organization.\n",
        "\n",
        "### Learning Path Generation\n",
        "\n",
        "The `find_learning_path` function is central to our recommendation system. Here's how it works:\n",
        "\n",
        "1. **Goal Understanding**\n",
        "   - Takes a learning goal as input (e.g., \"Mastering Python for Bioimage analysis\")\n",
        "   - Converts the goal into an embedding using the same sentence transformer model\n",
        "   - Compares this embedding with all video embeddings to find relevant content\n",
        "\n",
        "2. **Topic Prerequisites**\n",
        "   We define prerequisite relationships between topics. For example:\n",
        "   ```\n",
        "   'image_processing': needs {'python_basics', 'data_structures'}\n",
        "   'machine_learning': needs {'python_basics', 'data_structures', 'data_analysis'}\n",
        "   'computer_vision': needs {'python_basics', 'image_processing'}\n",
        "   'bio_applications': needs {'python_basics', 'image_processing'}\n",
        "   ```\n",
        "\n",
        "3. **Path Construction**\n",
        "   The system builds a path through the content by:\n",
        "   a) Starting with foundational content\n",
        "      - Automatically includes Python basics for technical topics\n",
        "      - Sorts basics by video number to maintain logical progression\n",
        "   \n",
        "   b) Adding topic-specific content\n",
        "      - Uses similarity scores to find most relevant videos\n",
        "      - Checks and includes prerequisites before advanced content\n",
        "      - Ensures proper skill progression\n",
        "\n",
        "### Path Analysis and Validation\n",
        "\n",
        "The `analyze_path_coverage` function examines generated paths to ensure quality:\n",
        "\n",
        "1. **Topic Coverage**\n",
        "   - Tracks which topics are covered in the path\n",
        "   - Ensures all necessary prerequisite topics are included\n",
        "\n",
        "2. **Prerequisite Validation**\n",
        "   - Checks if advanced topics (like machine learning) have necessary basics\n",
        "   - Issues warnings if prerequisites are missing\n",
        "   - Helps maintain logical learning progression\n",
        "\n",
        "3. **Path Statistics**\n",
        "   We collect detailed statistics about each path:\n",
        "   - Total number of videos\n",
        "   - Total duration\n",
        "   - Difficulty breakdown\n",
        "   - Topic coverage\n",
        "   - Concept progression\n",
        "\n",
        "### Querying the System\n",
        "\n",
        "Our system supports various types of queries:\n",
        "\n",
        "1. **Topic-Based Queries** (`query_videos_by_topic`)\n",
        "   - Find videos by topic and difficulty level\n",
        "   - Useful for focused learning in specific areas\n",
        "   - Can filter by beginner/intermediate/advanced content\n",
        "\n",
        "2. **Prerequisite Queries** (`get_video_prerequisites`)\n",
        "   - Find what videos should be watched before a specific video\n",
        "   - Shows relevance scores for each prerequisite\n",
        "   - Helps ensure proper preparation for advanced content\n",
        "\n",
        "3. **Learning Path Queries** (`get_learning_path_from_db`)\n",
        "   - Generate complete learning paths for specific goals\n",
        "   - Includes:\n",
        "     - Step-by-step video sequence\n",
        "     - Estimated completion time\n",
        "     - Difficulty progression\n",
        "     - Topic coverage analysis\n",
        "\n",
        "### System Persistence and Database Structure\n",
        "\n",
        "Instead of using simple serialization (like pickle), we use SQLite because:\n",
        "1. **Structured Storage**\n",
        "   - Maintains relationships between different components\n",
        "   - Allows for complex queries\n",
        "   - Ensures data integrity\n",
        "\n",
        "2. **Efficient Querying**\n",
        "   - Fast retrieval of video information\n",
        "   - Efficient path generation\n",
        "   - Quick prerequisite lookups\n",
        "\n",
        "3. **Data Organization**\n",
        "   Our database has three main tables:\n",
        "   - `nodes`: Stores video information\n",
        "   - `edges`: Stores relationships between videos\n",
        "   - `embeddings`: Stores video embeddings for similarity calculations\n",
        "\n",
        "This structured storage allows us to:\n",
        "- Quickly rebuild the knowledge graph\n",
        "- Run complex queries efficiently\n",
        "- Maintain relationship integrity\n",
        "- Update content without rebuilding everything\n",
        "\n",
        "## System Outputs and Practical Applications\n",
        "\n",
        "Let's look at what we get from this system and how it can be practically used.\n",
        "\n",
        "### Output Organization\n",
        "\n",
        "All system outputs are organized in a structured directory:\n",
        "```\n",
        "/video_recommender/results/\n",
        "├── database/\n",
        "│   └── video_recommender.db\n",
        "├── visualizations/\n",
        "│   ├── knowledge_graph.html\n",
        "│   ├── learning_path_*.html\n",
        "│   ├── topic_subgraph_*.html\n",
        "│   └── simplified_*.html\n",
        "└── queries/\n",
        "    ├── learning_path_*.txt\n",
        "    └── topic_query_*.txt\n",
        "```\n",
        "\n",
        "### Practical Applications\n",
        "\n",
        "1. **For Content Creators (like myself)**\n",
        "   - **Content Gap Analysis**\n",
        "     - Identify missing prerequisite content\n",
        "     - Spot areas needing more advanced material\n",
        "     - See which topics are under-represented\n",
        "\n",
        "   - **Content Organization**\n",
        "     - Verify logical progression of video series\n",
        "     - Ensure proper coverage of prerequisites\n",
        "     - Plan future content based on graph structure\n",
        "\n",
        "   - **Channel Management**\n",
        "     - Optimize playlist organization\n",
        "     - Create better video descriptions\n",
        "     - Link related videos effectively\n",
        "\n",
        "2. **For Learners**\n",
        "   - **Personalized Learning Paths**\n",
        "     - Get customized pathways for specific goals\n",
        "     - Understand prerequisites clearly\n",
        "     - Track learning progress\n",
        "\n",
        "   - **Topic Exploration**\n",
        "     - Find related content easily\n",
        "     - Understand topic relationships\n",
        "     - Choose appropriate difficulty levels\n",
        "\n",
        "3. **For Educational Institutions**\n",
        "   - **Curriculum Planning**\n",
        "     - Design coherent course sequences\n",
        "     - Ensure proper skill progression\n",
        "     - Create balanced learning paths\n",
        "\n",
        "### Real-World Impact\n",
        "\n",
        "In my YouTube channel (DigitalSreeni), this system helps:\n",
        "- New viewers find appropriate starting points\n",
        "- Regular viewers progress logically through topics\n",
        "- Advanced viewers find specific content quickly\n",
        "- Me (as a content creator) maintain content coherence\n",
        "\n",
        "### Future Extensions and Possibilities\n",
        "\n",
        "1. **Technical Enhancements**\n",
        "   - Real-time content updates\n",
        "   - User feedback integration\n",
        "   - More sophisticated difficulty estimation\n",
        "   - Advanced recommendation algorithms\n",
        "\n",
        "2. **Feature Additions**\n",
        "   - User progress tracking\n",
        "   - Interactive learning path modification\n",
        "   - Content engagement metrics\n",
        "   - Multi-language support\n",
        "\n",
        "3. **Integration Possibilities**\n",
        "   - YouTube API integration\n",
        "   - Learning Management Systems (LMS)\n",
        "   - Course creation platforms\n",
        "   - Social learning features\n",
        "\n",
        "\n",
        "\n",
        "## Summary\n",
        "\n",
        "The goal is to make this a comprehensive project on building a recommender system for learning content using knowledge graphs and NLP. While I've used it for my YouTube channel, the principles and techniques can be applied to any educational content platform.\n"
      ],
      "metadata": {
        "id": "BiAApEiCjWDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers spacy gensim pandas numpy networkx pyvis\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "51-GXVxMxgBh",
        "outputId": "a8c738ce-6967-4288-e056-ff031da897cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m579.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy (from sentence-transformers)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, jedi, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, blis, pyvis, nvidia-cusolver-cu12, gensim, thinc\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.2.1 gensim-4.3.3 jedi-0.19.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyvis-0.3.2 scipy-1.13.1 thinc-8.3.4\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "import re\n",
        "import networkx as nx\n",
        "from typing import List, Dict, Set, Tuple\n",
        "from gensim import corpora, models\n",
        "import sqlite3\n",
        "import json\n",
        "from pyvis.network import Network\n",
        "import os"
      ],
      "metadata": {
        "id": "2TYRbl-pSVGK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Personal note, delete later: Add Doc strings to each function. May be chatGPT can help?\n",
        "\n",
        "def load_video_data(csv_path: str = '04_combined_videos.csv') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load and preprocess the video data from CSV. Convert ms to minutes and\n",
        "    date to proper datetime format. Not sure if we will use the date but why not\n",
        "    make it ready for use.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Convert duration from milliseconds to minutes\n",
        "    df['duration_minutes'] = df['Approx Duration (ms)'] / (1000 * 60)\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    df['publish_date'] = pd.to_datetime(df['Video Publish Timestamp'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and preprocess text.\n",
        "    Takes a text string, converts it to lowercase, removes special characters,\n",
        "    extra spaces, and returns the cleaned result.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase and remove special characters\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def extract_key_concepts(text: str, nlp) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract key concepts from text using spaCy.\n",
        "    This process helps us understand what each video is about at a conceptual level.\n",
        "    For example, from a video titled \"Introduction to Python Image Processing\n",
        "    with OpenCV\", it might extract concepts like:\n",
        "        python\n",
        "        image processing\n",
        "        opencv\n",
        "        introduction\n",
        "    These concepts become important for building relationships between videos.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    concepts = []\n",
        "\n",
        "    # Extract noun phrases and named entities\n",
        "    for chunk in doc.noun_chunks:     # doc.noun_chunks is a generator provided by Spacy's Doc object and gives noun phrases from the text.\n",
        "        if len(chunk.text.split()) <= 3:  # Limit to phrases of 3 words or less, just so we work with concise phrases\n",
        "            concepts.append(chunk.text)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if len(ent.text.split()) <= 3:\n",
        "            concepts.append(ent.text)\n",
        "\n",
        "    # Remove duplicates and clean\n",
        "    concepts = list(set([clean_text(c) for c in concepts]))\n",
        "    return [c for c in concepts if c]  # Remove empty strings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_video_data(video_data: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, Dict]:\n",
        "    \"\"\"\n",
        "    Process video data and create embeddings for semantic understanding\n",
        "\n",
        "    We use the 'all-MiniLM-L6-v2' model from the sentence-transformers library\n",
        "    This model converts our text into high-dimensional vector embeddings\n",
        "    Each video's title and description are combined and transformed into a vector that captures its semantic meaning\n",
        "    These embeddings allow us to measure semantic similarity between videos, even if they don't share exact words\n",
        "\n",
        "    \"\"\"\n",
        "    # Initialize models\n",
        "    transformer_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    print(\"Cleaning text...\")\n",
        "    # Clean titles and descriptions\n",
        "    video_data['cleaned_title'] = video_data['Video Title (Original)'].apply(clean_text)\n",
        "    video_data['cleaned_description'] = video_data['Video Description (Original)'].apply(clean_text)\n",
        "\n",
        "    # Combine title and description for embedding\n",
        "    video_data['combined_text'] = video_data['cleaned_title'] + \" \" + video_data['cleaned_description']\n",
        "\n",
        "    print(\"Creating embeddings...\")\n",
        "    # Create embeddings\n",
        "    embeddings = transformer_model.encode(\n",
        "        video_data['combined_text'].tolist(),\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Calculate similarity matrix\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "    print(\"Extracting concepts...\")\n",
        "    # Extract concepts for each video - by building a dictionary that maps each video (by its index)\n",
        "    # to a list of key concepts extracted from its combined title and description.\n",
        "    #Example structure of the final result....\n",
        "    # {\n",
        "    #     0: ['python', 'image processing', 'opencv'],  # Concepts for video 0\n",
        "    #     1: ['machine learning', 'classification', 'sklearn'],  # Concepts for video 1\n",
        "    #     2: ['deep learning', 'segmentation', 'tensorflow']  # Concepts for video 2\n",
        "    # }\n",
        "\n",
        "    video_concepts = {}\n",
        "    for idx, row in video_data.iterrows():\n",
        "        concepts = extract_key_concepts(row['combined_text'], nlp)\n",
        "        video_concepts[idx] = concepts\n",
        "\n",
        "    return video_data, embeddings, similarity_matrix, video_concepts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_video_topics(title: str, description: str) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extract main topics from video title and description\n",
        "    categorizes videos into predefined topics like:\n",
        "        Python basics\n",
        "        Image processing\n",
        "        Machine learning\n",
        "        Computer vision\n",
        "        Bio applications\n",
        "This categorization is done by looking for specific keywords in the title and\n",
        "description, helping us organize content into meaningful groups.\n",
        "Basically, the output looks like this:\n",
        "Input: text = \"introduction to python image processing learn how to use opencv for microscopy image analysis and visualization\"\n",
        "Output: {'python_basics', 'image_processing', 'computer_vision'}\n",
        "\n",
        "    \"\"\"\n",
        "    # Handle NaN values\n",
        "    title = str(title) if not pd.isna(title) else \"\"\n",
        "    description = str(description) if not pd.isna(description) else \"\"\n",
        "\n",
        "    text = (title + \" \" + description).lower()\n",
        "    topics = set()\n",
        "\n",
        "    # Define topic categories\n",
        "    topic_keywords = {\n",
        "        'python_basics': {'python basics', 'introduction', 'variables', 'functions', 'loops', 'conditionals'},\n",
        "        'data_structures': {'lists', 'dictionaries', 'arrays', 'data structures'},\n",
        "        'image_processing': {'image', 'microscopy', 'bioimage', 'visualization', 'processing'},\n",
        "        'machine_learning': {'machine learning', 'deep learning', 'neural network', 'classification'},\n",
        "        'data_analysis': {'data analysis', 'statistics', 'pandas', 'numpy'},\n",
        "        'computer_vision': {'opencv', 'vision', 'object detection', 'segmentation'},\n",
        "        'bio_applications': {'cell', 'tissue', 'microscopy', 'biology', 'medical'}\n",
        "    }\n",
        "\n",
        "    for topic, keywords in topic_keywords.items():\n",
        "        if any(keyword in text for keyword in keywords):\n",
        "            topics.add(topic)\n",
        "\n",
        "    return topics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def infer_video_difficulty(title: str, concepts: List[str], video_number: int = None) -> str:\n",
        "    \"\"\"\n",
        "    Infer difficulty level of a video\n",
        "    by looking for some words that represent beginner or advanced\n",
        "    by video number, as my first videos are basic intro videos\n",
        "    also by number of concepts, like python, opencv, etc. etc.\n",
        "\n",
        "    \"\"\"\n",
        "    title = title.lower()\n",
        "\n",
        "    # Check for explicit difficulty indicators\n",
        "    if any(word in title for word in ['introduction', 'basics', 'beginner', 'what is']):\n",
        "        return 'beginner'\n",
        "    elif any(word in title for word in ['advanced', 'expert', 'complex']):\n",
        "        return 'advanced'\n",
        "\n",
        "    # Consider video number in series\n",
        "    if video_number is not None:\n",
        "        if video_number <= 20:\n",
        "            return 'beginner'\n",
        "        elif video_number > 50:\n",
        "            return 'advanced'\n",
        "\n",
        "    # Check concept complexity\n",
        "    concept_count = len(concepts)\n",
        "    if concept_count < 5:\n",
        "        return 'beginner'\n",
        "    elif concept_count > 10:\n",
        "        return 'advanced'\n",
        "\n",
        "    return 'intermediate'"
      ],
      "metadata": {
        "id": "OPfwMjEoxg2f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_knowledge_graph(video_data: pd.DataFrame,\n",
        "                        similarity_matrix: np.ndarray,\n",
        "                        video_concepts: Dict,\n",
        "                        similarity_threshold: float = 0.6) -> nx.DiGraph:\n",
        "    \"\"\"\n",
        "    Build a knowledge graph from video data using NetworkX\n",
        "    Build nodes and edges. Nodes are basically videos and they have various attributes (metadata).\n",
        "\n",
        "    Edges are added based on similarity we calculate (using cosine).\n",
        "    Basically semantic Similarity between video embeddings\n",
        "    Connect videos if their similarity exceeds a threshold (default 0.5 but changed to 0.6 to minimize the number of edges.)\n",
        "    This catches semantic relationships even when videos don't share exact keywords\n",
        "\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes (videos)\n",
        "    for idx, row in video_data.iterrows():\n",
        "        # Extract video number if present\n",
        "        video_num = None\n",
        "        match = re.search(r'(\\d+)', row['Video Title (Original)'])\n",
        "        if match:\n",
        "            video_num = int(match.group(1))\n",
        "\n",
        "        # Get video topics\n",
        "        topics = extract_video_topics(row['Video Title (Original)'],\n",
        "                                   row['Video Description (Original)'])\n",
        "\n",
        "        # Infer difficulty\n",
        "        difficulty = infer_video_difficulty(row['Video Title (Original)'],\n",
        "                                         video_concepts[idx],\n",
        "                                         video_num)\n",
        "\n",
        "        # Add node with metadata\n",
        "        G.add_node(idx,\n",
        "                  title=row['Video Title (Original)'],\n",
        "                  description=row['Video Description (Original)'],\n",
        "                  concepts=video_concepts[idx],\n",
        "                  topics=topics,\n",
        "                  difficulty=difficulty,\n",
        "                  duration=row['Approx Duration (ms)'],\n",
        "                  video_number=video_num)\n",
        "\n",
        "    # Add edges based on similarity and relationships\n",
        "    for i in range(len(video_data)):\n",
        "        for j in range(len(video_data)):\n",
        "            if i != j and similarity_matrix[i][j] >= similarity_threshold:   #similarity_matrix is nothing but our cosine similarity\n",
        "                # Determine edge type and direction\n",
        "                edge_type = determine_relationship(G, i, j)  #determine_relationship is defined next\n",
        "\n",
        "                G.add_edge(i, j,\n",
        "                          weight=similarity_matrix[i][j],\n",
        "                          type=edge_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "\n",
        "def determine_relationship(G: nx.DiGraph, video1_idx: int, video2_idx: int) -> str:\n",
        "    \"\"\"\n",
        "    Determine the relationship type between two videos\n",
        "\n",
        "    Prerequisite: Video A should be watched before Video B\n",
        "    Advanced: Video B builds upon concepts in Video A\n",
        "    Related: Videos cover related topics but don't have a strict order\n",
        "\n",
        "    Relationships are determined based on:\n",
        "      Video sequence numbers (if part of a series)\n",
        "      Difficulty levels (beginner → intermediate → advanced)\n",
        "      Topic relationships (e.g., Python basics are prerequisites for advanced topics)\n",
        "\n",
        "    \"\"\"\n",
        "    v1 = G.nodes[video1_idx]\n",
        "    v2 = G.nodes[video2_idx]\n",
        "\n",
        "    # Check if videos are part of a numbered series\n",
        "    if (v1['video_number'] is not None and\n",
        "        v2['video_number'] is not None):\n",
        "        if v1['video_number'] < v2['video_number']:\n",
        "            return 'prerequisite'\n",
        "        elif v1['video_number'] > v2['video_number']:\n",
        "            return 'advanced'\n",
        "\n",
        "    # Compare difficulty levels\n",
        "    diff_levels = ['beginner', 'intermediate', 'advanced']\n",
        "    v1_diff_idx = diff_levels.index(v1['difficulty'])\n",
        "    v2_diff_idx = diff_levels.index(v2['difficulty'])\n",
        "\n",
        "    if v1_diff_idx < v2_diff_idx:\n",
        "        return 'prerequisite'\n",
        "    elif v1_diff_idx > v2_diff_idx:\n",
        "        return 'advanced'\n",
        "\n",
        "    # Check topic relationships\n",
        "    v1_topics = v1['topics']\n",
        "    v2_topics = v2['topics']\n",
        "\n",
        "    if 'python_basics' in v1_topics and not 'python_basics' in v2_topics:\n",
        "        return 'prerequisite'\n",
        "\n",
        "    return 'related'"
      ],
      "metadata": {
        "id": "LbNzbSe_UlLp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## We are using pyviz for visualization, make sit easy for a complex graph like this one.\n",
        "\n",
        "def visualize_knowledge_graph(G: nx.DiGraph, filename='knowledge_graph.html'):\n",
        "    \"\"\"\n",
        "    Create interactive visualization of the knowledge graph (we are using pyviz)\n",
        "    \"\"\"\n",
        "\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'visualizations', filename)\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff',\n",
        "                 font_color='#000000', directed=True, notebook=True)\n",
        "\n",
        "    # Set physics layout options\n",
        "    net.force_atlas_2based()\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Color mapping for different difficulty levels\n",
        "    color_map = {\n",
        "        'beginner': '#90EE90',      # light green\n",
        "        'intermediate': '#ADD8E6',   # light blue\n",
        "        'advanced': '#FFB6C1'        # light pink\n",
        "    }\n",
        "\n",
        "    # Add nodes\n",
        "    for node_id in G.nodes():\n",
        "        node_data = G.nodes[node_id]\n",
        "        title = node_data['title']\n",
        "        difficulty = node_data['difficulty']\n",
        "        duration = node_data['duration'] / (1000 * 60)  # Convert to minutes\n",
        "        concepts = ', '.join(node_data['concepts'][:5])\n",
        "        topics = ', '.join(node_data['topics'])\n",
        "\n",
        "        hover_text = f\"\"\"\n",
        "        Title: {title}\n",
        "        Topics: {topics}\n",
        "        Difficulty: {difficulty}\n",
        "        Duration: {duration:.1f} min\n",
        "        Key Concepts: {concepts}\n",
        "        \"\"\"\n",
        "\n",
        "        net.add_node(\n",
        "            str(node_id),\n",
        "            label=title[:20] + \"...\",\n",
        "            title=hover_text,\n",
        "            color=color_map[difficulty],\n",
        "            size=20\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "        net.add_edge(\n",
        "            str(source),\n",
        "            str(target),\n",
        "            value=data['weight'] * 2,\n",
        "            title=f\"Type: {data['type']}\\nWeight: {data['weight']:.2f}\",\n",
        "            arrows='to'\n",
        "        )\n",
        "\n",
        "    # Save the network\n",
        "    net.save_graph(output_path)\n",
        "    print(f\"Knowledge graph visualization saved to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "def visualize_learning_path(G: nx.DiGraph, path: List[int], filename='learning_path.html'):\n",
        "    \"\"\"\n",
        "    Visualize a specific learning path\n",
        "    Create an interactive visualization of a learning path in a directed graph,\n",
        "    highlighting nodes and edges with details like title, difficulty, and duration,\n",
        "    and save it as an HTML file.\n",
        "\n",
        "    \"\"\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'visualizations', filename)\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff',\n",
        "                 font_color='#000000', directed=True, notebook=True)\n",
        "\n",
        "    # Color mapping\n",
        "    color_map = {\n",
        "        'beginner': '#90EE90',\n",
        "        'intermediate': '#ADD8E6',\n",
        "        'advanced': '#FFB6C1'\n",
        "    }\n",
        "\n",
        "    # Add nodes in path order\n",
        "    for i, node_id in enumerate(path):\n",
        "        node_data = G.nodes[node_id]\n",
        "        title = node_data['title']\n",
        "        difficulty = node_data['difficulty']\n",
        "        duration = node_data['duration'] / (1000 * 60)\n",
        "\n",
        "        hover_text = f\"\"\"\n",
        "        Step {i+1}\n",
        "        Title: {title}\n",
        "        Difficulty: {difficulty}\n",
        "        Duration: {duration:.1f} min\n",
        "        Topics: {', '.join(node_data['topics'])}\n",
        "        \"\"\"\n",
        "\n",
        "        net.add_node(\n",
        "            str(node_id),\n",
        "            label=f\"{i+1}. {title[:20]}...\",\n",
        "            title=hover_text,\n",
        "            color=color_map[difficulty],\n",
        "            size=20\n",
        "        )\n",
        "\n",
        "    # Add edges between consecutive nodes in the path\n",
        "    for i in range(len(path)-1):\n",
        "        source = path[i]\n",
        "        target = path[i+1]\n",
        "        if G.has_edge(source, target):\n",
        "            edge_data = G.get_edge_data(source, target)\n",
        "            net.add_edge(\n",
        "                str(source),\n",
        "                str(target),\n",
        "                value=edge_data['weight'] * 2,\n",
        "                title=f\"Type: {edge_data['type']}\",\n",
        "                arrows='to'\n",
        "            )\n",
        "\n",
        "    # Save the network\n",
        "    net.save_graph(output_path)\n",
        "    print(f\"Learning path visualization saved to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visualize_topic_subgraph(G: nx.DiGraph, topic: str, filename=None):\n",
        "    \"\"\"\n",
        "    Visualize subgraph for a specific topic\n",
        "    Generate an interactive visualization of a subgraph for a specific topic,\n",
        "    highlighting related nodes and edges with difficulty-based colors.\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        filename = f'{topic}_subgraph.html'\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'visualizations', filename)\n",
        "\n",
        "    # Find nodes related to topic\n",
        "    topic_nodes = [n for n, d in G.nodes(data=True) if topic in d['topics']]\n",
        "\n",
        "    # Get subgraph\n",
        "    subgraph = G.subgraph(topic_nodes)\n",
        "\n",
        "    # Create visualization\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff',\n",
        "                 directed=True, notebook=True)\n",
        "\n",
        "    # Add nodes with difficulty-based colors\n",
        "    difficulty_colors = {\n",
        "        'beginner': '#90EE90',\n",
        "        'intermediate': '#ADD8E6',\n",
        "        'advanced': '#FFB6C1'\n",
        "    }\n",
        "\n",
        "    for node_id in subgraph.nodes():\n",
        "        node_data = subgraph.nodes[node_id]\n",
        "        net.add_node(\n",
        "            str(node_id),\n",
        "            label=node_data['title'][:30] + \"...\",\n",
        "            title=f\"Title: {node_data['title']}\\nDifficulty: {node_data['difficulty']}\",\n",
        "            color=difficulty_colors[node_data['difficulty']],\n",
        "            size=20\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for u, v, data in subgraph.edges(data=True):\n",
        "        net.add_edge(str(u), str(v), value=data['weight'] * 2)\n",
        "\n",
        "    net.save_graph(output_path)\n",
        "    print(f\"Topic subgraph saved to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visualize_simplified_graph(G: nx.DiGraph, min_weight=0.7, show_basics_only=False, filename=None):\n",
        "    \"\"\"\n",
        "    Creates a simplified visualization of the knowledge graph,\n",
        "    filtering nodes and edges by importance or topic.\n",
        "\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        filename = 'simplified_graph.html'\n",
        "        if show_basics_only:\n",
        "            filename = 'simplified_basics_only_graph.html'\n",
        "\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'visualizations', filename)\n",
        "\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff',\n",
        "                 directed=True, notebook=True)\n",
        "\n",
        "    # Customize physics for better layout\n",
        "    net.set_options(\"\"\"\n",
        "    const options = {\n",
        "        \"physics\": {\n",
        "            \"forceAtlas2Based\": {\n",
        "                \"gravitationalConstant\": -100,\n",
        "                \"springLength\": 100,\n",
        "                \"springConstant\": 0.1\n",
        "            },\n",
        "            \"maxVelocity\": 50,\n",
        "            \"minVelocity\": 0.1,\n",
        "            \"solver\": \"forceAtlas2Based\"\n",
        "        },\n",
        "        \"edges\": {\n",
        "            \"smooth\": {\n",
        "                \"type\": \"continuous\",\n",
        "                \"forceDirection\": \"none\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    # Filter nodes based on criteria\n",
        "    nodes_to_include = []\n",
        "    for node_id in G.nodes():\n",
        "        node_data = G.nodes[node_id]\n",
        "        if (show_basics_only and 'python_basics' in node_data['topics']) or \\\n",
        "           (not show_basics_only and len(list(G.neighbors(node_id))) > 3):\n",
        "            nodes_to_include.append(node_id)\n",
        "\n",
        "    # Create subgraph\n",
        "    subgraph = G.subgraph(nodes_to_include)\n",
        "\n",
        "    # Color scheme\n",
        "    color_map = {\n",
        "        'python_basics': '#90EE90',\n",
        "        'image_processing': '#ADD8E6',\n",
        "        'machine_learning': '#FFB6C1',\n",
        "        'bio_applications': '#DDA0DD'\n",
        "    }\n",
        "\n",
        "    # Add nodes with simplified information\n",
        "    for node_id in subgraph.nodes():\n",
        "        node_data = subgraph.nodes[node_id]\n",
        "        primary_topic = next(\n",
        "            (topic for topic in ['python_basics', 'image_processing',\n",
        "                               'machine_learning', 'bio_applications']\n",
        "             if topic in node_data['topics']),\n",
        "            'other'\n",
        "        )\n",
        "\n",
        "        net.add_node(\n",
        "            str(node_id),\n",
        "            label=node_data['title'][:30] + \"...\" if len(node_data['title']) > 30 else node_data['title'],\n",
        "            title=f\"Title: {node_data['title']}\\nDifficulty: {node_data['difficulty']}\",\n",
        "            color=color_map.get(primary_topic, '#DCDCDC'),\n",
        "            size=20\n",
        "        )\n",
        "\n",
        "    # Add important edges\n",
        "    for u, v, data in subgraph.edges(data=True):\n",
        "        if data['weight'] >= min_weight:\n",
        "            net.add_edge(\n",
        "                str(u),\n",
        "                str(v),\n",
        "                value=data['weight'] * 2,\n",
        "                title=f\"Relationship: {data['type']}\"\n",
        "            )\n",
        "\n",
        "    net.save_graph(output_path)\n",
        "    print(f\"Simplified graph visualization saved to {output_path}\")"
      ],
      "metadata": {
        "id": "91XEJG4ixqof"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "MahFWT3YXiUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_learning_path(G: nx.DiGraph,\n",
        "                      goal: str,\n",
        "                      embeddings: np.ndarray,\n",
        "                      transformer_model) -> List[int]:\n",
        "    \"\"\"\n",
        "    Find optimal learning path for a given goal\n",
        "\n",
        "    This function is key to our recommendation system. Here's how it works:\n",
        "\n",
        "    Goal Understanding:\n",
        "    Takes a learning goal as input (e.g., \"Mastering Python for Bioimage analysis\")\n",
        "    Converts the goal into an embedding using the same sentence transformer model\n",
        "    Compares this embedding with all video embeddings to find relevant content\n",
        "\n",
        "    Topic Prerequisites\n",
        "    We manually define prerequisite relationships between topics. This ensures that\n",
        "    before a learner is shown advanced videos on a topic (e.g., machine learning),\n",
        "    they are first recommended videos covering the necessary foundational knowledge.\n",
        "\n",
        "    For example:\n",
        "    'image_processing': needs {'python_basics', 'data_structures'}\n",
        "    'machine_learning': needs {'python_basics', 'data_structures', 'data_analysis'}\n",
        "    'computer_vision': needs {'python_basics', 'image_processing'}\n",
        "    'bio_applications': needs {'python_basics', 'image_processing'}\n",
        "\n",
        "    Path Construction:\n",
        "    The system builds a path through the content by:\n",
        "    a) Starting with foundational content\n",
        "    Automatically includes Python basics for technical topics\n",
        "    Sorts basics by video number to maintain logical progression\n",
        "    b) Adding topic-specific content\n",
        "    Uses similarity scores to find most relevant videos\n",
        "    Checks and includes prerequisites before advanced content\n",
        "    Ensures proper skill progression\n",
        "\n",
        "    Outputs a list of vidoes\n",
        "\n",
        "    \"\"\"\n",
        "    # Get goal embedding\n",
        "    goal_embedding = transformer_model.encode([goal])\n",
        "    video_similarities = cosine_similarity(goal_embedding, embeddings)[0]\n",
        "\n",
        "    # Define topic prerequisites\n",
        "    topic_prerequisites = {\n",
        "        'image_processing': {'python_basics', 'data_structures'},\n",
        "        'machine_learning': {'python_basics', 'data_structures', 'data_analysis'},\n",
        "        'computer_vision': {'python_basics', 'image_processing'},\n",
        "        'bio_applications': {'python_basics', 'image_processing'}\n",
        "    }\n",
        "\n",
        "    # Initialize path\n",
        "    path = []\n",
        "    visited = set()\n",
        "\n",
        "    # Start with basics if needed\n",
        "    goal_lower = goal.lower()\n",
        "    if any(topic in goal_lower for topic in ['bioimage', 'image', 'machine learning', 'computer vision']):\n",
        "        # Add Python basics videos first\n",
        "        basics_videos = [n for n, d in G.nodes(data=True)\n",
        "                        if 'python_basics' in d['topics'] and\n",
        "                        d['difficulty'] == 'beginner']\n",
        "        basics_videos.sort(key=lambda x: G.nodes[x].get('video_number', float('inf'))) # Sort with a default value if video_number is None\n",
        "        path.extend(basics_videos)\n",
        "        visited.update(basics_videos)\n",
        "\n",
        "    # Get top relevant videos\n",
        "    relevant_indices = np.argsort(video_similarities)[::-1]\n",
        "\n",
        "    # Add videos to path based on relevance and prerequisites\n",
        "    for idx in relevant_indices:\n",
        "        if idx in visited:\n",
        "            continue\n",
        "\n",
        "        node_data = G.nodes[idx]\n",
        "\n",
        "        # Check if prerequisites are met\n",
        "        node_topics = node_data['topics']\n",
        "        prerequisites_needed = set()\n",
        "        for topic in node_topics:\n",
        "            if topic in topic_prerequisites:\n",
        "                prerequisites_needed.update(topic_prerequisites[topic])\n",
        "\n",
        "        # Add missing prerequisites first\n",
        "        if prerequisites_needed:\n",
        "            for prereq_topic in prerequisites_needed:\n",
        "                if not any(prereq_topic in G.nodes[n]['topics'] for n in path):\n",
        "                    prereq_videos = [n for n, d in G.nodes(data=True)\n",
        "                                   if prereq_topic in d['topics'] and\n",
        "                                   n not in visited]\n",
        "                    prereq_videos.sort(key=lambda x: G.nodes[x]['video_number'] or float('inf'))\n",
        "                    path.extend(prereq_videos)\n",
        "                    visited.update(prereq_videos)\n",
        "\n",
        "        # Add the video to path\n",
        "        path.append(idx)\n",
        "        visited.add(idx)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "\n",
        "def format_learning_path(G: nx.DiGraph, path: List[int]) -> Dict:\n",
        "    \"\"\"\n",
        "    Format a learning path by summarizing total videos, duration,\n",
        "    difficulty breakdown, topics covered, and detailed video info.\n",
        "\n",
        "    Basically, organize and present information about a learning path\n",
        "    in a structured and detailed way.\n",
        "    This function takes a directed graph and creates a summary with:\n",
        "\n",
        "      - The total number of videos.\n",
        "      - The total duration in minutes.\n",
        "      - A breakdown of the difficulty levels.\n",
        "      - A list of unique topics covered.\n",
        "      - Detailed information for each video, like its title, difficulty, duration, associated topics, and key concepts.\n",
        "    \"\"\"\n",
        "    formatted_path = {\n",
        "        'total_videos': len(path),\n",
        "        'total_duration_minutes': sum(G.nodes[n]['duration'] / (1000 * 60) for n in path),\n",
        "        'difficulty_breakdown': {\n",
        "            'beginner': sum(1 for n in path if G.nodes[n]['difficulty'] == 'beginner'),\n",
        "            'intermediate': sum(1 for n in path if G.nodes[n]['difficulty'] == 'intermediate'),\n",
        "            'advanced': sum(1 for n in path if G.nodes[n]['difficulty'] == 'advanced')\n",
        "        },\n",
        "        'topics_covered': set(),\n",
        "        'videos': []\n",
        "    }\n",
        "\n",
        "    for i, node_id in enumerate(path):\n",
        "        node_data = G.nodes[node_id]\n",
        "        formatted_path['topics_covered'].update(node_data['topics'])\n",
        "\n",
        "        video_info = {\n",
        "            'id': node_id,  # Include the video ID\n",
        "            'step': i + 1,\n",
        "            'title': node_data['title'],\n",
        "            'difficulty': node_data['difficulty'],\n",
        "            'duration_minutes': node_data['duration'] / (1000 * 60),\n",
        "            'topics': list(node_data['topics']),\n",
        "            'key_concepts': node_data['concepts'][:5]\n",
        "        }\n",
        "        formatted_path['videos'].append(video_info)\n",
        "\n",
        "    formatted_path['topics_covered'] = list(formatted_path['topics_covered'])\n",
        "    return formatted_path\n",
        "\n",
        "\n",
        "\n",
        "def print_learning_path(formatted_path: Dict):\n",
        "    \"\"\"\n",
        "    Print formatted learning path in a readable way\n",
        "    \"\"\"\n",
        "    print(\"\\nLearning Path Summary\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Total Videos: {formatted_path['total_videos']}\")\n",
        "    print(f\"Total Duration: {formatted_path['total_duration_minutes']:.1f} minutes\")\n",
        "    print(f\"                ({formatted_path['total_duration_minutes']/60:.1f} hours)\")\n",
        "\n",
        "    print(\"\\nDifficulty Breakdown:\")\n",
        "    for level, count in formatted_path['difficulty_breakdown'].items():\n",
        "        print(f\"  {level.title()}: {count} videos\")\n",
        "\n",
        "    print(\"\\nTopics Covered:\")\n",
        "    for topic in formatted_path['topics_covered']:\n",
        "        print(f\"  - {topic.replace('_', ' ').title()}\")\n",
        "\n",
        "    print(\"\\nDetailed Video Path:\")\n",
        "    print(\"=\" * 50)\n",
        "    for video in formatted_path['videos']:\n",
        "        print(f\"\\n{video['step']}. {video['title']}\")\n",
        "        print(f\"   Difficulty: {video['difficulty']}\")\n",
        "        print(f\"   Duration: {video['duration_minutes']:.1f} minutes\")\n",
        "        print(f\"   Topics: {', '.join(t.replace('_', ' ').title() for t in video['topics'])}\")\n",
        "        if video['key_concepts']:\n",
        "            print(f\"   Key Concepts: {', '.join(video['key_concepts'])}\")\n",
        "\n",
        "\n",
        "\n",
        "def analyze_path_coverage(G: nx.DiGraph, path: List[int]):\n",
        "    \"\"\"\n",
        "    Analyze topic coverage and prerequisites in the learning path\n",
        "\n",
        "      Tracks which topics are covered in the path\n",
        "      Ensures all necessary prerequisite topics are included\n",
        "      Prerequisite Validation\n",
        "\n",
        "      Checks if advanced topics (like machine learning) have necessary basics\n",
        "      Issues warnings if prerequisites are missing\n",
        "      Helps maintain logical learning progression\n",
        "      Path Statistics We collect detailed statistics about each path:\n",
        "\n",
        "      Total number of videos\n",
        "      Total duration\n",
        "      Difficulty breakdown\n",
        "      Topic coverage\n",
        "      Concept progression\n",
        "\n",
        "Example output\n",
        "{\n",
        "    'covered_topics': {'python_basics', 'data_structures', 'machine_learning'},\n",
        "    'prerequisite_issues': [\"Warning: Advanced topic found without Python basics coverage\"],\n",
        "    'topic_sequence': [['python_basics'], ['data_structures'], ['machine_learning']]\n",
        "}\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    covered_topics = set()\n",
        "    for node_id in path:\n",
        "        covered_topics.update(G.nodes[node_id]['topics'])\n",
        "\n",
        "    # Check if basic prerequisites are included before advanced topics\n",
        "    prerequisite_issues = []\n",
        "    for i, node_id in enumerate(path):\n",
        "        node_topics = G.nodes[node_id]['topics']\n",
        "        if ('machine_learning' in node_topics or 'computer_vision' in node_topics) and \\\n",
        "           'python_basics' not in covered_topics:\n",
        "            prerequisite_issues.append(f\"Warning: Advanced topic found without Python basics coverage\")\n",
        "\n",
        "    return {\n",
        "        'covered_topics': covered_topics,\n",
        "        'prerequisite_issues': prerequisite_issues,\n",
        "        'topic_sequence': [list(G.nodes[n]['topics']) for n in path]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def create_recommendation_system(csv_path='combined_videos.csv'):\n",
        "    \"\"\"\n",
        "    Create and initialize the complete recommendation system (by running previously defined functions)\n",
        "    Basically return the knowledge graph, the transformer model and embeddings\n",
        "\n",
        "    \"\"\"\n",
        "    # Initialize transformer model\n",
        "    transformer_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Load and process data\n",
        "    print(\"Loading video data...\")\n",
        "    video_data = load_video_data(csv_path)\n",
        "\n",
        "    print(\"Processing video content...\")\n",
        "    processed_data, embeddings, similarity_matrix, video_concepts = process_video_data(video_data)\n",
        "\n",
        "    print(\"Building knowledge graph...\")\n",
        "    G = build_knowledge_graph(processed_data, similarity_matrix, video_concepts)\n",
        "\n",
        "    print(\"System ready!\")\n",
        "    return G, transformer_model, embeddings"
      ],
      "metadata": {
        "id": "lX2TT6s4yHjb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aNl60jl5LL1U",
        "outputId": "897a9b3a-6e85-4851-ae0a-e02daf751540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Serialize to a SQL Database\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/recommender_systems/knowledge_graphs'\n",
        "DB_PATH = os.path.join(OUTPUT_DIR, 'database', 'video_recommender.db')\n",
        "\n",
        "\n",
        "\n",
        "def create_output_dirs():\n",
        "    \"\"\"\n",
        "    Create output directories if they don't exist\n",
        "    \"\"\"\n",
        "    subdirs = ['visualizations', 'queries', 'database']\n",
        "    for subdir in subdirs:\n",
        "        path = os.path.join(OUTPUT_DIR, subdir)\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created output directories in {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "def create_database(db_name='video_recommender.db'):\n",
        "    \"\"\"\n",
        "    Create SQLite database with necessary tables\n",
        "    \"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_name, timeout=10)\n",
        "        conn.text_factory = str\n",
        "        c = conn.cursor()\n",
        "\n",
        "        # Drop existing tables to ensure clean slate\n",
        "        c.execute('DROP TABLE IF EXISTS edges')\n",
        "        c.execute('DROP TABLE IF EXISTS nodes')\n",
        "        c.execute('DROP TABLE IF EXISTS embeddings')\n",
        "\n",
        "        # Create tables with explicit types and add video_number\n",
        "        c.execute('''\n",
        "            CREATE TABLE nodes (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                title TEXT NOT NULL,\n",
        "                description TEXT,\n",
        "                difficulty TEXT NOT NULL,\n",
        "                duration INTEGER NOT NULL,\n",
        "                concepts TEXT NOT NULL,\n",
        "                topics TEXT NOT NULL,\n",
        "                video_number INTEGER\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        c.execute('''\n",
        "            CREATE TABLE edges (\n",
        "                source INTEGER NOT NULL,\n",
        "                target INTEGER NOT NULL,\n",
        "                weight REAL NOT NULL,\n",
        "                relationship_type TEXT NOT NULL,\n",
        "                PRIMARY KEY (source, target),\n",
        "                FOREIGN KEY (source) REFERENCES nodes(id),\n",
        "                FOREIGN KEY (target) REFERENCES nodes(id)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        c.execute('''\n",
        "            CREATE TABLE embeddings (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                embedding BLOB NOT NULL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "\n",
        "# Save the recommender system as serialized database\n",
        "def save_recommendation_system(G, transformer_model, embeddings):\n",
        "    \"\"\"\n",
        "    Save the recommendation system to the specified location\n",
        "\n",
        "    \"\"\"\n",
        "    #db_path = os.path.join(OUTPUT_DIR, 'database', 'video_recommender.db')\n",
        "    try:\n",
        "        create_database(DB_PATH)\n",
        "\n",
        "        conn = sqlite3.connect(DB_PATH, timeout=20)\n",
        "        c = conn.cursor()\n",
        "\n",
        "        # Save nodes with video_number\n",
        "        for node_id, data in G.nodes(data=True):\n",
        "            c.execute('''\n",
        "                INSERT OR REPLACE INTO nodes\n",
        "                (id, title, description, difficulty, duration, concepts, topics, video_number)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            ''', (\n",
        "                node_id,\n",
        "                data['title'],\n",
        "                data.get('description', ''),\n",
        "                data['difficulty'],\n",
        "                data['duration'],\n",
        "                json.dumps(data['concepts']),\n",
        "                json.dumps(list(data['topics'])),\n",
        "                data.get('video_number', None)  # Handle cases where video_number doesn't exist\n",
        "            ))\n",
        "\n",
        "        # Save edges with explicit float conversion\n",
        "        c.execute('DELETE FROM edges')\n",
        "        for source, target, data in G.edges(data=True):\n",
        "            weight = float(data['weight'])\n",
        "            c.execute('''\n",
        "                INSERT INTO edges (source, target, weight, relationship_type)\n",
        "                VALUES (?, ?, ?, ?)\n",
        "            ''', (source, target, weight, data['type']))\n",
        "\n",
        "        # Save embeddings\n",
        "        c.execute('DELETE FROM embeddings')\n",
        "        for i, emb in enumerate(embeddings):\n",
        "            c.execute('INSERT INTO embeddings (id, embedding) VALUES (?, ?)',\n",
        "                     (i, emb.tobytes()))\n",
        "\n",
        "        conn.commit()\n",
        "        print(f\"System saved to {DB_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to database: {e}\")\n",
        "        try:\n",
        "            conn.rollback()\n",
        "        except:\n",
        "            pass\n",
        "        raise\n",
        "\n",
        "    finally:\n",
        "        try:\n",
        "            conn.close()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "def save_query_results(results, filename):\n",
        "    \"\"\"\n",
        "    Save query results to a text file\n",
        "    \"\"\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, 'queries', filename)\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(results)\n",
        "    print(f\"Query results saved to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_recommendation_system():\n",
        "    \"\"\"\n",
        "    Load the recommendation system from SQLite database, for future use without\n",
        "    building the knowledge graph again.\n",
        "    Note that we are loading the database but then reconstructing the graph\n",
        "    again using NetworkX.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(DB_PATH):\n",
        "        raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n",
        "\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    conn.text_factory = str\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Create new graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Load nodes with video_number\n",
        "    c.execute('SELECT * FROM nodes')\n",
        "    for row in c.fetchall():\n",
        "        node_id = row[0]\n",
        "        G.add_node(\n",
        "            node_id,\n",
        "            title=str(row[1]) if isinstance(row[1], bytes) else row[1],\n",
        "            description=str(row[2]) if isinstance(row[2], bytes) else row[2],\n",
        "            difficulty=str(row[3]) if isinstance(row[3], bytes) else row[3],\n",
        "            duration=row[4],\n",
        "            concepts=json.loads(row[5]) if isinstance(row[5], str) else json.loads(row[5].decode()),\n",
        "            topics=set(json.loads(row[6]) if isinstance(row[6], str) else json.loads(row[6].decode())),\n",
        "            video_number=row[7]  # Add video_number to node attributes\n",
        "        )\n",
        "\n",
        "    # Load edges\n",
        "    c.execute('SELECT source, target, CAST(weight AS REAL) as weight, relationship_type FROM edges')\n",
        "    for row in c.fetchall():\n",
        "        G.add_edge(\n",
        "            row[0], row[1],\n",
        "            weight=float(row[2]),\n",
        "            type=str(row[3]) if isinstance(row[3], bytes) else row[3]\n",
        "        )\n",
        "\n",
        "    # Load embeddings\n",
        "    c.execute('SELECT * FROM embeddings ORDER BY id')\n",
        "    embeddings = []\n",
        "    for row in c.fetchall():\n",
        "        embedding = np.frombuffer(row[1], dtype=np.float32)\n",
        "        embeddings.append(embedding)\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    # Recreate transformer model\n",
        "    transformer_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    return G, transformer_model, embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def query_videos_by_topic(topic=None, difficulty=None):\n",
        "    \"\"\"\n",
        "    Query videos based on topic and/or difficulty.\n",
        "    Directly querying the databse and not the graph.\n",
        "    Just to show as an example that you can do certain queries on the databse itself.\n",
        "\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    c = conn.cursor()\n",
        "\n",
        "    query = 'SELECT id, title, difficulty, duration FROM nodes WHERE 1=1'\n",
        "    params = []\n",
        "\n",
        "    if topic:\n",
        "        query += ' AND topics LIKE ?'\n",
        "        params.append(f'%{topic}%')\n",
        "\n",
        "    if difficulty:\n",
        "        query += ' AND difficulty = ?'\n",
        "        params.append(difficulty)\n",
        "\n",
        "    c.execute(query, params)\n",
        "    results = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return [{'id': r[0],\n",
        "             'title': r[1],\n",
        "             'difficulty': r[2],\n",
        "             'duration_minutes': r[3]/1000/60}\n",
        "            for r in results]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_video_prerequisites(video_id):\n",
        "    \"\"\"\n",
        "    Get prerequisites for a specific video\n",
        "    Directly querying the databse and not the graph.\n",
        "    Just to show as an example that you can do certain queries on the databse itself.\n",
        "\n",
        "    Basically querying source nodes (n.id, n.title, and n.difficulty) that are linked to the\n",
        "    target video (e.target = video_id) through a relationship of type 'prerequisite'.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    conn.text_factory = str\n",
        "    c = conn.cursor()\n",
        "\n",
        "    c.execute('''\n",
        "        SELECT n.id, n.title, n.difficulty, CAST(e.weight AS REAL) as weight\n",
        "        FROM edges e\n",
        "        JOIN nodes n ON e.source = n.id\n",
        "        WHERE e.target = ? AND e.relationship_type = 'prerequisite'\n",
        "    ''', (video_id,))\n",
        "\n",
        "    results = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return [{'id': r[0],\n",
        "             'title': str(r[1]) if isinstance(r[1], bytes) else r[1],\n",
        "             'difficulty': str(r[2]) if isinstance(r[2], bytes) else r[2],\n",
        "             'relevance': float(r[3])}\n",
        "            for r in results]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_learning_path_from_db(goal, db_name='video_recommender.db'):\n",
        "    \"\"\"\n",
        "    Generate learning path for a specific goal from database\n",
        "    Again, we are loading the database but converting back to a Digraph\n",
        "    \"\"\"\n",
        "    # Load the system\n",
        "    G, transformer_model, embeddings = load_recommendation_system()\n",
        "\n",
        "    # Find the path\n",
        "    path = find_learning_path(G, goal, embeddings, transformer_model)\n",
        "\n",
        "    # Format and analyze the path\n",
        "    formatted_path = format_learning_path(G, path)\n",
        "\n",
        "    return formatted_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_learning_path_from_db(path_info):\n",
        "    \"\"\"\n",
        "    Print the learning path from database\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"\\nLearning Path Summary\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Total Videos: {path_info['total_videos']}\")\n",
        "    print(f\"Total Duration: {path_info['total_duration_minutes']:.1f} minutes\")\n",
        "    print(f\"                ({path_info['total_duration_minutes']/60:.1f} hours)\")\n",
        "\n",
        "    print(\"\\nDifficulty Breakdown:\")\n",
        "    for level, count in path_info['difficulty_breakdown'].items():\n",
        "        print(f\"  {level.title()}: {count} videos\")\n",
        "\n",
        "    print(\"\\nTopics Covered:\")\n",
        "    for topic in path_info['topics_covered']:\n",
        "        print(f\"  - {topic.replace('_', ' ').title()}\")\n",
        "\n",
        "    print(\"\\nDetailed Learning Path:\")\n",
        "    print(\"=\" * 50)\n",
        "    for video in path_info['videos']:\n",
        "        print(f\"\\n{video['step']}. {video['title']}\")\n",
        "        print(f\"   Difficulty: {video['difficulty']}\")\n",
        "        print(f\"   Duration: {video['duration_minutes']:.1f} minutes\")\n",
        "        print(f\"   Topics: {', '.join(t.replace('_', ' ').title() for t in video['topics'])}\")\n",
        "        if video['key_concepts']:\n",
        "            print(f\"   Key Concepts: {', '.join(video['key_concepts'])}\")"
      ],
      "metadata": {
        "id": "l-z_i3CUyIRn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_system(csv_path):\n",
        "    \"\"\"\n",
        "    Initialize and save the recommendation system\n",
        "    \"\"\"\n",
        "    print(\"Initializing recommendation system...\")\n",
        "    create_output_dirs()  # Using the original function instead of setup_environment\n",
        "\n",
        "    # Create and save the system\n",
        "    G, transformer_model, embeddings = create_recommendation_system(csv_path)\n",
        "    save_recommendation_system(G, transformer_model, embeddings)\n",
        "\n",
        "    # Generate and save initial visualizations\n",
        "    visualize_knowledge_graph(G)\n",
        "    visualize_simplified_graph(G, min_weight=0.7, filename='simplified_strong_connections.html')\n",
        "    visualize_simplified_graph(G, show_basics_only=True, filename='simplified_basics_only.html')\n",
        "\n",
        "    return G, transformer_model, embeddings\n",
        "\n",
        "\n",
        "\n",
        "# Getting Prerequisites for a Video\n",
        "def check_prerequisites(video_id):\n",
        "    \"\"\"\n",
        "    Check prerequisites for a specific video and save results\n",
        "    \"\"\"\n",
        "    prereqs = get_video_prerequisites(video_id)\n",
        "\n",
        "    # Prepare output string\n",
        "    output = []\n",
        "    output.append(f\"Prerequisites for Video {video_id}:\")\n",
        "    output.append(\"=\" * 50)\n",
        "\n",
        "    if prereqs:\n",
        "        for prereq in prereqs:\n",
        "            output.append(f\"Title: {prereq['title']}\")\n",
        "            output.append(f\"Difficulty: {prereq['difficulty']}\")\n",
        "            output.append(f\"Relevance Score: {prereq['relevance']:.2f}\")\n",
        "            output.append(\"-\" * 30)\n",
        "    else:\n",
        "        output.append(f\"No prerequisites found for Video {video_id}\")\n",
        "\n",
        "    # Save to file\n",
        "    filename = os.path.join(OUTPUT_DIR, 'queries', f'prerequisites_video_{video_id}.txt')\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(output))\n",
        "\n",
        "    # Also print to console\n",
        "    print('\\n'.join(output))\n",
        "\n",
        "\n",
        "\n",
        "# Getting Learning Path for a Goal\n",
        "def get_path_for_goal(goal):\n",
        "    \"\"\"\n",
        "    Get and display learning path for a specific goal\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating learning path for: {goal}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    path_info = get_learning_path_from_db(goal)\n",
        "\n",
        "    # Create output string (all the following code just to dump output to a file)\n",
        "    output = []\n",
        "    output.append(f\"Learning Path for: {goal}\")\n",
        "    output.append(\"=\" * 80)\n",
        "    output.append(f\"\\nTotal Videos: {path_info['total_videos']}\")\n",
        "    output.append(f\"Total Duration: {path_info['total_duration_minutes']:.1f} minutes\")\n",
        "    output.append(f\"                ({path_info['total_duration_minutes']/60:.1f} hours)\")\n",
        "\n",
        "    output.append(\"\\nDifficulty Breakdown:\")\n",
        "    for level, count in path_info['difficulty_breakdown'].items():\n",
        "        output.append(f\"  {level.title()}: {count} videos\")\n",
        "\n",
        "    output.append(\"\\nTopics Covered:\")\n",
        "    for topic in path_info['topics_covered']:\n",
        "        output.append(f\"  - {topic.replace('_', ' ').title()}\")\n",
        "\n",
        "    output.append(\"\\nDetailed Video Path:\")\n",
        "    output.append(\"=\" * 50)\n",
        "    for video in path_info['videos']:\n",
        "        output.append(f\"\\n{video['step']}. {video['title']}\")\n",
        "        output.append(f\"   Difficulty: {video['difficulty']}\")\n",
        "        output.append(f\"   Duration: {video['duration_minutes']:.1f} minutes\")\n",
        "        output.append(f\"   Topics: {', '.join(t.replace('_', ' ').title() for t in video['topics'])}\")\n",
        "        if video['key_concepts']:\n",
        "            output.append(f\"   Key Concepts: {', '.join(video['key_concepts'])}\")\n",
        "\n",
        "    # Save to file\n",
        "    filename = os.path.join(OUTPUT_DIR, 'queries', f'learning_path_{goal.replace(\" \", \"_\")}.txt')\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(output))\n",
        "\n",
        "    # Also print to console\n",
        "    print('\\n'.join(output))\n",
        "\n",
        "    return path_info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Querying Videos by Topic and Difficulty\n",
        "def explore_topics(topic=None, difficulty=None):\n",
        "    \"\"\"\n",
        "    Explore videos by topic and/or difficulty\n",
        "    \"\"\"\n",
        "    videos = query_videos_by_topic(topic=topic, difficulty=difficulty)\n",
        "\n",
        "    # Prepare output string\n",
        "    output = []\n",
        "    output.append(f\"\\nFound {len(videos)} videos\")\n",
        "    if topic:\n",
        "        output.append(f\" for topic '{topic}'\")\n",
        "    if difficulty:\n",
        "        output.append(f\" with {difficulty} difficulty\")\n",
        "    output.append(\":\")\n",
        "    output.append(\"=\" * 50)\n",
        "\n",
        "    for video in videos:\n",
        "        output.append(f\"\\nID: {video['id']}\")\n",
        "        output.append(f\"Title: {video['title']}\")\n",
        "        output.append(f\"Difficulty: {video['difficulty']}\")\n",
        "        output.append(f\"Duration: {video['duration_minutes']:.1f} minutes\")\n",
        "\n",
        "    # Save to file\n",
        "    filename_parts = []\n",
        "    if topic:\n",
        "        filename_parts.append(topic)\n",
        "    if difficulty:\n",
        "        filename_parts.append(difficulty)\n",
        "    filename = os.path.join(OUTPUT_DIR, 'queries', f'topic_query_{\"_\".join(filename_parts)}.txt')\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(output))\n",
        "\n",
        "    # Also print to console\n",
        "    print('\\n'.join(output))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_example_queries(G, transformer_model, embeddings):\n",
        "    \"\"\"\n",
        "    Run and save example queries\n",
        "    \"\"\"\n",
        "    create_output_dirs()  # Ensure directories exist\n",
        "\n",
        "    # Example goals\n",
        "    example_goals = [\n",
        "        \"Mastering python for Bioimage analysis\",\n",
        "        \"Learning machine learning for microscopy\",\n",
        "       # \"Understanding computer vision and image processing\",\n",
        "       #\"Python programming basics for scientists\"\n",
        "    ]\n",
        "\n",
        "    # Generate learning paths\n",
        "    for goal in example_goals:\n",
        "        print(f\"\\nProcessing goal: {goal}\")\n",
        "        try:\n",
        "            path_info = get_path_for_goal(goal)\n",
        "            if path_info and 'videos' in path_info:\n",
        "                filename = f'learning_path_{goal.replace(\" \", \"_\")}.html'\n",
        "                path = [video['id'] for video in path_info['videos']]\n",
        "                if path:\n",
        "                    visualize_learning_path(G, path, filename)\n",
        "                else:\n",
        "                    print(f\"Warning: No valid path found for goal: {goal}\")\n",
        "            else:\n",
        "                print(f\"Warning: Invalid path_info structure for goal: {goal}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing goal '{goal}': {str(e)}\")\n",
        "\n",
        "    # Explore topics\n",
        "    for topic in ['python_basics', 'machine_learning', 'image_processing']:\n",
        "        for difficulty in ['beginner', 'intermediate', 'advanced']:\n",
        "            try:\n",
        "                explore_topics(topic=topic, difficulty=difficulty)\n",
        "            except Exception as e:\n",
        "                print(f\"Error exploring topic '{topic}' with difficulty '{difficulty}': {str(e)}\")\n",
        "\n",
        "    # Generate topic visualizations\n",
        "    for topic in ['python_basics', 'image_processing', 'bio_applications']:\n",
        "        try:\n",
        "            visualize_topic_subgraph(G, topic)\n",
        "        except Exception as e:\n",
        "            print(f\"Error visualizing topic '{topic}': {str(e)}\")\n",
        "\n",
        "    # Check prerequisites for some example videos\n",
        "    for video_id in [42, 43, 44]:\n",
        "        try:\n",
        "            check_prerequisites(video_id)\n",
        "        except Exception as e:\n",
        "            print(f\"Error checking prerequisites for video {video_id}: {str(e)}\")"
      ],
      "metadata": {
        "id": "UG3i-vtCygzG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    csv_path = '/content/04_combined_videos.csv'\n",
        "\n",
        "    # Create directories first\n",
        "    create_output_dirs()\n",
        "\n",
        "    # Initialize or load system\n",
        "    try:\n",
        "        print(\"Checking if system needs initialization...\")\n",
        "        G, transformer_model, embeddings = load_recommendation_system()\n",
        "        print(\"System loaded from database successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"System not found or error loading: {str(e)}\")\n",
        "        print(\"Initializing new system...\")\n",
        "        try:\n",
        "            G, transformer_model, embeddings = initialize_system(csv_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing system: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    # Run queries\n",
        "    try:\n",
        "        run_example_queries(G, transformer_model, embeddings)\n",
        "        print(\"\\nAll operations completed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during query execution: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "TCKlZnzfyaey",
        "outputId": "866d2e02-55d2-4784-a752-dbde2530c548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1925553ec09943d2ac76957371b93672",
            "f5325972027842c08d24f6a74cf36fac",
            "5f7aa2e0089142afa5fe0a2bd46e854e",
            "f92536f53250491180f1d4c5a3c12636",
            "7f3cc60a750a4ae891f21fda04e3ce49",
            "454feacc6335407fa165a6776dc85fab",
            "911708a28ebd4a5e99069d094eef7154",
            "68980d2429734933aa93db984690311e",
            "ac775420e6224629846bc64eacd28e43",
            "85ea59f502724dbc8dd584b8cbc2b52d",
            "027d848aa4d44aa6b2adc9dee73dead9",
            "66008c7741de438db49a25d31bf88224",
            "14e37c5bf67b44389bb33b950c9872da",
            "a6736bb7dcdc4916bcbe6bea0cb4cf78",
            "ba4f034d630b4707b23ceee43ae51d3c",
            "9ee75708de174447b2dddbfcf54c06b3",
            "6d3f60e48eb34db48351479ec318511f",
            "c7e6eba155da4e1e8869bc2fa701699e",
            "5935d5824d424f34b35e08da4c85b38d",
            "87c60f690fe64c3eb3d017b12e477d22",
            "3482737466c04ed3a849aafe799afd21",
            "5570b21e0e2a4f52a7192f74700e87f1",
            "fb7a5507878a49358e7c6ff8c5b24ed5",
            "7f51f940291f4e32bae72b385dc257a4",
            "5996df04d075465186ded6bf36f651f5",
            "b03541d6056d4551a662ad4c85b1237d",
            "5d626df0e4a242db97a6674186488ccc",
            "15b5749866614c0e98fed0258cf83eb1",
            "8130f06599f4412eb4a42ed3ce751fba",
            "cbd60c7987f94ab78e2aaf3694413cd3",
            "a124a56769b44988ae3a64625f11b17c",
            "783e020a8a234320bcffec9c7d805296",
            "56ddde3b28ff4efdac10e9109e5268de",
            "f16015a3f03745d7b3e9a2c12b6ba811",
            "c48e6905873c44d791d734ac34cc5eb1",
            "67d0a489f53049c29b29f6904a7edc26",
            "32ca4d279842437aa7a23b315e762441",
            "f40d155498314df0a8d9973ebdc0e2e9",
            "58f54a45a21b4e9c8d441a133d4940a5",
            "a7efcea284ff4495848a5ba72fe00f51",
            "b29cde28dcc24762ad13d7af4449b5cb",
            "ffcc3341b065441d869ff9efa7b2cf62",
            "f1b1541678a84ceaadfab7e8141d44e8",
            "d148bbf433c342aaaf940a65d0bd3b30",
            "334fe36b6d194ce89113947a455884fd",
            "0c28aba6ba2f4bec905029d572a82242",
            "c8b7aae3a83c4e9bbadf93fe5a3ab6d6",
            "1562e3f3db444a5287ae7916f2ee50f2",
            "86162672b29247d5be63271fe4694e10",
            "d9e9054a3b61417190439d35f41d5188",
            "2e606d476c034ae8847f759754df4e1e",
            "d8afcce2c4474edda1beb927a4b1ca69",
            "e56592b120544958a2d5f2c433cc9ee7",
            "2b3bf7b8679e4294b47d78c45f35f08e",
            "730ce02218174ee8ad37e49f24e6310e",
            "2aea888f7a9d4996af9c5b93500977a1",
            "fcc7b2cba90a4c5e85a4b6a934d28283",
            "cbc0ab7fb191448eb585b9bdb5caba09",
            "fd1e52ac33524845865a141a75340ac7",
            "a661af118f3845c6b6faec6881f1c568",
            "649c09db7fd248148473508216c9c550",
            "b8494651ff00425ab65c7b02f9546f0f",
            "df210aefed704d39940ce58f5d67fcf3",
            "9e46a0d3e4b34aa09aa8098a3b2540f9",
            "3cc80cd8d93845fc98f779864288c34d",
            "0280b33683a74eaabea8ec7226458e60",
            "c86760231ca049c6b40d427664426495",
            "af3dec08a62448a4bbbaa46edd73b319",
            "551999a2822741279e1db32f3c1af476",
            "5679106956d241069639465056828e44",
            "1b829c0ea7234d2d9f2400dd6cdfefc4",
            "2cd6c38bd00044e7b3dfdceaf5b3316d",
            "9d2516b0e3764eb5b70fee9b5d728e05",
            "ff2639fb9e814d01b1fea82ce79e88ab",
            "0612a8b3b2ff4dacb35f27096210abdf",
            "303d662bb380431db483dde4fee03f4d",
            "c318529a9aca498595802dcf71e34077",
            "0e77201de99c481bb83b6bc573df44f5",
            "467d44984a4f4e5ea267bd0a0e89b165",
            "9095e132bfaf4d0c8d5622b7575d1559",
            "f38dad0a7c49486b8684dbc9e65e37e8",
            "69688a3de27b4c789b02ba5374c4dfa4",
            "e0f541e685804e2a9dbf3f4b95ba70e7",
            "7b62fbfc4d814702bc5a6562c9a2fe6a",
            "21fb05e916ed4d39bd7868f082edc8a0",
            "e70013e56ce34b4ab2e3a49873b5c8b0",
            "c5fb3d643caa40d2b4cba4d263e43ef7",
            "afc490253cdf4cb4b452f22c1b755e10",
            "dbc208f77b20412382ecc7c1acd60778",
            "6e98d6aa431f4f4ba122a164a515e35f",
            "526df554e6e346eabfb09d99ed8ba254",
            "9f2903ef396b44ca9516a64d09e68fb6",
            "644b97cef15b4a049a85bf52bae23f7d",
            "ea3921cbb84243cc91bf05f62127b535",
            "f16cd7badb31405fa96365b701621a40",
            "4c5dd754ef7d4c28965f34ae95f853f4",
            "65a5e71a321944609a650ede3c802f9c",
            "6754b1a8ec8a48b28269454cb34ed986",
            "6eedd218c30144f18340277ecb083860",
            "7340335035774d149db430c551ca10ac",
            "cbdb66aed19f4bb7819acd88a58c74a3",
            "9d9cb351114c4f2992cd6faa475a8c2c",
            "71436919495b416fbd96ba74c4f81eb1",
            "fd1df45e9aa6423fb637bf9d09237f76",
            "8bc8aa34e6c3403bae78e0e293fa167f",
            "14c765b111a54392970cac1d11b4786c",
            "fbb7f29e437644118f5ad66797c705ee",
            "eeb17456d75243b2912a2526af345134",
            "f700e6080a3f452b8ca15dd3af76ae71",
            "83801ba4b3cb4702b93d6949b000a632",
            "bc3c4669582c4f6888069b904cad2db8",
            "5283f2ee11a0419dbf5444327f3bf04f",
            "7ee9ad281384493caf0b2baa30c4a64f",
            "314c4d61e89e4ecb8e10b6c21e6ad385",
            "9da014db65be4b139079d60d7bf3f149",
            "d61783f82d0f4d02b871b424465af98d",
            "814706abd10245f9b97415707c6d429d",
            "05e906244cc34f6a970bee9ca64641d7",
            "592892ef111f4476b313b645b93aa0fb",
            "79ca214bb09441938664c81a5cdfdbae",
            "86a94e636c09467bb45284832dc50520",
            "cb1ba58c4e984dcaba1010ce9896ba96",
            "521e59af90574c75917297648c8be6eb",
            "0c29a77df4ab4035900a5fd5eeb257de",
            "7f94e09c80f747d8b1c700a87a2e7ec1",
            "b5ed0b58d48744d1ada86cafeca0d805",
            "8679bb2df0bc405c8899bce90b954392",
            "5eebb2acfc58417296061065296adfe5",
            "6ecc530c90ab4ab99ea3a7b9c62aa70f",
            "fdb99de21f7c4337b850bcf4681e2cf5",
            "1ec79ef4d1ea44bd8cd03bc4bf442950",
            "672792cd2426456aa9969ab5075ffcd9"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created output directories in /content/drive/MyDrive/recommender_systems/knowledge_graphs\n",
            "Checking if system needs initialization...\n",
            "System not found or error loading: Database not found at /content/drive/MyDrive/recommender_systems/knowledge_graphs/database/video_recommender.db\n",
            "Initializing new system...\n",
            "Initializing recommendation system...\n",
            "Created output directories in /content/drive/MyDrive/recommender_systems/knowledge_graphs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1925553ec09943d2ac76957371b93672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66008c7741de438db49a25d31bf88224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb7a5507878a49358e7c6ff8c5b24ed5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f16015a3f03745d7b3e9a2c12b6ba811"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334fe36b6d194ce89113947a455884fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2aea888f7a9d4996af9c5b93500977a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86760231ca049c6b40d427664426495"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e77201de99c481bb83b6bc573df44f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbc208f77b20412382ecc7c1acd60778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7340335035774d149db430c551ca10ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc3c4669582c4f6888069b904cad2db8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading video data...\n",
            "Processing video content...\n",
            "Cleaning text...\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb1ba58c4e984dcaba1010ce9896ba96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Total Duration: 8735.8 minutes\n",
            "                (145.6 hours)\n",
            "\n",
            "Difficulty Breakdown:\n",
            "  Beginner: 119 videos\n",
            "  Intermediate: 13 videos\n",
            "  Advanced: 306 videos\n",
            "\n",
            "Topics Covered:\n",
            "  - Data Structures\n",
            "  - Machine Learning\n",
            "  - Computer Vision\n",
            "  - Bio Applications\n",
            "  - Python Basics\n",
            "  - Image Processing\n",
            "  - Data Analysis\n",
            "\n",
            "Detailed Video Path:\n",
            "==================================================\n",
            "\n",
            "1. 04 - What is a digital image?\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.7 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis, Python Basics\n",
            "   Key Concepts: these images, you, a digital image, 04, it\n",
            "\n",
            "2. 05 - What is Python?\n",
            "   Difficulty: beginner\n",
            "   Duration: 8.7 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: you, 05, the video, introduction, a bit\n",
            "\n",
            "3. 06 - Python basics - IDE & operators\n",
            "   Difficulty: beginner\n",
            "   Duration: 19.1 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: different data types, you, various development environments, int float, 06\n",
            "\n",
            "4. 07 - Python basics - logical operators and basic math\n",
            "   Difficulty: beginner\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: you, e mc, previous video, data type, keyboard\n",
            "\n",
            "5. 13 - for and while Loops in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 22.8 minutes\n",
            "   Topics: Data Analysis, Python Basics\n",
            "   Key Concepts: a condition, you, statements, useful tasks, each item\n",
            "\n",
            "6. 14 - Python Functions\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.6 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: your own functions, 14 python functions, you, a coder, its use\n",
            "\n",
            "7. 15 - Python Classes\n",
            "   Difficulty: beginner\n",
            "   Duration: 22.9 minutes\n",
            "   Topics: Bio Applications, Python Basics\n",
            "   Key Concepts: an example, 15, any information, variables, object oriented programming\n",
            "\n",
            "8. Tips Tricks 17 - All you need to know about decorators in python\n",
            "   Difficulty: beginner\n",
            "   Duration: 41.1 minutes\n",
            "   Topics: Data Structures, Python Basics\n",
            "   Key Concepts: you, indians, python_for_microscopists, a variable, a decorator\n",
            "\n",
            "9. 20 - Introduction to image processing using scikit-image in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 37.4 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Python Basics\n",
            "   Key Concepts: python scikit image, scikit image, segmentation process, python_for_microscopists, scratch\n",
            "\n",
            "10. 36 - Introduction to Pandas - Data reading and handling\n",
            "   Difficulty: beginner\n",
            "   Duration: 23.0 minutes\n",
            "   Topics: Image Processing, Data Analysis, Python Basics\n",
            "   Key Concepts: an essential step, analysis, python_for_microscopists, data loading, image processing\n",
            "\n",
            "11. 37 - Introduction to Pandas - Data Manipulation\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.1 minutes\n",
            "   Topics: Data Analysis, Python Basics\n",
            "   Key Concepts: data manipulation, python_for_microscopists, these tasks, pandas library, columns\n",
            "\n",
            "12. 38 - Introduction to Pandas - Data Sorting\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.2 minutes\n",
            "   Topics: Data Analysis, Python Basics\n",
            "   Key Concepts: you, python_for_microscopists, sorting, pandas library, this video\n",
            "\n",
            "13. 39 - Introduction to Pandas -  Grouping Data\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Data Analysis, Bio Applications, Python Basics\n",
            "   Key Concepts: you, python_for_microscopists, the information, better understanding, pandas\n",
            "\n",
            "14. 40 - Introduction to Pandas - Dealing with missing (null) data\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.1 minutes\n",
            "   Topics: Data Analysis, Python Basics\n",
            "   Key Concepts: many forms, missing data, a meaningful value, inevitable pandas, a k\n",
            "\n",
            "15. 41 - Introduction to Pandas  - Plotting\n",
            "   Difficulty: beginner\n",
            "   Duration: 27.7 minutes\n",
            "   Topics: Image Processing, Data Analysis, Bio Applications, Python Basics\n",
            "   Key Concepts: python_for_microscopists, pandas, this video, the best way, data analysis\n",
            "\n",
            "16. 42 - Introduction to Seaborn Plotting in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 29.1 minutes\n",
            "   Topics: Image Processing, Data Analysis, Python Basics\n",
            "   Key Concepts: the visualization capabilities, seaborn library, python_for_microscopists, this video, the code\n",
            "\n",
            "17. 48 - What is logistic regression?\n",
            "   Difficulty: beginner\n",
            "   Duration: 13.8 minutes\n",
            "   Topics: Bio Applications, Python Basics, Machine Learning\n",
            "   Key Concepts: problems, which, a statistical method, an outcome, other words\n",
            "\n",
            "18. 59 - What is Random Forest classifier?\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Python Basics, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, these traditional classifiers, one such application, a quick introduction, this video\n",
            "\n",
            "19. 68 - Quick introduction to Support Vector Machines (SVM)\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Image Processing, Python Basics, Machine Learning\n",
            "   Key Concepts: support vector machines, vector machines, data image analysis, python_for_microscopists, a quick overview\n",
            "\n",
            "20. 79 - What is Docker?\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.2 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: you, python_for_microscopists, 79, docker, this video\n",
            "\n",
            "21. 81 - Testing Docker on Windows and introduction to basic commands\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.0 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: https hub docker, you, python_for_microscopists, 81, this video\n",
            "\n",
            "22. 85b - An introduction to autoencoders - in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.3 minutes\n",
            "   Topics: Image Processing, Python Basics, Machine Learning\n",
            "   Key Concepts: you, python_for_microscopists, g images, image colorization, this video\n",
            "\n",
            "23. 91 - Introduction to transfer learning\n",
            "   Difficulty: beginner\n",
            "   Duration: 20.8 minutes\n",
            "   Topics: Image Processing, Bio Applications, Python Basics, Machine Learning\n",
            "   Key Concepts: training data, python_for_microscopists, dogs, this video, a network\n",
            "\n",
            "24. 135 - A quick introduction to Metrics in deep learning. (Keras & TensorFlow)\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.2 minutes\n",
            "   Topics: Python Basics, Machine Learning\n",
            "   Key Concepts: metrics, https github, the video, 135\n",
            "\n",
            "25. 161 - An introduction to time series forecasting - Part 1\n",
            "   Difficulty: beginner\n",
            "   Duration: 13.0 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: the video, 1, 161, time series, part 1 code\n",
            "\n",
            "26. 162 - An introduction to time series forecasting - Part 2 Exploring data using python\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.3 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: 2, python dataset, the video, 162, 162 an introduction\n",
            "\n",
            "27. 163 - An introduction to time series forecasting - Part 3 Using ARIMA in python\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.3 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: python dataset, arima, the video, 3, https github\n",
            "\n",
            "28. 164 - An introduction to time series forecasting - Part 4 Using feed forward neural networks\n",
            "   Difficulty: beginner\n",
            "   Duration: 20.9 minutes\n",
            "   Topics: Python Basics, Machine Learning\n",
            "   Key Concepts: feed, the video, neural networks, time series, 164\n",
            "\n",
            "29. 165 - An introduction to RNN and LSTM\n",
            "   Difficulty: beginner\n",
            "   Duration: 19.5 minutes\n",
            "   Topics: Python Basics, Machine Learning\n",
            "   Key Concepts: recurrent neural networks, deep learning, neural networks lstm, feedback connections, architecture\n",
            "\n",
            "30. 166 - An introduction to time series forecasting - Part 5 Using LSTM\n",
            "   Difficulty: beginner\n",
            "   Duration: 23.7 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: the video, lstm dataset, time series, 5, an introduction\n",
            "\n",
            "31. 178 - An introduction to variational autoencoders (VAE)\n",
            "   Difficulty: beginner\n",
            "   Duration: 17.6 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: https github, 178, the video, 178 an introduction\n",
            "\n",
            "32. 220 - What is the best loss function for semantic segmentation?\n",
            "   Difficulty: beginner\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: Computer Vision, Python Basics, Machine Learning\n",
            "   Key Concepts: multiclass classification, examples, the cross, classes, better focal loss\n",
            "\n",
            "33. 231 - Semantic Segmentation of BraTS2020 - Part 0 - Introduction (and plan)\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.2 minutes\n",
            "   Topics: Data Structures, Computer Vision, Python Basics, Image Processing, Data Analysis\n",
            "   Key Concepts: the dataset, real labeled volumes, a weird name, step, 3 label\n",
            "\n",
            "34. 253 - Unpaired image to image translation​ using cycleGAN - An introduction\n",
            "   Difficulty: beginner\n",
            "   Duration: 25.9 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: https arxiv, the previous layer, guidelines, values, 1703 10593\n",
            "\n",
            "35. 279 - An introduction to object segmentation using StarDist library in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 20.7 minutes\n",
            "   Topics: Computer Vision, Python Basics\n",
            "   Key Concepts: 279, the video, stardist library, https github, details\n",
            "\n",
            "36. 308 - An introduction to language models with focus on GPT\n",
            "   Difficulty: beginner\n",
            "   Duration: 26.6 minutes\n",
            "   Topics: Image Processing, Python Basics, Machine Learning\n",
            "   Key Concepts: step, schmidhuber, its practical applications, new tasks, 1997\n",
            "\n",
            "37. 318 - Introduction to Metaheuristic Algorithms​\n",
            "   Difficulty: beginner\n",
            "   Duration: 13.7 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: these algorithms, 318 introduction, the global optimum, the solution space, the solutions\n",
            "\n",
            "38. 327 - An introduction to Single Molecule Fluorescence In Situ Hybridization (smFISH​)\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.4 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Python Basics\n",
            "   Key Concepts: insights, the examination, smfish experimental workflow, the signals, the probes\n",
            "\n",
            "39. 329 - What is Detectron2? An introduction.\n",
            "   Difficulty: beginner\n",
            "   Duration: 23.9 minutes\n",
            "   Topics: Computer Vision, Python Basics\n",
            "   Key Concepts: a variety, detectron2, facebook, 329_detectron2_intro, this video\n",
            "\n",
            "40. 333 - An introduction to YOLO v8​\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.7 minutes\n",
            "   Topics: Computer Vision, Python Basics\n",
            "   Key Concepts: you, 333, object detection, code, key features code\n",
            "\n",
            "41. 92 - Autoencoders using transfer learning - Image colorization\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.2 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: training data, python_for_microscopists, dogs, image colorization, this video\n",
            "\n",
            "42. 89 - Applications of Autoencoders - Domain Adaptation\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.9 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: python_for_microscopists, an image, training, enough training data, this video\n",
            "\n",
            "43. 32 - Grain size analysis in Python using a microscope image\n",
            "   Difficulty: advanced\n",
            "   Duration: 41.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: grain structure, python_for_microscopists, this video tutorial, consistent repeatable results, a csv file\n",
            "\n",
            "44. Python tips and tricks - 4: Best free software for image visualization and processing\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.1 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: tricks, https, imagej net fiji, image visualization, lite https\n",
            "\n",
            "45. 51 - Image Segmentation using K-means\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.3 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: 51 image segmentation, you, images, 51, it\n",
            "\n",
            "46. 305 - What is Cellpose algorithm for segmentation?\n",
            "   Difficulty: beginner\n",
            "   Duration: 30.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: google colab, 305, model retraining, cellular segmentation, https www\n",
            "\n",
            "47. 294 - Denoising 3D multi-channel scientific images using Noise2Void deep learning approach\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.4 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: the need, you, 294_n2v_2d_multi_ch_czi, 294_n2v_3d_multi_ch_czi, https www zeiss\n",
            "\n",
            "48. Book Review - Machine Learning in Biotechnology and Life Sciences\n",
            "   Difficulty: intermediate\n",
            "   Duration: 4.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: biotechnology, amazon https, sciences, life, the book\n",
            "\n",
            "49. 205 - U-Net plus watershed for instance segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: objects, you, the video, images, apeer\n",
            "\n",
            "50. 207 - Using IoU (Jaccard) as loss function to train U-Net for semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: semantic segmentation code, you, the video, images, 207\n",
            "\n",
            "51. 22 - Denoising microscope images in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: Image Processing, Data Analysis, Python Basics\n",
            "   Key Concepts: python_for_microscopists, speed, this video, algorithms, libraries\n",
            "\n",
            "52. 104 - Ridge Filters to detect tube like structures in images\n",
            "   Difficulty: advanced\n",
            "   Duration: 5.4 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: neurons, python_for_microscopists, these filters, structures, this video\n",
            "\n",
            "53. 304 - Augmentation of histology images​ to train stain-agnostic deep learning models\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.7 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: histology images, 2206 12694, randstainna, 20of, randomness\n",
            "\n",
            "54. 171 - AutoKeras for image classification using cifar10 data set\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: 171 autokeras, the use, the video, 171, hyperparameters\n",
            "\n",
            "55. 121 - Image registration using pystackreg library in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.3 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, registration, 4 affine, 121 image registration, this\n",
            "\n",
            "56. 204 - U-Net for semantic segmentation of mitochondria\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.6 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: you, the video, mitochondria code, images, semantic segmentation\n",
            "\n",
            "57. 330 - Fine tuning Detectron2 for instance segmentation using custom data\n",
            "   Difficulty: advanced\n",
            "   Duration: 50.4 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Machine Learning\n",
            "   Key Concepts: you, detectron2, https www, 330_detectron2_instance_3d_em_platelet ipynb, 68yclbraqq1diza\n",
            "\n",
            "58. 170 - AutoKeras for structured data classification using the Wisconsin breast cancer data set\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the use, the video, wisconsin, hyperparameters, keras\n",
            "\n",
            "59. 303 - Reinhard color transformation​\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: pdf code, 303, https www, this, e2\n",
            "\n",
            "60. Python tips and tricks - 3: Be conservative with image augmentation\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: your model accuracy, you, a smaller dataset, 3, tricks\n",
            "\n",
            "61. 43 - What is machine learning anyway?\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.4 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: python_for_microscopists, the code, absolute beginners, this video, what\n",
            "\n",
            "62. 71 - Malarial cell classification using CNN\n",
            "   Difficulty: advanced\n",
            "   Duration: 49.2 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: the dataset, python_for_microscopists, this video, the national library, iarunava cell images\n",
            "\n",
            "63. 33 - Grain size analysis in Python using watershed\n",
            "   Difficulty: advanced\n",
            "   Duration: 38.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: previous video, pixel values, python_for_microscopists, 33, a microscope image\n",
            "\n",
            "64. 34 - Grain size analysis in Python using watershed - multiple images\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, python_for_microscopists, 34, this video, a directory\n",
            "\n",
            "65. Labeling images using LabKit for semantic segmentation\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.8 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 29, labeling images, semantic segmentation part, labkit\n",
            "\n",
            "66. 7 best machine learning books in 2022\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.5 minutes\n",
            "   Topics: Computer Vision, Machine Learning\n",
            "   Key Concepts: computer vision, artificial intelligence, deep learning, books, fourth\n",
            "\n",
            "67. 57 - How to generate features in Python for machine learning?\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: you, python_for_microscopists, 57, the data, machine learning\n",
            "\n",
            "68. 55 - How to read proprietary microscope images into Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, czi, python_for_microscopists, this, this video\n",
            "\n",
            "69. 206 - The right way to segment large images by applying a trained U-Net model on smaller patches\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.0 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: you, apeer, https www, 206, this point\n",
            "\n",
            "70. 265 - Feature engineering or deep learning (for semantic segmentation)\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.0 minutes\n",
            "   Topics: Computer Vision, Machine Learning\n",
            "   Key Concepts: semantic segmentation code, a better approach, classification, the video, deep learning\n",
            "\n",
            "71. 78 - Image Segmentation using U-Net - Part 6 (Running the code and understanding results)\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: results, python_for_microscopists, net part, this, number\n",
            "\n",
            "72. 288 - Nuclei segmentation using StarDist and tracking using Trackpy in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: you, conda environment, this video, 288_nuclei_tracking_trackpy_stardist, conda\n",
            "\n",
            "73. Tips Tricks 16 - How much memory to train a DL model on large images\n",
            "   Difficulty: beginner\n",
            "   Duration: 16.8 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: a dl model, the video, tips, rough calculation, large images\n",
            "\n",
            "74. 280 - Custom object segmentation using StarDist library in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, this approach, the video, this video tutorial, stardist library\n",
            "\n",
            "75. 259 - Semi-supervised learning with GANs - in keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.2 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: you, essence, the discriminator, an excellent classifier, https arxiv\n",
            "\n",
            "76. 76 - Image Segmentation using U-Net - Part 4 (Model fitting, checkpoints, and callbacks)\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, keras, training, net part, each epoch\n",
            "\n",
            "77. 249 - keras implementation of Conditional GAN (cifar10 data set)\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: cyclegan transform images, blurry areas text, the latent space, the resolution, both the generator\n",
            "\n",
            "78. 141 - Regression using Neural Networks and comparison to other models\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, neural networks, 141, comparison, https github\n",
            "\n",
            "79. 23 - Histogram based image segmentation in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: a sample, the information, python_for_microscopists, other words, image segmentation\n",
            "\n",
            "80. 215 - 3D U-Net for semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 50.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, apeer, this dataset, this video\n",
            "\n",
            "81. 292 - Denoising images using deep learning (Noise2Void)​\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.9 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: the need, you, https www zeiss, noise, a structure\n",
            "\n",
            "82. 139 - The topology of deep neural networks, designing your model.\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: deep neural networks, the video, 139, https github, 139 the topology\n",
            "\n",
            "83. 128 - Malarial cell classification using CNN and data augmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.9 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: the video, cell images, link https, 128, malaria\n",
            "\n",
            "84. 337 - Whole Slide Image segmentation for nuclei​ using Detectron2 and YOLOv8\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.5 minutes\n",
            "   Topics: Image Processing, Data Structures, Computer Vision\n",
            "   Key Concepts: svs extensions, these trained models, detectron2, e2, here https openslide\n",
            "\n",
            "85. Feature engineering vs Feature Learning (tips tricks 46 )\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.7 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: representation learning, pre trained networks, domain expertise, 46 code, this\n",
            "\n",
            "86. 246 - Training a keras model by enumerating epochs and batches\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 246, the video, epochs, 246 training, a keras model\n",
            "\n",
            "87. 321 - What is Particle Swarm Optimization PSO?\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Machine Learning\n",
            "   Key Concepts: new regions, cell classification, exploitation, the collective influence, signal processing pso\n",
            "\n",
            "88. 307 - Segment your images in python without training using Segment Anything Model (SAM)\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.9 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 20python, training, trained models, 20images, this video\n",
            "\n",
            "89. 297 - Converting keras trained model to ONNX format​ - Semantic Segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.9 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: simple_unet_model, you, 20to, https www, 256x256\n",
            "\n",
            "90. 54 - Unsupervised and supervised machine learning  - a reminder\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: a reminder, the name, python_for_microscopists, the user, the algorithm\n",
            "\n",
            "91. Book Review - Machine Learning with scikit-learn and scientific python toolkits\n",
            "   Difficulty: beginner\n",
            "   Duration: 4.3 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: ref, scikit, https www, cm_sw_r_tw_dp_p34rz4xb5cy0snpb0t5s\n",
            "\n",
            "92. 184 - Scheduling learning rate in keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 184, keras code, the video, https github\n",
            "\n",
            "93. 74 - Image Segmentation using U-Net - Part 2 (Defining U-Net in Python using Keras)\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, keras, net part, u, this video\n",
            "\n",
            "94. 35 - Cell Nuclei analysis in Python using watershed segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.4 minutes\n",
            "   Topics: Computer Vision, Bio Applications\n",
            "   Key Concepts: 35, python_for_microscopists, these task, grain segmentation, this video\n",
            "\n",
            "95. 302 - Tuning deep learning hyperparameters​ using GridSearchCV\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 302 tuning, the gridsearchcv instance, python_for_microscopists, the param_grid parameter, a dataset\n",
            "\n",
            "96. 216 - Semantic segmentation using a small dataset for training (& U-Net)\n",
            "   Difficulty: advanced\n",
            "   Duration: 37.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, the video, images, semantic segmentation, code\n",
            "\n",
            "97. 144 - Binary classification using Keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.6 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: keras code, the video, 144 binary classification, 144, link https\n",
            "\n",
            "98. 69 - Image classification using Bag of Visual Words (BOVW)\n",
            "   Difficulty: advanced\n",
            "   Duration: 38.1 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: a classifier, the extracted features, natural language processing, this video, 69\n",
            "\n",
            "99. 281 - Segmenting whole slide images (WSI) for nuclei using StarDist in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.7 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, the video, the segmented nuclei, this video tutorial, stardist\n",
            "\n",
            "100. 154 - Understanding the training and validation loss curves\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, 154, the interpretation, wisconsin, training\n",
            "\n",
            "101. 52 - What is GMM and how to use it for Image segmentation?\n",
            "   Difficulty: beginner\n",
            "   Duration: 29.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, a microscope image, the expectation maximization, this video, the umbrella\n",
            "\n",
            "102. Learn about neural network hyperparameters visually\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: neural network hyperparameters, hyperparameters, visually tips, 33\n",
            "\n",
            "103. 189 - Hyperparameter tuning for dropout, # neurons, batch size, # epochs, and weight constraint\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 189 hyperparameter, weight constraint code, 189, https github\n",
            "\n",
            "104. 317 - HyperParameter Optimization using Genetic algorithms\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.4 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the dataset, the strength, its chemical composition, tensile strengths, their respective yield\n",
            "\n",
            "105. 159b - Pretrained CNN (VGG16 - imagenet) features for semantic segmentation using Random Forest\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, image annotation, apeer, this dataset\n",
            "\n",
            "106. 250 - Image to image translation using Pix2Pix GAN\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the receptive field, the discriminator, an image, a patchgan, https arxiv\n",
            "\n",
            "107. 187 - Hyperparameter tuning for learning rate and momentum\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: momentum code, the video, rate, 187 hyperparameter, 187\n",
            "\n",
            "108. 127 - Data augmentation using keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: keras code, the video, 127 data augmentation, 127, https github\n",
            "\n",
            "109. Annotate Images Like a Pro: Python Image Annotation Tool Demo\n",
            "   Difficulty: advanced\n",
            "   Duration: 54.6 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: you, the following links, czi, multi dimensional images, tiff czi\n",
            "\n",
            "110. 210 - Multiclass U-Net using VGG, ResNet, and Inception as backbones\n",
            "   Difficulty: advanced\n",
            "   Duration: 37.9 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, apeer, this dataset, u\n",
            "\n",
            "111. 143 - Multiclass classification using Keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: keras code, the video, 143 multiclass classification, https github, 143\n",
            "\n",
            "112. 61 - How to create Gabor feature banks for machine learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: based image segmentation, feature banks, images, 61, the tutorial\n",
            "\n",
            "113. 258 - Semi-supervised learning with GANs\n",
            "   Difficulty: advanced\n",
            "   Duration: 34.3 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: you, essence, the discriminator, an excellent classifier, https arxiv\n",
            "\n",
            "114. 169 - Deep Learning made easy with AutoKeras\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: keras, everyone, this video, various models, autokeras\n",
            "\n",
            "115. Python tips and tricks - 10: Loading images and masks in the right order for semantic segmentation\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.8 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: semantic segmentation code, 10, masks, 10 loading images, the video\n",
            "\n",
            "116. 126 - Generative Adversarial Networks (GAN) using keras in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.6 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: pdf code, the discriminator, keras, https www, both the generator\n",
            "\n",
            "117. 267 - Processing whole slide images (as tiles)\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.7 minutes\n",
            "   Topics: Image Processing, Bio Applications, Python Basics\n",
            "   Key Concepts: 0169875, you, 2009, an image pyramid, normalizing histology slides\n",
            "\n",
            "118. 26 - Denoising and edge detection using opencv in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, https github, noise, canny edge detection, this video\n",
            "\n",
            "119. 67 - Image Segmentation using traditional machine learning - Part5 Segmenting Images\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: 67 image segmentation, python_for_microscopists, this, part5, segmenting multiple images\n",
            "\n",
            "120. 179 - Variational autoencoders using keras on MNIST data\n",
            "   Difficulty: advanced\n",
            "   Duration: 34.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 179, keras, 179 variational autoencoders, https github\n",
            "\n",
            "121. 70 - An overview of deep learning and neural networks\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: loss, brief explanation, deep learning, this video tutorial, 70 an overview\n",
            "\n",
            "122. 64 - Image Segmentation using traditional machine learning - Part2 Training RF\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.9 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, this, part2, this video, image segmentation\n",
            "\n",
            "123. 209 - Multiclass semantic segmentation using U-Net: Large images and 3D volumes (slice by slice)\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, slice code, apeer, this dataset\n",
            "\n",
            "124. 66 - Image Segmentation using traditional machine learning - Part4 Pickling Model\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.4 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, an image, this, this video, image segmentation\n",
            "\n",
            "125. 158 - Convolutional filters + Random Forest for image classification.\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: training data, image processing applications, image classification, 158, this video\n",
            "\n",
            "126. 247 - Conditional GANs and their applications\n",
            "   Difficulty: advanced\n",
            "   Duration: 39.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: cyclegan transform images, blurry areas text, the latent space, the resolution, both the generator\n",
            "\n",
            "127. 235 - Pre-training U-net using autoencoders - Part 1 - Autoencoders and visualizing features\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.3 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: a single image, 235, you, the video, python_for_microscopists\n",
            "\n",
            "128. 73 - Image Segmentation using U-Net - Part1 (What is U-net?)\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.2 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: 1505, link, 73, python_for_microscopists, semantic image segmentation\n",
            "\n",
            "129. 227 - Various U-Net models using keras unet collection library - for semantic image segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.1 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, python_for_microscopists, https www, 256x256, yingkaisha keras\n",
            "\n",
            "130. 25 - Reading Images, Splitting Channels, Resizing using openCV in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: Image Processing, Computer Vision, Python Basics\n",
            "   Key Concepts: channels, computer vision, 25, processing microscope images, merge channels\n",
            "\n",
            "131. 200 - Image classification using gray-level co-occurrence matrix (GLCM) features and LGBM classifier\n",
            "   Difficulty: advanced\n",
            "   Duration: 23.4 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: 200 image classification, the video, 200, auto_examples features_detection, https github\n",
            "\n",
            "132. 277 - 3D object segmentation in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.2 minutes\n",
            "   Topics: Computer Vision, Machine Learning\n",
            "   Key Concepts: objects, installation instructions, python_for_microscopists, deep learning, the video\n",
            "\n",
            "133. 67b - Feature based image segmentation using traditional machine learning. (Multi-training images)\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, this dataset, this video, multiclass semantic segmentation, segmenting images\n",
            "\n",
            "134. 116 - Measuring properties of labeled / segmented regions\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: labeled segmented regions, the video, images, 116, properties\n",
            "\n",
            "135. My review of the 'Automated Machine Learning with AutoKeras' book\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 1, accessible dp, automated machine, sr_1_2 dchild, the automated machine\n",
            "\n",
            "136. 138 - The need for scaling, dropout, and batch normalization in deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: normalization, keras code, dropout, deep learning, 138 the need\n",
            "\n",
            "137. 176 -- Speeding up ML training using PCA - Multiclass image classification example\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.6 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: 176, https github, the video\n",
            "\n",
            "138. 134 - What are Optimizers in deep learning? (Keras & TensorFlow)\n",
            "   Difficulty: advanced\n",
            "   Duration: 8.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 134, deep learning keras, optimizers, what\n",
            "\n",
            "139. 152 - How to visualize convolutional filter outputs in your deep learning model?\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: outputs, convolutional layers, the video, code, convolutional filter outputs\n",
            "\n",
            "140. 94 - Denoising MRI images (also CT & microscopy images)\n",
            "   Difficulty: advanced\n",
            "   Duration: 43.4 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: 3d filtering bm3d, 94, 3d, first, mri images\n",
            "\n",
            "141. 290 - Deep Learning based edge detection using HED\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.6 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: october, image prediction, 20hed, these links, prototxt\n",
            "\n",
            "142. Book Review - Deep Learning with fastai Cookbook\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: sr_1_4 dchild, easy dp, 8 4, amazon https, 1800208103\n",
            "\n",
            "143. 159 - Convolutional filters + Random Forest for image segmentation.\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, training data, this dataset, image processing applications\n",
            "\n",
            "144. 142 - Multilabel classification using Keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.4 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: keras code, the video, 142, 142 multilabel classification, https github\n",
            "\n",
            "145. 175 - Speeding up ML training using PCA - Breast cancer data set example\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: ml training, the video, example code, https github, 175\n",
            "\n",
            "146. 260 - Identifying anomaly images using convolutional autoencoders\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.5 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: malariadatasets, the latent space, anomaly images, anomaly, the malarial data\n",
            "\n",
            "147. 213 - Ensemble of networks for improved accuracy in deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: python_for_microscopists, 213 ensemble, this video, https www kaggle, deep learning classification\n",
            "\n",
            "148. What I am reading this week about Machine Learning and AI - 13 August 2021\n",
            "   Difficulty: beginner\n",
            "   Duration: 7.5 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: 1101 2021, gan https arxiv, 07 21260138v1, 2107, 10\n",
            "\n",
            "149. Python tips and tricks - 9: Performing additional tasks during data augmentation in keras\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.6 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: datagen, any rotation, pixel values, 2 plt subplot, data_for_keras_aug\n",
            "\n",
            "150. 276 - Grain segmentation using less than 10 lines of code in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.3 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: installation instructions, the video, 276, the pyclesperanto library, clesperanto pyclesperanto_prototype\n",
            "\n",
            "151. 119 - Sub-pixel image registration in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: accuracy, samuel t thurman, the video, subpixel precision code, images\n",
            "\n",
            "152. 263 - Object localization in images​ using GAP layer\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: 263 object localization, the video, images, https gist, an image\n",
            "\n",
            "153. 130 - Evaluating the deep learning trained model (Keras and TensorFlow)\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, tensorflow code, keras, 130, https github\n",
            "\n",
            "154. 219 - Understanding U-Net architecture and building it from scratch\n",
            "   Difficulty: advanced\n",
            "   Duration: 37.6 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, scratch, functional blocks, https www, u\n",
            "\n",
            "155. 56 - What are features in machine learning?\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.9 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: appropriate features, python_for_microscopists, 56, traditional machine learning, this video\n",
            "\n",
            "156. 46 - Splitting data into training and testing sets for machine learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: you, python_for_microscopists, this, the training data, this video\n",
            "\n",
            "157. 237 - What is Tensorflow Lite and how to convert keras model to tflite?\n",
            "   Difficulty: beginner\n",
            "   Duration: 30.7 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: the cell, tflite dataset, this, the probablility, tensorflow lite\n",
            "\n",
            "158. 336 - Nuclei segmentation and analysis using Detectron2 & YOLOv8​\n",
            "   Difficulty: advanced\n",
            "   Duration: 57.1 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: analysis, the dataset, the entire dataset, yolov8 annotations, 336\n",
            "\n",
            "159. 177 - Semantic segmentation made easy (using segmentation models library)\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.1 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: 1 0, 2, the video, colab execution tensorflow, this demo\n",
            "\n",
            "160. 86 - Applications of Autoencoders - Denoising using MNIST dataset\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: python_for_microscopists, noise reduction, images, autoencoders, mnist dataset denoising\n",
            "\n",
            "161. 272 - Instance segmentation via semantic segmentation by using border class\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.8 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 272 instance segmentation, the video, masks, border class code, images\n",
            "\n",
            "162. 65 - Image Segmentation using traditional machine learning - Part3 Feature Ranking\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, 65, regions, this, 65 image segmentation\n",
            "\n",
            "163. 319 - What is Simulated Annealing Optimization​?\n",
            "   Difficulty: beginner\n",
            "   Duration: 14.3 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: network design problems, many local optima, the global optimum, optimization, 319\n",
            "\n",
            "164. 158b - Transfer learning using CNN (VGG16) as feature extractor and Random Forest classifier\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, pretrained weights vgg16, random forest classifier, 158b transfer learning, https github\n",
            "\n",
            "165. 322 - PSO Using steel optimization\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.6 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Machine Learning\n",
            "   Key Concepts: the strength, its chemical composition, new regions, exploitation, cell classification\n",
            "\n",
            "166. 188 - Hyperparameter tuning for activation function, optimizer and weight initialization\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 188, https github, the video\n",
            "\n",
            "167. 93 - Do not waste your time with deep learning (updated)\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.0 minutes\n",
            "   Topics: Image Processing, Data Analysis, Machine Learning\n",
            "   Key Concepts: traditional filters, image denoising, their image, you, better results\n",
            "\n",
            "168. 120 - Image registration methods in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.4 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: 4 different ways, 120, python_for_microscopists, images, https github\n",
            "\n",
            "169. 136 understanding deep learning parameters batch size\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, size code, 136, https github, deep learning parameters\n",
            "\n",
            "170. 90 - Application of Autoencoders - Image colorization\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: 90 application, python_for_microscopists, this process, images, 90\n",
            "\n",
            "171. 233 - Semantic Segmentation of BraTS2020 - Part 2 - Defining your custom data generator\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.3 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: python_for_microscopists, 3 label, https www, nifti files, brats20\n",
            "\n",
            "172. 75 - Image Segmentation using U-Net - Part 3 (What are trainable parameters?)\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.8 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: trainable parameters, 3, python_for_microscopists, 75, biases\n",
            "\n",
            "173. 211 - U-Net vs LinkNet for multiclass semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.9 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: 1505, the dataset, you, 1707, apeer\n",
            "\n",
            "174. Tips Tricks 20 - Understanding transfer learning for different size and channel inputs\n",
            "   Difficulty: beginner\n",
            "   Duration: 47.5 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the mean, the input, 224x224x3 pixels, the pool size, this\n",
            "\n",
            "175. 214 - Improving semantic segmentation (U-Net) performance via ensemble of multiple trained networks\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.6 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, 214, syjzxdtlujs code, apeer\n",
            "\n",
            "176. Tips Tricks 18 - Extracting faces from images for deep learning training\n",
            "   Difficulty: beginner\n",
            "   Duration: 6.2 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, the video, images, tips, 18\n",
            "\n",
            "177. 286 - Object detection using Mask RCNN: end-to-end from annotation to prediction\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.8 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: you, 20end, 286 object detection, https www, training\n",
            "\n",
            "178. 125 - What are Generative Adversarial Networks (GAN)?\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: pdf code, the discriminator, keras, a quick overview, https www\n",
            "\n",
            "179. 334 - Training custom instance segmentation model using YOLO v8\n",
            "   Difficulty: advanced\n",
            "   Duration: 35.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Machine Learning\n",
            "   Key Concepts: you, scratch, this dataset, https www, multiple classes\n",
            "\n",
            "180. 234 - Semantic Segmentation of BraTS2020 - Part 3 - Training and Prediction\n",
            "   Difficulty: advanced\n",
            "   Duration: 30.7 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: python_for_microscopists, 3 label, https www, 234 semantic segmentation, nifti files\n",
            "\n",
            "181. 133 - What are Loss functions in machine learning?\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.8 minutes\n",
            "   Topics: Python Basics, Machine Learning\n",
            "   Key Concepts: machine learning, 133, what, loss functions\n",
            "\n",
            "182. Python tips and tricks - 7:  Continuing keras model training when using custom loss and metrics\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: my_model load_model, loss, no code, the model, 7\n",
            "\n",
            "183. 296 - Converting keras trained model to ONNX format - Image Classification example\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.1 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the keras model, multiclass classification, 2 4 4, the onnx model, 2\n",
            "\n",
            "184. Generating borders around objects for use in semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.0 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: objects, semantic segmentation tips, another class, the advantage, 31\n",
            "\n",
            "185. 77 - Image Segmentation using U-Net - Part 5 (Understanding the data)\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, net part, u, this video, the images\n",
            "\n",
            "186. Lung cancer subclassification using fastai​ (Tips Tricks 22)\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.8 minutes\n",
            "   Topics: Image Processing, Bio Applications, Machine Learning\n",
            "   Key Concepts: size, the dataset, benign lung tissues, two subfolders colon_image_sets, fastai tips\n",
            "\n",
            "187. 274 - Object segmentation using voronoi and otsu\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.6 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: step, 5 separate objects, the pyclesperanto package, maxima locations, each nuclei\n",
            "\n",
            "188. 291 - Object segmentation using Deep Learning based edge detection (HED)​\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.3 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: october, image prediction, these links, prototxt, connected component\n",
            "\n",
            "189. 131 - How to load a partially trained deep learning model and continue training?\n",
            "   Difficulty: advanced\n",
            "   Duration: 5.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 131, https github, the video, training code\n",
            "\n",
            "190. 63 - Image Segmentation using traditional machine learning Part1 - FeatureExtraction\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.9 minutes\n",
            "   Topics: Image Processing, Computer Vision, Data Analysis, Machine Learning\n",
            "   Key Concepts: you, python_for_microscopists, this, this video, image segmentation\n",
            "\n",
            "191. 230 - Semantic Segmentation of Landcover Dataset using U-Net\n",
            "   Difficulty: advanced\n",
            "   Duration: 45.9 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, python_for_microscopists, https landcover, 230 semantic segmentation, unlabeled pixels\n",
            "\n",
            "192. You want to be a machine learning engineer, now what?\n",
            "   Difficulty: beginner\n",
            "   Duration: 6.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: those, you, career tips\n",
            "\n",
            "193. 185 - Hyperparameter tuning using GridSearchCV\n",
            "   Difficulty: advanced\n",
            "   Duration: 4.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 185, the video, 185 hyperparameter tuning, https github, gridsearchcv code\n",
            "\n",
            "194. 192 - Working with 3D and multi-dimensional images in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, 192, python code, https github, 3d\n",
            "\n",
            "195. 344 Color separation and nuclei segmentation in cores extracted from TMA\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Machine Learning\n",
            "   Key Concepts: tma, analysis, you, 344 tma, the analysis part\n",
            "\n",
            "196. 17 - Reading images in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 55.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: standard images, python_for_microscopists, images, image reading, 17\n",
            "\n",
            "197. Installing napari library in python for scientific image visualization - Tips and Tricks 39\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: napari library, you, a walkthrough tutorial, 39, https napari\n",
            "\n",
            "198. What I am reading this week about Machine Learning and AI - 23 July 2021\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 18 july 2021, 021 10, 2101, 2103, 19\n",
            "\n",
            "199. 261 - What is global average pooling in deep learning?\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the video, deep learning, 261, an image code, it\n",
            "\n",
            "200. Tips Tricks 25 - Locating objects in large images using template matching\n",
            "   Difficulty: intermediate\n",
            "   Duration: 13.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 25, tips_tricks_25_locating_objects_in_large_images_via_template_matching, template matching opencv, tips, python code\n",
            "\n",
            "201. 208 - Multiclass semantic segmentation using U-Net\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.3 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, you, the video, images, usp\n",
            "\n",
            "202. 293  - Denoising RGB images using deep learning (Noise2Void)\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.0 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the need, you, 293, example sem, ct images\n",
            "\n",
            "203. 212 - Classification of mnist sign language alphabets using deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: 25, deep learning classification, a wave motion, the video, python_for_microscopists\n",
            "\n",
            "204. 320 - Understanding Simulated Annealing​ using steel optimization\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the strength, its chemical composition, tensile strengths, maximum yield strength, their respective yield\n",
            "\n",
            "205. 186 - A note about parallelization during hyperparameter search using GridSearchCV\n",
            "   Difficulty: advanced\n",
            "   Duration: 5.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 186 a note, hyperparameter search, parallelization, the video, 186\n",
            "\n",
            "206. 148 - 7 techniques to work with imbalanced data for machine learning in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 36.7 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: sklearn metrics, appropriate weights, 6, logistic regression, learning algorithms\n",
            "\n",
            "207. Tips Tricks 14 - EasyOCR for text detection in images (using python)\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, images, tips, 14 easyocr, python code\n",
            "\n",
            "208. Python tips and tricks - 5: Extracting patches from large images and masks for semantic segmentation\n",
            "   Difficulty: beginner\n",
            "   Duration: 7.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: masks, tricks, https github, large images, my github\n",
            "\n",
            "209. 10 best annotation tools for computer vision​ applications\n",
            "   Difficulty: beginner\n",
            "   Duration: 13.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 34, www makesense, https www, 6, 9\n",
            "\n",
            "210. 195 - Image classification using XGBoost and VGG16 imagenet as feature extractor\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.2 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the video, 195 image classification, feature extractor code, latest video, 195\n",
            "\n",
            "211. 21 - Scratch assay analysis with just 5 lines code in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: analysis, cell filled regions, python_for_microscopists, 21 scratch, 21\n",
            "\n",
            "212. 289 - 3D object tracking using trackpy in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: you, conda environment, 3d objects, this video, 289 3d\n",
            "\n",
            "213. 245 - Advantages of keras functional API in defining complex models\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 245 advantages, functional api, keras, 245\n",
            "\n",
            "214. Annotate Images Like a Pro: Python Image Annotation Tool Walkthrough\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.1 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: you, the python library, the following links, czi, multi dimensional images\n",
            "\n",
            "215. 300 - Picking the best model and corresponding hyperparameters using Gridsearch\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the gridsearchcv instance, a gridsearch, 10 50, a dataset, a grid\n",
            "\n",
            "216. 332 - All about image annotations​\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.6 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: objects, a dictionary, you, metadata, contours\n",
            "\n",
            "217. 132 - What are Activation functions in deep learning (Keras & Tensorflow)?\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.1 minutes\n",
            "   Topics: Python Basics, Machine Learning\n",
            "   Key Concepts: 132, activation functions, deep learning keras, what\n",
            "\n",
            "218. 224 - Recurrent and Residual U-net\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.1 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the layers, time steps, the input, an image, the idea\n",
            "\n",
            "219. 58 - What are Gabor filters?\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: you, segmentation gabor, python_for_microscopists, texture orientation, regions\n",
            "\n",
            "220. 117 - Shading correction using rolling ball background subtraction\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: these images, the video, 117, other images, clahe\n",
            "\n",
            "221. 85a - What are Autoencoders and what are they used for?\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.9 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: python_for_microscopists, g images, image colorization, this video, anomaly detection\n",
            "\n",
            "222. 236 - Pre-training U-net using autoencoders - Part 2 - Generating encoder weights for U-net\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 2, you, the video, python_for_microscopists, autoencoders\n",
            "\n",
            "223. 346 - 3D Sholl Analysis Using Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the soma, each distance, 20analysis video, 3d sholl analysis, simpler terms\n",
            "\n",
            "224. 19 - image processing using scipy in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 27.2 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: python_for_microscopists, scipy, numpy stack, scipy library, this video\n",
            "\n",
            "225. 87 - Applications of Autoencoders - Denoising using custom images\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: python_for_microscopists, your own images, images, autoencoders, 87 applications\n",
            "\n",
            "226. 350 - Efficient Image Retrieval with Vision Transformer (ViT) and FAISS\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.9 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: metadata, a query image, similar images, speed, fast similarity search\n",
            "\n",
            "227. 256 - Super resolution GAN (SRGAN) in keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: keras code, the video, 1609, https arxiv, 04802 pdf dataset\n",
            "\n",
            "228. 343 De-arraying Tissue Microarrays (TMA) using Qupath and python code\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Image Processing, Data Structures, Bio Applications\n",
            "   Key Concepts: tma, you, 20and, individual cores, the locations\n",
            "\n",
            "229. 328 - smFISH Analysis using Big FISH library in python​\n",
            "   Difficulty: advanced\n",
            "   Duration: 49.8 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications, Python Basics\n",
            "   Key Concepts: the cell, you, this, a higher concentration, the extracted features\n",
            "\n",
            "230. 68b - SVM vs. Random Forest for image segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: both approaches, results, data image analysis, a previous tutorial, image segmentation purposes\n",
            "\n",
            "231. Exploring Metadata in Scientific Images\n",
            "   Difficulty: advanced\n",
            "   Duration: 43.3 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: results, metadata, you, a detailed history, czi\n",
            "\n",
            "232. 190 - Finding the best model between Random Forest & SVM via hyperparameter tuning\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: hyperparameter tuning code, the video, 190, https github, random forest svm\n",
            "\n",
            "233. 16 - Understanding digital images for Python processing\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.5 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: numpy array manipulation, their data types, images, a quick overview, python\n",
            "\n",
            "234. 122 - Normalizing H&E images and digitally separating Hematoxylin and Eosin components\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.4 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: 0169875, 2009, digitally separate images, normalizing histology slides, a pathologist\n",
            "\n",
            "235. 335 - Converting COCO JSON annotations to labeled mask images\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.6 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: the dataset, you, respective images, this license, the instructions\n",
            "\n",
            "236. 118 - Object detection by template matching\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.1 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: objects, the same scale, the video, the template image, an image\n",
            "\n",
            "237. How to get started with Data Science and Machine Learning​\n",
            "   Difficulty: intermediate\n",
            "   Duration: 21.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: you, deep learning, data science, the difference, machine\n",
            "\n",
            "238. 268 - How to deploy your trained machine learning model into a local web application?\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.2 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, your scikit, a web application, the process, flask\n",
            "\n",
            "239. 262 - Localizing anomalies in images\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.4 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: the video, images, malariadatasets html code, bad images, 262 localizing anomalies\n",
            "\n",
            "240. 28 - Thresholding and morphological operations using openCV in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: erosion dilation, python_for_microscopists, morphological operators, noise, this video\n",
            "\n",
            "241. 223 - Test time augmentation for semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: semantic segmentation code, the video, prediction time augmentation, augmented images, 223\n",
            "\n",
            "242. 340 - Comparing Top Large Language Models for Python Code Generation\n",
            "   Difficulty: advanced\n",
            "   Duration: 38.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: the need, 405, many prompts, ai, didn t\n",
            "\n",
            "243. 257 - Exploring GAN latent space to generate images with desired features​\n",
            "   Difficulty: advanced\n",
            "   Duration: 39.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: gan latent space, you, the latent space, that category, 10s\n",
            "\n",
            "244. 285 - Object detection using Mask RCNN (with XML annotated data)\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, https www, 285 object detection, 284, this video\n",
            "\n",
            "245. 316  - Optimizing Steel Strength using Metaheuristic algorithms (e.g., Genetic)\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the differential evolution, the strength, its chemical composition, tensile strengths, a few differences\n",
            "\n",
            "246. 225 - Attention U-net. What is attention and why is it needed for U-Net?\n",
            "   Difficulty: beginner\n",
            "   Duration: 14.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: relevant parts, an image, less relevant parts, training, this\n",
            "\n",
            "247. 18 - Image processing using pillow in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 31.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: 18 image processing, python_for_microscopists, multiple images, a few examples, pillow library\n",
            "\n",
            "248. Tips Tricks 21 - Understanding the keras-trained model saved as hdf5 (or h5)\n",
            "   Difficulty: intermediate\n",
            "   Duration: 22.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: tips, h5, 21, https www, the process\n",
            "\n",
            "249. 191 - Measuring image similarity in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, image similarity, images, ssim code, python\n",
            "\n",
            "250. 202 - Two ways to read HAM10000 dataset into python for skin cancer lesion classification\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.7 minutes\n",
            "   Topics: Bio Applications, Machine Learning\n",
            "   Key Concepts: the video, melanoma mel, description https arxiv, https github, 202 two\n",
            "\n",
            "251. 88 - Applications of Autoencoders - Anomaly Detection\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.6 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: python_for_microscopists, the acceptable error, this video, anomaly detection, 88\n",
            "\n",
            "252. 62 - Image Segmentation using traditional machine learning - The plan\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: a folder dataset, the plan, 62 image segmentation, segmenting multiple images, image segmentation\n",
            "\n",
            "253. 60 - How to use Random Forest in Python?\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.3 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, https github, the implementation, the upcoming videos, the code\n",
            "\n",
            "254. 254 - Unpaired image to image translation​ using cycleGAN in keras\n",
            "   Difficulty: advanced\n",
            "   Duration: 38.5 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: keras code, the video, 1703 10593, https arxiv, taesung_park\n",
            "\n",
            "255. 153 - Artificial Neural Networks - Explanation for those who understand linear regression\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: those, heart disease data, you, results, the video\n",
            "\n",
            "256. 101 - What is block matching and 3D filtering (BM3D)?\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: electronic components, python_for_microscopists, sensors, 3d filtering bm3d, noise\n",
            "\n",
            "257. 275 - Object segmentation and analysis using voronoi otsu labeling\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: analysis, 275, czi, the pyclesperanto package, this\n",
            "\n",
            "258. 306 - Content based image retrieval​ via feature extraction in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, resnet50, 20image, a match score, this video\n",
            "\n",
            "259. 197 - Light GBM vs XGBoost for semantic image segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.1 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the dataset, this dataset, this video, multiclass semantic segmentation, usp\n",
            "\n",
            "260. 167 - Text prediction using LSTM (English text)\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, english, 236, them, https www\n",
            "\n",
            "261. 341 - Sholl Analysis using python coding\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.8 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: analysis, the soma, regular intervals, an image, neuronal structure\n",
            "\n",
            "262. 30 - Image registration using homography in openCV\n",
            "   Difficulty: advanced\n",
            "   Duration: 46.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: python_for_microscopists, excellent algorithms, homography, image registration, descriptors\n",
            "\n",
            "263. 45 - Linear regression using Sci-Kit Learn in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.3 minutes\n",
            "   Topics: \n",
            "   Key Concepts: python_for_microscopists, 45, this, this video, a follow\n",
            "\n",
            "264. What I am reading this week about Machine Learning and AI - 16 July 2021\n",
            "   Difficulty: beginner\n",
            "   Duration: 5.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the content, io, 2104, https, 18 july 2021\n",
            "\n",
            "265. 301 - Evaluating keras model using KFold cross validation​\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.5 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the dataset, a way, the kerasclassifier, this, tensorflow keras wrappers\n",
            "\n",
            "266. 221 - Easy way to split data on your disk into train, test, and validation?\n",
            "   Difficulty: advanced\n",
            "   Duration: 8.9 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: val test, validation, fixed splitfolders, folders import splitfolders, 8 2\n",
            "\n",
            "267. Labeling images using QuPath for semantic segmentation\n",
            "   Difficulty: intermediate\n",
            "   Duration: 10.8 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: labeling images, extras, the groovy script, 28, https qupath github\n",
            "\n",
            "268. 248 - keras implementation of GAN to generate cifar10 images\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: gan, 248, the video, 248 keras implementation, cifar10\n",
            "\n",
            "269. 232 - Semantic Segmentation of BraTS2020 - Part 1 - Getting the data ready\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.6 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis, Computer Vision\n",
            "   Key Concepts: the dataset, real labeled volumes, python_for_microscopists, a weird name, step\n",
            "\n",
            "270. 252 - Generating realistic looking scientific images using pix2pix GAN\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, the dataset folder, https github, pix2pix gan code, 1hwtbasa\n",
            "\n",
            "271. 95 - What is digital image filtering and image convolution?\n",
            "   Difficulty: beginner\n",
            "   Duration: 24.3 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, this video, the convolution, the implementation, 95\n",
            "\n",
            "272. 331 - Fine-tune Segment Anything Model (SAM) using custom data\n",
            "   Difficulty: advanced\n",
            "   Duration: 44.1 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: objects, the need, you, 331_fine_tune_sam_mito ipynb, the ambiguity\n",
            "\n",
            "273. Labeling images for semantic segmentation using Label Studio\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.1 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, python_for_microscopists, your browser, io, python version\n",
            "\n",
            "274. 240 - Deep Learning training for age and gender detection\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, windows, https susanqq github, 240, deep learning models\n",
            "\n",
            "275. 93 - Do not waste your time with deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.0 minutes\n",
            "   Topics: Image Processing, Data Analysis, Machine Learning\n",
            "   Key Concepts: you, this, 100s 1000s, better results, anisotropic diffusion\n",
            "\n",
            "276. 194 - Semantic segmentation using XGBoost and VGG16 imagenet as feature extractor\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Machine Learning\n",
            "   Key Concepts: the link, the dataset, xgboost readthedocs io, the video, usp\n",
            "\n",
            "277. 172 - Top k accuracy for multiclass machine learning classification\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: multiclass machine, the video, the network code, the correct label, 172\n",
            "\n",
            "278. 228 - Semantic segmentation of aerial (satellite) imagery using U-net\n",
            "   Difficulty: advanced\n",
            "   Duration: 42.0 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis, Computer Vision\n",
            "   Key Concepts: the dataset, 6 larger tiles, the total volume, python_for_microscopists, a u\n",
            "\n",
            "279. White balancing your pictures using python\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: white, two different approaches, 45, algorithm, this video\n",
            "\n",
            "280. 155 - How many hidden layers and neurons do you need in your artificial neural network?\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: neurons, you, number, this, the number\n",
            "\n",
            "281. 182 - How to batch process multiple images in python?\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, python code, process multiple images, https github, 182\n",
            "\n",
            "282. 23b - Image segmentation using color spaces​ - in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, blue marbles, color spaces, an image, marbles\n",
            "\n",
            "283. 52b - Understanding Gaussian Mixture Model (GMM) using 1D, 2D, and 3D examples\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.4 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, the video, gmm, be kkairywakmk, 1d 2d\n",
            "\n",
            "284. 173 - Intersection over Union (IoU) for semantic segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.9 minutes\n",
            "   Topics: Computer Vision, Machine Learning\n",
            "   Key Concepts: semantic segmentation code, the dataset, the video, this dataset, 1hwtbasa\n",
            "\n",
            "285. 160 - When to retrain your ML model and what is the best way to re-train?\n",
            "   Difficulty: beginner\n",
            "   Duration: 24.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the best way, the video, link https www, data data, what\n",
            "\n",
            "286. 24 - Random Walker segmentation in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: an alloy, many cases, python_for_microscopists, random walker segmentation, this video\n",
            "\n",
            "287. 239 - Deep Learning training for facial emotion detection\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.6 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, windows, 239, https www kaggle, https github\n",
            "\n",
            "288. 49 - Logistic Regression using scikit-learn in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 38.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: logistic regression, python_for_microscopists, 49, 49 logistic regression, library\n",
            "\n",
            "289. 203 - Skin cancer lesion classification using the HAM10000 dataset\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.7 minutes\n",
            "   Topics: Bio Applications, Machine Learning\n",
            "   Key Concepts: the video, melanoma mel, description https arxiv, 1803 1803 10417, this dataset\n",
            "\n",
            "290. 287 - Tracking particles and objects using Trackpy in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.0 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: objects, conda environment, 287, 287_tracking_particles_using_trackpy, miniconda\n",
            "\n",
            "291. 115 - Auto segmentation using multi-otsu\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.7 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, chung p c, 727 2001, the number, image segmentation\n",
            "\n",
            "292. 83 - Running your Docker in the cloud\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.1 minutes\n",
            "   Topics: Image Processing, Bio Applications, Python Basics\n",
            "   Key Concepts: you, python_for_microscopists, 83, www apeer, course\n",
            "\n",
            "293. 145 - Confusion matrix,  ROC and AUC in machine learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.0 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: roc, the video, 145, machine learning code, https github\n",
            "\n",
            "294. 84 - How to build a Docker (module) with your code and run it on APEER?\n",
            "   Difficulty: advanced\n",
            "   Duration: 42.3 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: you, python_for_microscopists, some basic understanding, apeer, scratch\n",
            "\n",
            "295. 174  - What is PCA and how to use it to speed up machine learning training\n",
            "   Difficulty: beginner\n",
            "   Duration: 8.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, it, what, https github, 174\n",
            "\n",
            "296. Tips Tricks 26 - How to properly convert 16 bit to 8 bit images in python\n",
            "   Difficulty: intermediate\n",
            "   Duration: 13.0 minutes\n",
            "   Topics: Image Processing, Computer Vision, Data Analysis\n",
            "   Key Concepts: the video, 8, uint8, tips, 26\n",
            "\n",
            "297. 99 - What is Non-local means (NLM) denoising filter?\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.5 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: electronic components, python_for_microscopists, sensors, many sources, filter noise\n",
            "\n",
            "298. 183 - OCR in python using keras-ocr\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 183, io, ocr, keras\n",
            "\n",
            "299. 146 - Raspberry Pi - Learning python and deep learning on a tight budget\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.4 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the western world, other regions, google colaboratory, deep learning, 146 raspberry pi\n",
            "\n",
            "300. Interpolation for resizing 3D volumetric data (Tips and Tricks 50)\n",
            "   Difficulty: beginner\n",
            "   Duration: 14.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: this video, specific pixel sizes, 50 interpolation, 3d, platelet em\n",
            "\n",
            "301. Extracting a Targeted Subset from a COCO JSON annotated dataset\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: rapid testing, you, this video tutorial, 53, coco json annotations\n",
            "\n",
            "302. 150 - Warning about keras' data augmentation when working with categorical labels\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.0 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis\n",
            "   Key Concepts: suggestions, you, keras, this, this video\n",
            "\n",
            "303. 137 - What is one hot encoding in machine learning?\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.3 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, one hot encoding, one, 137, machine learning code\n",
            "\n",
            "304. 222 - Working with large data that doesn't fit your system memory - Semantic Segmentation\n",
            "   Difficulty: advanced\n",
            "   Duration: 45.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, folders, doesn t, https www, pip install\n",
            "\n",
            "305. 96 - What is Gaussian Denoising Filter?\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: lines, electronic components, you, python_for_microscopists, sensors\n",
            "\n",
            "306. 29 - Key points, detectors and descriptors in openCV\n",
            "   Difficulty: advanced\n",
            "   Duration: 30.4 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: image processing tasks, python_for_microscopists, registration, an image, these algorithms\n",
            "\n",
            "307. 123 - Reference based image quality metrics\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, sewar, 123, this video, https github\n",
            "\n",
            "308. 342 Sholl Analysis: Aggregating Sholl Profiles from Multiple Soma\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: neurons, sholl analysis, the same set, didn t, this\n",
            "\n",
            "309. 5 things to check before applying for your first machine learning job\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.0 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: first, 5 things, 5\n",
            "\n",
            "310. 47 - Multiple Linear Regression with SciKit-Learn in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.3 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: python_for_microscopists, this video, the dependent variable, the response, multiple dependent variables\n",
            "\n",
            "311. 11 - numpy arrays\n",
            "   Difficulty: beginner\n",
            "   Duration: 41.5 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis\n",
            "   Key Concepts: you, an image, that image, 11, the array values\n",
            "\n",
            "312. 311 - Fine tuning GPT2 using custom documents​\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: q, the video, https github, gpt2, 311\n",
            "\n",
            "313. 339 - Surrogate Optimization explained using simple python code\n",
            "   Difficulty: advanced\n",
            "   Duration: 31.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: sa surrogate optimization, this video, traditional metaheuristic approaches, other optimization techniques, ipynb video number\n",
            "\n",
            "314. 53  - How to pick optimal number of parameters for your unsupervised machine learning model?\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.7 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the use, optimal number, you, gmm, python_for_microscopists\n",
            "\n",
            "315. 229 - Smooth blending of patches for semantic segmentation of large images (using U-Net)\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.6 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python_for_microscopists, segmenting patches, a large image, smooth blending, 229 smooth blending\n",
            "\n",
            "316. 168 - Text prediction using LSTM - Non-English example using Hindi and Telugu letters.\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, english, them, hindi, 168\n",
            "\n",
            "317. 114 - Automatic image quality assessment using BRISQUE\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: python_for_microscopists, an image, the distorted images, 21, python mittal\n",
            "\n",
            "318. 180 - LSTM Autoencoder for anomaly detection\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 180 lstm autoencoder, the autoencoder, the video, 180, anomaly code\n",
            "\n",
            "319. Color segmentation of images ​followed by text removal​ in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.0 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: rgb image, color segmentation, the traffic sign, 43, text removal\n",
            "\n",
            "320. Python tips and tricks - 2: Downloading images from online search\n",
            "   Difficulty: beginner\n",
            "   Duration: 6.8 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: you, a limit, copyright terms, google_images_download, this\n",
            "\n",
            "321. Overlaying images for easy comparison (in python)\n",
            "   Difficulty: intermediate\n",
            "   Duration: 1.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, tips_tricks_48_overlay_image_comparison, tips_tricks_48_overlay_image_comparison ipynb, 48, easy comparison\n",
            "\n",
            "322. 129 - What are Callbacks, Checkpoints and Early Stopping in deep learning (Keras and TensorFlow)\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, tensorflow code, deep learning keras, what, callbacks checkpoints\n",
            "\n",
            "323. 199 - Detecting straight lines using Hough transform in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, the original image, y axis, hough transform, the detected line\n",
            "\n",
            "324. 27 - CLAHE and Thresholding using opencv in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.5 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: python histogram equalization, python_for_microscopists, images, 27, this video\n",
            "\n",
            "325. Tips Tricks 13 - How to visualize keras models on windows10\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: pydot, windows10 code, the plot_model library, the command prompt, import plot_model plot_model\n",
            "\n",
            "326. 264 - Image outlier detection using alibi-detect\n",
            "   Difficulty: advanced\n",
            "   Duration: 30.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: world_dataset_for_unsupervised_anomaly_cvpr_2019_paper pdf data, the input, alibi, https arxiv, the reconstructed instance\n",
            "\n",
            "327. 140 - What in the world is regression, multi-label, multi-class and binary classification?\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 140, the world, what, binary classification, regression\n",
            "\n",
            "328. Random is not so random - understanding random in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.2 minutes\n",
            "   Topics: Data Analysis, Machine Learning\n",
            "   Key Concepts: algorithm https en, mersenne_twister numpy random, the topic, this, data analysis\n",
            "\n",
            "329. 242 - Real time detection of facial emotion, age, and gender using TensorFlow Lite (on Windows10)\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: windows10 code, 242, trained models, edge devices, optimization\n",
            "\n",
            "330. 31 - A few ways to read and write csv files in Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.3 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: import csv files, results, you, python_for_microscopists, 31\n",
            "\n",
            "331. Loading Kaggle data directly into Google Colab\n",
            "   Difficulty: intermediate\n",
            "   Duration: 10.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 35, the video, kaggle data, google colab code, google colab tips\n",
            "\n",
            "332. Tips Tricks 15 - Understanding Binary Cross-Entropy loss\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 15, the video, tips, a measure, the difference\n",
            "\n",
            "333. 282 -  IHC color separation followed by nuclei segmentation using StarDist in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 10.1 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: analysis, the video, rgb, stardist, 282\n",
            "\n",
            "334. How to remove text from images using python?\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.0 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the ending points, keras, the thickness, a mask, tips_tricks_42_how 20to\n",
            "\n",
            "335. 295 - ONNX – open format for machine learning models​\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.4 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: you, ios, ane, your trained model, coreml coreml\n",
            "\n",
            "336. 149 - Working with imbalanced data for ML - Demonstrated using liver disease data\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: a proper knowledge, 149, imbalanced data, data, the video\n",
            "\n",
            "337. 12 - Python Recap of lists and numpy arrays\n",
            "   Difficulty: beginner\n",
            "   Duration: 16.8 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis\n",
            "   Key Concepts: images, multidimensional lists, lists, numpy arrays, this video\n",
            "\n",
            "338. 270 - How to deploy your trained machine learning model as a web app on Heroku (No Docker)\n",
            "   Difficulty: advanced\n",
            "   Duration: 40.5 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: your heroku account, no docker code, skin cancer type, this video, some useful commands\n",
            "\n",
            "339. 124 - Image quality by estimating sharpness\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: sharpness estimation, jayant kumar, this video, jsessionid 33cd0038a0d2d24ae2c4f1a30b6ef1a4, chen david doermann\n",
            "\n",
            "340. 193 - What is XGBoost and is it really better than Random Forest and Deep Learning?\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.0 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the video, xgboost, https xgboost readthedocs, edu ml, uci\n",
            "\n",
            "341. 299 - Evaluating sklearn model using KFold cross validation​ in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.7 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: the dataset, keras, train test sets, test, training\n",
            "\n",
            "342. 326 - Cell type annotation for single cell RNA seq data​\n",
            "   Difficulty: advanced\n",
            "   Duration: 43.4 minutes\n",
            "   Topics: Image Processing, Bio Applications\n",
            "   Key Concepts: the end result, cell type annotation, all these techniques, https www, the transcriptomes\n",
            "\n",
            "343. 348 - Image Similarity Search with VGG16 and Cosine Distance\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: directions, query vector, the angle, a metric, this\n",
            "\n",
            "344. 151 Warning about JPG files when working with categorical labels\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.5 minutes\n",
            "   Topics: Image Processing, Computer Vision, Bio Applications\n",
            "   Key Concepts: 151, quick email exchanges, this video, jpg compression jpg, social media sharing\n",
            "\n",
            "345. 50 - What is k-means clustering and how to code it in Python?\n",
            "   Difficulty: beginner\n",
            "   Duration: 16.9 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: you, python_for_microscopists, this video tutorial, the basics, 50\n",
            "\n",
            "346. 338 - Understanding the Benford's Law of Probability\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.9 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: you, pixel values, the pain, the leading digits, case\n",
            "\n",
            "347. 226 - U-Net vs Attention U-Net vs Attention Residual U-Net - should you care?\n",
            "   Difficulty: advanced\n",
            "   Duration: 27.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, the video, python_for_microscopists, masks, code\n",
            "\n",
            "348. 198 - Feature selection using Boruta in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 16.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 198 feature selection, https xgboost readthedocs, edu ml, https pypi org\n",
            "\n",
            "349. 97 - What is median denoising filter?\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: electronic components, python_for_microscopists, sensors, many sources, this video\n",
            "\n",
            "350. 112 - Averaging image stack in real and DCT space for denoising\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.5 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: respect, similar results, the information, python_for_microscopists, this video\n",
            "\n",
            "351. 98 - What is bilateral denoising filter?\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: electronic components, python_for_microscopists, sensors, many sources, bilateral filter\n",
            "\n",
            "352. 241 - Real time detection of facial emotion, age, and gender (using video feed from a webcam)\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: gender, the video, a webcam code, live prediction, emotion age\n",
            "\n",
            "353. 196 - What is Light GBM and how does it compare against XGBoost?\n",
            "   Difficulty: beginner\n",
            "   Duration: 19.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 196, uci, it, what\n",
            "\n",
            "354. 271 - How to deploy your trained machine learning model as a web app on Heroku (with docker)\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.6 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: docker image, your heroku account, e g docker, an image, skin cancer type\n",
            "\n",
            "355. 244 - What are embedding layers in keras?\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the input array, python_for_microscopists, each value, other keras, 0 integer encoding\n",
            "\n",
            "356. 325: Transcriptomics Unveiled – An In-Depth Exploration of Single Cell RNASeq Analysis using python\n",
            "   Difficulty: advanced\n",
            "   Duration: 69.5 minutes\n",
            "   Topics: Image Processing, Bio Applications, Python Basics\n",
            "   Key Concepts: 2009, development functioning, a single cell, spatial transcriptomics methods, scenarios\n",
            "\n",
            "357. Simplifying code with defaultdict in python\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 20 20defaultdict py, you, the need, doesn t, any fruit\n",
            "\n",
            "358. 109 - Predicting COVID-19 cases using Python\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: covid 19 cases, 2019_novel_coronavirus, https github, fitting data, the process\n",
            "\n",
            "359. 166b - Forecasting COVID-19 cases using LSTM networks\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, 19 cases, 166b, 19, time_series_covid19_confirmed_global csv code\n",
            "\n",
            "360. 269 - How to deploy your trained machine learning model as a web app on Heroku?\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.7 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: 269, the video, heroku www heroku, https github, heroku code\n",
            "\n",
            "361. 310 - Understanding sub word tokenization used for NLP\n",
            "   Difficulty: advanced\n",
            "   Duration: 32.3 minutes\n",
            "   Topics: \n",
            "   Key Concepts: just space tokenization, 1508 07909, vocabulary words, the vocabulary, a tokenizer\n",
            "\n",
            "362. 251 - Satellite image to maps translation using  pix2pix GAN\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the video, 251 satellite image, maps translation, edu pix2pix, http efrosgans eecs\n",
            "\n",
            "363. 218 - Difference between UpSampling2D and Conv2DTranspose used in U-Net and GAN\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.1 minutes\n",
            "   Topics: Data Structures\n",
            "   Key Concepts: conv2dtranspose, the input, u, these, 218 difference\n",
            "\n",
            "364. 312 - What are genetic algorithms?\n",
            "   Difficulty: advanced\n",
            "   Duration: 13.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: evolutionary algorithm, biological evolution, engineering designs, the next generation, the mutation operator\n",
            "\n",
            "365. 351 - Image Retrieval Made Easy With GUI. Uses ViT and FAISS\n",
            "   Difficulty: advanced\n",
            "   Duration: 11.3 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: 351 image retrieval, windows macos, similar images, imagenet, vision transformer\n",
            "\n",
            "366. 347 - Automate Google Search Results to Excel\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 347, 20search 20results 20to, 20excel, 20results 20to, https github\n",
            "\n",
            "367. 255 - Single image super resolution​ using SRGAN\n",
            "   Difficulty: advanced\n",
            "   Duration: 29.4 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: srgan, 1609, https arxiv, 255, 1609 04802 pdf\n",
            "\n",
            "368. 313 - Using genetic algorithms to simulate ​evolution\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the next generation, specific visual features, offspring, genes, ipynb\n",
            "\n",
            "369. This is the proper way to get started with python\n",
            "   Difficulty: intermediate\n",
            "   Duration: 9.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: a plan, this, the proper way, python, the basics\n",
            "\n",
            "370. Automate periodic mouse movements using python\n",
            "   Difficulty: advanced\n",
            "   Duration: 7.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: e g colab, any programs, this technique, this, your status\n",
            "\n",
            "371. 156 - How to limit GPU memory usage for TensorFlow?\n",
            "   Difficulty: advanced\n",
            "   Duration: 6.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, tensorflow calculations code, gpu memory, 156, gpu\n",
            "\n",
            "372. Python tips and tricks - 6: Fixing generic_utils error while importing segmentation models library\n",
            "   Difficulty: beginner\n",
            "   Duration: 7.8 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: custom_objects, you, colab, doesn t, keras\n",
            "\n",
            "373. Python tips and tricks - 8:  Working with RGB (and Hex) masks for semantic segmentation\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.2 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis, Computer Vision\n",
            "   Key Concepts: 0 2, 8429f6 lstrip land, values, array labels labels, pixels\n",
            "\n",
            "374. 113 - Histogram equalization and CLAHE\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: global contrast, python_for_microscopists, a specific limit, 113 histogram equalization, noise\n",
            "\n",
            "375. 314 - How to code the genetic algorithm in python?\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.3 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: the binary bitstrings, binary bitstrings, the mutation operation, numerical values, an implementation\n",
            "\n",
            "376. 147 - Getting started with Google Colaboratory for deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.1 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: google colaboratory, you, deep learning, google colab, a quick overview\n",
            "\n",
            "377. 315 - Optimization using Genetic Algorithm\n",
            "   Difficulty: advanced\n",
            "   Duration: 23.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the binary bitstrings, binary bitstrings, the mutation operation, 315 optimization, numerical values\n",
            "\n",
            "378. COVID Vaccine analysis using pandas in python (Tips Tricks 23)\n",
            "   Difficulty: intermediate\n",
            "   Duration: 30.9 minutes\n",
            "   Topics: Data Analysis\n",
            "   Key Concepts: covid vaccine analysis, 23, 23 code, vaccine analysis, pandas\n",
            "\n",
            "379. 238 - Real time face detection using opencv (and video feed from a webcam)\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.2 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: eye detection, the video, a webcam code, eye models, haarcascade_eye xml\n",
            "\n",
            "380. Web-deployed deep learning model, on Heroku.\n",
            "   Difficulty: beginner\n",
            "   Duration: 0.2 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: web, deep learning model, heroku\n",
            "\n",
            "381. How to install DigitalSreeni Image Annotator\n",
            "   Difficulty: advanced\n",
            "   Duration: 3.3 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, the following links, the correct environment, multiple downloads, this video\n",
            "\n",
            "382. 349 - Understanding FAISS for efficient similarity search of dense vectors\n",
            "   Difficulty: advanced\n",
            "   Duration: 25.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: quickly faiss, you, https arxiv, dense vectors, faiss faiss\n",
            "\n",
            "383. 309 - Training your own Chatbot using GPT​\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 2, this video tutorial, 309, 309_training_your_own_chatbot_using_gpt, https huggingface\n",
            "\n",
            "384. Digital Sreeni Channel name change from Python for Microscopists\n",
            "   Difficulty: beginner\n",
            "   Duration: 1.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: digital sreeni channel, python, microscopists\n",
            "\n",
            "385. 10 - lists tuples and dictionaries\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.4 minutes\n",
            "   Topics: Image Processing, Data Structures, Data Analysis\n",
            "   Key Concepts: 10, numbers, images, 10 lists tuples, dictionaries\n",
            "\n",
            "386. 157 - What is TensorBoard and how to launch it in a browser?\n",
            "   Difficulty: beginner\n",
            "   Duration: 18.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: a browser dataset, training model, the recorded logs, the video, tensorboard callback\n",
            "\n",
            "387. 243 - Real time detection of facial emotion, age, and gender using TensorFlow Lite on RaspberryPi\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.5 minutes\n",
            "   Topics: Computer Vision\n",
            "   Key Concepts: 3 7 download, you, your pi, python_for_microscopists, the python wheel\n",
            "\n",
            "388. Tips Tricks 24 - Interactive network visualization using pyviz\n",
            "   Difficulty: intermediate\n",
            "   Duration: 22.1 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: tips_tricks_24_quick_intro_to_pyviz ipynb, tips, latest code, tips_tricks_24_quick_intro_to_pyviz, 24\n",
            "\n",
            "389. Installing Conda in Google Colab - Tips Tricks 38\n",
            "   Difficulty: advanced\n",
            "   Duration: 9.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: you, 38 installing conda, conda environment, google colab code, conda\n",
            "\n",
            "390. 100 - What is total variation (TV) denoising filter?\n",
            "   Difficulty: beginner\n",
            "   Duration: 10.6 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: electronic components, python_for_microscopists, sensors, many sources, this video\n",
            "\n",
            "391. Generative AI and Prompt Engineering for Marketers\n",
            "   Difficulty: advanced\n",
            "   Duration: 50.1 minutes\n",
            "   Topics: \n",
            "   Key Concepts: analysis, you, a good prompt, the essence, ai\n",
            "\n",
            "392. 284 - Installing Mask RCNN and troubleshooting errors\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.7 minutes\n",
            "   Topics: Image Processing, Computer Vision, Data Analysis\n",
            "   Key Concepts: 2 2 link, 16 2, 2 2, 284, 2\n",
            "\n",
            "393. 103 - Edge filters for image processing\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: similar results, a variety, image processing, the filter, the application\n",
            "\n",
            "394. 106 - Image filters using discrete Fourier transform (DFT)\n",
            "   Difficulty: advanced\n",
            "   Duration: 15.2 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: the use, python_for_microscopists, any signal, 106 image filters, an image\n",
            "\n",
            "395. A New Blood Test to Differentiate Prostate Cancer from BPH Using GASP-1 Protein\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Bio Applications\n",
            "   Key Concepts: bph, 6694, 21, tmas color separation, unnecessary biopsies\n",
            "\n",
            "396. AMT2 - Extracting Emails from your Gmail Inbox using python\n",
            "   Difficulty: beginner\n",
            "   Duration: 16.0 minutes\n",
            "   Topics: Image Processing, Machine Learning\n",
            "   Key Concepts: you, required information, your time, your gmail inbox, manual things\n",
            "\n",
            "397. 82 - Dockerizing your python application\n",
            "   Difficulty: advanced\n",
            "   Duration: 18.7 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: you, python_for_microscopists, an image, this, docker\n",
            "\n",
            "398. Understanding Mean Absolute Error and Mean Squared Error as ML metrics and loss functions\n",
            "   Difficulty: advanced\n",
            "   Duration: 23.9 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: mean squared error, a balance, mse, mean absolute error, some weight\n",
            "\n",
            "399. 107 - Analysis of COVID-19 data using Python - Part 1\n",
            "   Difficulty: advanced\n",
            "   Duration: 19.1 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: 107, a key step, you, a quick review, this\n",
            "\n",
            "400. 72 - Getting Windows10 system ready for GPU accelerated deep learning\n",
            "   Difficulty: advanced\n",
            "   Duration: 12.2 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: you, gpu computation, doesn t, this, your gpu\n",
            "\n",
            "401. 108 - Analysis of COVID-19 data using Python - Part 2\n",
            "   Difficulty: advanced\n",
            "   Duration: 26.8 minutes\n",
            "   Topics: Image Processing, Data Analysis\n",
            "   Key Concepts: a key step, you, a quick review, an online server, this\n",
            "\n",
            "402. 44 - What is linear regression?\n",
            "   Difficulty: beginner\n",
            "   Duration: 16.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: relevant terminology, python_for_microscopists, a type, predictive analysis, gradient descent\n",
            "\n",
            "403. 298 - What is k fold cross validation?\n",
            "   Difficulty: beginner\n",
            "   Duration: 19.2 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: validation, training, its parameters, the number, various models\n",
            "\n",
            "404. 102 - What is unsharp mask?\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.8 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: unsharp mask, the workings, 102, its name, it\n",
            "\n",
            "405. 278 - IHC color separation followed by nuclei segmentation using python\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.2 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: analysis, american, voronoi otsu, the hematoxylin, 1485967\n",
            "\n",
            "406. Why GPUs Outpace CPUs?\n",
            "   Difficulty: advanced\n",
            "   Duration: 28.4 minutes\n",
            "   Topics: Data Analysis, Machine Learning\n",
            "   Key Concepts: the number, tutorial flops, a vector, speeds, 56\n",
            "\n",
            "407. 273 - What is Voronoi - explanation using python code\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: python_for_microscopists, python code code, the cluster, voronoi, separate regions\n",
            "\n",
            "408. 283 - What is Mask R-CNN?\n",
            "   Difficulty: beginner\n",
            "   Duration: 23.8 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: convolutional neural, mask r cnn, a trick, convolutional neural network, pixel level\n",
            "\n",
            "409. 181 - Multivariate time series forecasting using LSTM\n",
            "   Difficulty: advanced\n",
            "   Duration: 22.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: interested code, you, the dates, the video, any other stock\n",
            "\n",
            "410. 105 - What is Fourier Transform?\n",
            "   Difficulty: beginner\n",
            "   Duration: 26.6 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: minimal math, python_for_microscopists, any signal, an image, this video\n",
            "\n",
            "411. 110 - Visualizing COVID-19 cases & death information using Python and plotly\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: easy analysis code, com cssegisanddata covid, covid 19 27a063d7f442, 110, data science\n",
            "\n",
            "412. Python Tips and Tricks - 1: Mito (trymito.io) for structured data\n",
            "   Difficulty: beginner\n",
            "   Duration: 6.8 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 1, mito https hubs, h0h0gsz0, python tips, structured data link\n",
            "\n",
            "413. 09 - if else elif statements in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 11.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: you, very common statements, 09, python, this video\n",
            "\n",
            "414. PyScript – Running python in your browser​\n",
            "   Difficulty: advanced\n",
            "   Duration: 20.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: you, conda prompt, the html file, python commands, that local directory\n",
            "\n",
            "415. 323 - How to train a chatbot on your own documents?\n",
            "   Difficulty: advanced\n",
            "   Duration: 43.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the video, your own documents, 323, 323 train 20a, a chatbot\n",
            "\n",
            "416. What are various underscores used in python​?\n",
            "   Difficulty: advanced\n",
            "   Duration: 21.4 minutes\n",
            "   Topics: Python Basics\n",
            "   Key Concepts: various underscores, double underscore, identifiers, other words, this video\n",
            "\n",
            "417. 266 - Openslide library for whole slide images\n",
            "   Difficulty: advanced\n",
            "   Duration: 33.6 minutes\n",
            "   Topics: Image Processing, Computer Vision\n",
            "   Key Concepts: several formats aperio, you, virtual slides, the resolution, a small amount\n",
            "\n",
            "418. 01 - Why do you need to learn programming?\n",
            "   Difficulty: beginner\n",
            "   Duration: 4.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the need, you, your career, your peers, your fears\n",
            "\n",
            "419. 111 - What are the top 10 countries with highest COVID-19 cases and deaths?\n",
            "   Difficulty: advanced\n",
            "   Duration: 8.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: covid 19 27a063d7f442, highest cases, 111, the results code, 19\n",
            "\n",
            "420. 02 - What is programming?\n",
            "   Difficulty: beginner\n",
            "   Duration: 6.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: an ide, what, 02\n",
            "\n",
            "421. Camouflage simulation using the Genetic Algorithm\n",
            "   Difficulty: advanced\n",
            "   Duration: 0.3 minutes\n",
            "   Topics: \n",
            "   Key Concepts: some upcoming tutorials, camouflage simulation, this subject, the genetic algorithm, african\n",
            "\n",
            "422. 08 - A warning about round off errors in Python\n",
            "   Difficulty: beginner\n",
            "   Duration: 2.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: potential round, you, round, 08, 08 a warning\n",
            "\n",
            "423. 201 - Working with geotiff files using rasterio in python (also quick demo of NDVI calculation)\n",
            "   Difficulty: advanced\n",
            "   Duration: 24.3 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: 3 1 4, win_amd64, rasterio download, win_amd64 whl cp37, cp37\n",
            "\n",
            "424. Who is Sreeni and what does he do with the ad-revenue from his YouTube channel?\n",
            "   Difficulty: intermediate\n",
            "   Duration: 6.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: a brief summary, his youtube channel, who, he, what\n",
            "\n",
            "425. 324 - Chat-based data analysis​ using openAI and pandasAI\n",
            "   Difficulty: advanced\n",
            "   Duration: 17.4 minutes\n",
            "   Topics: Data Analysis, Python Basics\n",
            "   Key Concepts: gventuri pandas, dataset, openai, 324 chat, https github\n",
            "\n",
            "426. AMT1 - Extracting required information from your Outlook inbox\n",
            "   Difficulty: beginner\n",
            "   Duration: 12.6 minutes\n",
            "   Topics: \n",
            "   Key Concepts: you, required information, your time, manual things, amt01_extracting_information_from_outlook_emails\n",
            "\n",
            "427. A review of COVID19 situation in India using Python data analysis and plotting\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.5 minutes\n",
            "   Topics: Data Analysis\n",
            "   Key Concepts: you, covid19 situation, python data analysis, python_for_microscopists, covid19\n",
            "\n",
            "428. 03 - What is command prompt?\n",
            "   Difficulty: beginner\n",
            "   Duration: 9.7 minutes\n",
            "   Topics: \n",
            "   Key Concepts: command prompt, you, folders, an expert, the basics\n",
            "\n",
            "429. 217 - 9 steps to installing TensorFlow GPU on Windows 10\n",
            "   Difficulty: advanced\n",
            "   Duration: 14.2 minutes\n",
            "   Topics: Machine Learning\n",
            "   Key Concepts: an env, you, 2 gpus, the new environment, gpu computing\n",
            "\n",
            "430. 7 (+2) AI-powered fun and useful web applications\n",
            "   Difficulty: beginner\n",
            "   Duration: 15.0 minutes\n",
            "   Topics: \n",
            "   Key Concepts: 5 https, 4 https, 6, 9, www craiyon com\n",
            "\n",
            "431. 80 - What is Dockerfile, Docker Image, and Docker Container\n",
            "   Difficulty: beginner\n",
            "   Duration: 5.9 minutes\n",
            "   Topics: Image Processing\n",
            "   Key Concepts: perspective, python_for_microscopists, docker repository, these terms, https www\n",
            "\n",
            "432. Tips Tricks 19 - colab vs colab pro vs purchasing your own system\n",
            "   Difficulty: beginner\n",
            "   Duration: 35.5 minutes\n",
            "   Topics: \n",
            "   Key Concepts: some light, tips, your own workstation, 19 colab, 19\n",
            "\n",
            "433. A Holistic View of Software Languages, Databases, and Frameworks\n",
            "   Difficulty: advanced\n",
            "   Duration: 45.9 minutes\n",
            "   Topics: Image Processing, Python Basics\n",
            "   Key Concepts: you, 51, big data handling, certain tools, this video\n",
            "\n",
            "434. Swiss alps\n",
            "   Difficulty: beginner\n",
            "   Duration: 0.3 minutes\n",
            "   Topics: \n",
            "   Key Concepts: swiss alps, swiss\n",
            "\n",
            "435. Effect of Social Distancing on the spread of COVID-19 pandemic - A quick Python simulation\n",
            "   Difficulty: beginner\n",
            "   Duration: 21.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: python_for_microscopists, contacts hellewell, 2019 ncov outbreaks, isolation, the coronavirus 768292f04296\n",
            "\n",
            "436. Clarification about my YouTube channels\n",
            "   Difficulty: intermediate\n",
            "   Duration: 2.2 minutes\n",
            "   Topics: \n",
            "   Key Concepts: my youtube channels, you, clarification, my personal channel, my work channel\n",
            "\n",
            "437. Hidden gems around the Bay Area - Santa Cruz - Feb2021\n",
            "   Difficulty: advanced\n",
            "   Duration: 1.4 minutes\n",
            "   Topics: \n",
            "   Key Concepts: santa cruz feb2021, hidden gems, the car, home, i\n",
            "\n",
            "438. 🚴‍♀️ around the Coyote Hills Regional Park - San Francisco East Bay\n",
            "   Difficulty: beginner\n",
            "   Duration: 0.9 minutes\n",
            "   Topics: \n",
            "   Key Concepts: the coyote hills, org parks, east bay coyote, san francisco\n",
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "Learning path visualization saved to /content/drive/MyDrive/recommender_systems/knowledge_graphs/visualizations/learning_path_Learning_machine_learning_for_microscopy.html\n",
            "\n",
            "Found 40 videos\n",
            " for topic 'python_basics'\n",
            " with beginner difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 3\n",
            "Title: 04 - What is a digital image?\n",
            "Difficulty: beginner\n",
            "Duration: 10.7 minutes\n",
            "\n",
            "ID: 4\n",
            "Title: 05 - What is Python?\n",
            "Difficulty: beginner\n",
            "Duration: 8.7 minutes\n",
            "\n",
            "ID: 5\n",
            "Title: 06 - Python basics - IDE & operators\n",
            "Difficulty: beginner\n",
            "Duration: 19.1 minutes\n",
            "\n",
            "ID: 6\n",
            "Title: 07 - Python basics - logical operators and basic math\n",
            "Difficulty: beginner\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 12\n",
            "Title: 13 - for and while Loops in Python\n",
            "Difficulty: beginner\n",
            "Duration: 22.8 minutes\n",
            "\n",
            "ID: 13\n",
            "Title: 14 - Python Functions\n",
            "Difficulty: beginner\n",
            "Duration: 21.6 minutes\n",
            "\n",
            "ID: 14\n",
            "Title: 15 - Python Classes\n",
            "Difficulty: beginner\n",
            "Duration: 22.9 minutes\n",
            "\n",
            "ID: 19\n",
            "Title: 20 - Introduction to image processing using scikit-image in Python\n",
            "Difficulty: beginner\n",
            "Duration: 37.4 minutes\n",
            "\n",
            "ID: 35\n",
            "Title: 36 - Introduction to Pandas - Data reading and handling\n",
            "Difficulty: beginner\n",
            "Duration: 23.0 minutes\n",
            "\n",
            "ID: 36\n",
            "Title: 37 - Introduction to Pandas - Data Manipulation\n",
            "Difficulty: beginner\n",
            "Duration: 15.1 minutes\n",
            "\n",
            "ID: 37\n",
            "Title: 38 - Introduction to Pandas - Data Sorting\n",
            "Difficulty: beginner\n",
            "Duration: 21.2 minutes\n",
            "\n",
            "ID: 38\n",
            "Title: 39 - Introduction to Pandas -  Grouping Data\n",
            "Difficulty: beginner\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 39\n",
            "Title: 40 - Introduction to Pandas - Dealing with missing (null) data\n",
            "Difficulty: beginner\n",
            "Duration: 15.1 minutes\n",
            "\n",
            "ID: 40\n",
            "Title: 41 - Introduction to Pandas  - Plotting\n",
            "Difficulty: beginner\n",
            "Duration: 27.7 minutes\n",
            "\n",
            "ID: 41\n",
            "Title: 42 - Introduction to Seaborn Plotting in Python\n",
            "Difficulty: beginner\n",
            "Duration: 29.1 minutes\n",
            "\n",
            "ID: 47\n",
            "Title: 48 - What is logistic regression?\n",
            "Difficulty: beginner\n",
            "Duration: 13.8 minutes\n",
            "\n",
            "ID: 58\n",
            "Title: 59 - What is Random Forest classifier?\n",
            "Difficulty: beginner\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 67\n",
            "Title: 68 - Quick introduction to Support Vector Machines (SVM)\n",
            "Difficulty: beginner\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 79\n",
            "Title: 79 - What is Docker?\n",
            "Difficulty: beginner\n",
            "Duration: 9.2 minutes\n",
            "\n",
            "ID: 81\n",
            "Title: 81 - Testing Docker on Windows and introduction to basic commands\n",
            "Difficulty: beginner\n",
            "Duration: 15.0 minutes\n",
            "\n",
            "ID: 85\n",
            "Title: 85b - An introduction to autoencoders - in Python\n",
            "Difficulty: beginner\n",
            "Duration: 21.3 minutes\n",
            "\n",
            "ID: 92\n",
            "Title: 91 - Introduction to transfer learning\n",
            "Difficulty: beginner\n",
            "Duration: 20.8 minutes\n",
            "\n",
            "ID: 140\n",
            "Title: 135 - A quick introduction to Metrics in deep learning. (Keras & TensorFlow)\n",
            "Difficulty: beginner\n",
            "Duration: 10.2 minutes\n",
            "\n",
            "ID: 167\n",
            "Title: 162 - An introduction to time series forecasting - Part 2 Exploring data using python\n",
            "Difficulty: beginner\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 168\n",
            "Title: 163 - An introduction to time series forecasting - Part 3 Using ARIMA in python\n",
            "Difficulty: beginner\n",
            "Duration: 21.3 minutes\n",
            "\n",
            "ID: 169\n",
            "Title: 164 - An introduction to time series forecasting - Part 4 Using feed forward neural networks\n",
            "Difficulty: beginner\n",
            "Duration: 20.9 minutes\n",
            "\n",
            "ID: 170\n",
            "Title: 165 - An introduction to RNN and LSTM\n",
            "Difficulty: beginner\n",
            "Duration: 19.5 minutes\n",
            "\n",
            "ID: 171\n",
            "Title: 166 - An introduction to time series forecasting - Part 5 Using LSTM\n",
            "Difficulty: beginner\n",
            "Duration: 23.7 minutes\n",
            "\n",
            "ID: 172\n",
            "Title: 161 - An introduction to time series forecasting - Part 1\n",
            "Difficulty: beginner\n",
            "Duration: 13.0 minutes\n",
            "\n",
            "ID: 190\n",
            "Title: 178 - An introduction to variational autoencoders (VAE)\n",
            "Difficulty: beginner\n",
            "Duration: 17.6 minutes\n",
            "\n",
            "ID: 242\n",
            "Title: 220 - What is the best loss function for semantic segmentation?\n",
            "Difficulty: beginner\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 254\n",
            "Title: 231 - Semantic Segmentation of BraTS2020 - Part 0 - Introduction (and plan)\n",
            "Difficulty: beginner\n",
            "Duration: 15.2 minutes\n",
            "\n",
            "ID: 283\n",
            "Title: 253 - Unpaired image to image translation​ using cycleGAN - An introduction\n",
            "Difficulty: beginner\n",
            "Duration: 25.9 minutes\n",
            "\n",
            "ID: 292\n",
            "Title: Tips Tricks 17 - All you need to know about decorators in python\n",
            "Difficulty: beginner\n",
            "Duration: 41.1 minutes\n",
            "\n",
            "ID: 336\n",
            "Title: 279 - An introduction to object segmentation using StarDist library in Python\n",
            "Difficulty: beginner\n",
            "Duration: 20.7 minutes\n",
            "\n",
            "ID: 383\n",
            "Title: 308 - An introduction to language models with focus on GPT\n",
            "Difficulty: beginner\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 396\n",
            "Title: 318 - Introduction to Metaheuristic Algorithms​\n",
            "Difficulty: beginner\n",
            "Duration: 13.7 minutes\n",
            "\n",
            "ID: 404\n",
            "Title: 327 - An introduction to Single Molecule Fluorescence In Situ Hybridization (smFISH​)\n",
            "Difficulty: beginner\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "ID: 406\n",
            "Title: 329 - What is Detectron2? An introduction.\n",
            "Difficulty: beginner\n",
            "Duration: 23.9 minutes\n",
            "\n",
            "ID: 411\n",
            "Title: 333 - An introduction to YOLO v8​\n",
            "Difficulty: beginner\n",
            "Duration: 18.7 minutes\n",
            "\n",
            "Found 0 videos\n",
            " for topic 'python_basics'\n",
            " with intermediate difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "Found 16 videos\n",
            " for topic 'python_basics'\n",
            " with advanced difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 21\n",
            "Title: 22 - Denoising microscope images in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 24\n",
            "Title: 25 - Reading Images, Splitting Channels, Resizing using openCV in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 46\n",
            "Title: 47 - Multiple Linear Regression with SciKit-Learn in Python\n",
            "Difficulty: advanced\n",
            "Duration: 13.3 minutes\n",
            "\n",
            "ID: 83\n",
            "Title: 83 - Running your Docker in the cloud\n",
            "Difficulty: advanced\n",
            "Duration: 15.1 minutes\n",
            "\n",
            "ID: 124\n",
            "Title: 120 - Image registration methods in python\n",
            "Difficulty: advanced\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "ID: 137\n",
            "Title: 132 - What are Activation functions in deep learning (Keras & Tensorflow)?\n",
            "Difficulty: advanced\n",
            "Duration: 7.1 minutes\n",
            "\n",
            "ID: 138\n",
            "Title: 133 - What are Loss functions in machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 6.8 minutes\n",
            "\n",
            "ID: 305\n",
            "Title: 267 - Processing whole slide images (as tiles)\n",
            "Difficulty: advanced\n",
            "Duration: 28.7 minutes\n",
            "\n",
            "ID: 348\n",
            "Title: Understanding Mean Absolute Error and Mean Squared Error as ML metrics and loss functions\n",
            "Difficulty: advanced\n",
            "Duration: 23.9 minutes\n",
            "\n",
            "ID: 351\n",
            "Title: 287 - Tracking particles and objects using Trackpy in python\n",
            "Difficulty: advanced\n",
            "Duration: 31.0 minutes\n",
            "\n",
            "ID: 369\n",
            "Title: What are various underscores used in python​?\n",
            "Difficulty: advanced\n",
            "Duration: 21.4 minutes\n",
            "\n",
            "ID: 389\n",
            "Title: 314 - How to code the genetic algorithm in python?\n",
            "Difficulty: advanced\n",
            "Duration: 20.3 minutes\n",
            "\n",
            "ID: 395\n",
            "Title: 324 - Chat-based data analysis​ using openAI and pandasAI\n",
            "Difficulty: advanced\n",
            "Duration: 17.4 minutes\n",
            "\n",
            "ID: 401\n",
            "Title: 325: Transcriptomics Unveiled – An In-Depth Exploration of Single Cell RNASeq Analysis using python\n",
            "Difficulty: advanced\n",
            "Duration: 69.5 minutes\n",
            "\n",
            "ID: 405\n",
            "Title: 328 - smFISH Analysis using Big FISH library in python​\n",
            "Difficulty: advanced\n",
            "Duration: 49.8 minutes\n",
            "\n",
            "ID: 412\n",
            "Title: A Holistic View of Software Languages, Databases, and Frameworks\n",
            "Difficulty: advanced\n",
            "Duration: 45.9 minutes\n",
            "\n",
            "Found 33 videos\n",
            " for topic 'machine_learning'\n",
            " with beginner difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 42\n",
            "Title: 43 - What is machine learning anyway?\n",
            "Difficulty: beginner\n",
            "Duration: 21.4 minutes\n",
            "\n",
            "ID: 47\n",
            "Title: 48 - What is logistic regression?\n",
            "Difficulty: beginner\n",
            "Duration: 13.8 minutes\n",
            "\n",
            "ID: 49\n",
            "Title: 50 - What is k-means clustering and how to code it in Python?\n",
            "Difficulty: beginner\n",
            "Duration: 16.9 minutes\n",
            "\n",
            "ID: 51\n",
            "Title: 52 - What is GMM and how to use it for Image segmentation?\n",
            "Difficulty: beginner\n",
            "Duration: 29.5 minutes\n",
            "\n",
            "ID: 58\n",
            "Title: 59 - What is Random Forest classifier?\n",
            "Difficulty: beginner\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 67\n",
            "Title: 68 - Quick introduction to Support Vector Machines (SVM)\n",
            "Difficulty: beginner\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 73\n",
            "Title: 73 - Image Segmentation using U-Net - Part1 (What is U-net?)\n",
            "Difficulty: beginner\n",
            "Duration: 18.2 minutes\n",
            "\n",
            "ID: 85\n",
            "Title: 85b - An introduction to autoencoders - in Python\n",
            "Difficulty: beginner\n",
            "Duration: 21.3 minutes\n",
            "\n",
            "ID: 92\n",
            "Title: 91 - Introduction to transfer learning\n",
            "Difficulty: beginner\n",
            "Duration: 20.8 minutes\n",
            "\n",
            "ID: 140\n",
            "Title: 135 - A quick introduction to Metrics in deep learning. (Keras & TensorFlow)\n",
            "Difficulty: beginner\n",
            "Duration: 10.2 minutes\n",
            "\n",
            "ID: 142\n",
            "Title: 137 - What is one hot encoding in machine learning?\n",
            "Difficulty: beginner\n",
            "Duration: 12.3 minutes\n",
            "\n",
            "ID: 169\n",
            "Title: 164 - An introduction to time series forecasting - Part 4 Using feed forward neural networks\n",
            "Difficulty: beginner\n",
            "Duration: 20.9 minutes\n",
            "\n",
            "ID: 170\n",
            "Title: 165 - An introduction to RNN and LSTM\n",
            "Difficulty: beginner\n",
            "Duration: 19.5 minutes\n",
            "\n",
            "ID: 184\n",
            "Title: 174  - What is PCA and how to use it to speed up machine learning training\n",
            "Difficulty: beginner\n",
            "Duration: 8.1 minutes\n",
            "\n",
            "ID: 205\n",
            "Title: 193 - What is XGBoost and is it really better than Random Forest and Deep Learning?\n",
            "Difficulty: beginner\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 230\n",
            "Title: Python tips and tricks - 2: Downloading images from online search\n",
            "Difficulty: beginner\n",
            "Duration: 6.8 minutes\n",
            "\n",
            "ID: 242\n",
            "Title: 220 - What is the best loss function for semantic segmentation?\n",
            "Difficulty: beginner\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 269\n",
            "Title: 5 things to check before applying for your first machine learning job\n",
            "Difficulty: beginner\n",
            "Duration: 10.0 minutes\n",
            "\n",
            "ID: 270\n",
            "Title: You want to be a machine learning engineer, now what?\n",
            "Difficulty: beginner\n",
            "Duration: 6.5 minutes\n",
            "\n",
            "ID: 277\n",
            "Title: What I am reading this week about Machine Learning and AI - 16 July 2021\n",
            "Difficulty: beginner\n",
            "Duration: 5.5 minutes\n",
            "\n",
            "ID: 291\n",
            "Title: Tips Tricks 16 - How much memory to train a DL model on large images\n",
            "Difficulty: beginner\n",
            "Duration: 16.8 minutes\n",
            "\n",
            "ID: 293\n",
            "Title: Tips Tricks 18 - Extracting faces from images for deep learning training\n",
            "Difficulty: beginner\n",
            "Duration: 6.2 minutes\n",
            "\n",
            "ID: 294\n",
            "Title: What I am reading this week about Machine Learning and AI - 13 August 2021\n",
            "Difficulty: beginner\n",
            "Duration: 7.5 minutes\n",
            "\n",
            "ID: 300\n",
            "Title: 261 - What is global average pooling in deep learning?\n",
            "Difficulty: beginner\n",
            "Duration: 15.2 minutes\n",
            "\n",
            "ID: 307\n",
            "Title: Web-deployed deep learning model, on Heroku.\n",
            "Difficulty: beginner\n",
            "Duration: 0.2 minutes\n",
            "\n",
            "ID: 318\n",
            "Title: 7 best machine learning books in 2022\n",
            "Difficulty: beginner\n",
            "Duration: 12.5 minutes\n",
            "\n",
            "ID: 322\n",
            "Title: AMT2 - Extracting Emails from your Gmail Inbox using python\n",
            "Difficulty: beginner\n",
            "Duration: 16.0 minutes\n",
            "\n",
            "ID: 340\n",
            "Title: Learn about neural network hyperparameters visually\n",
            "Difficulty: beginner\n",
            "Duration: 10.6 minutes\n",
            "\n",
            "ID: 343\n",
            "Title: 283 - What is Mask R-CNN?\n",
            "Difficulty: beginner\n",
            "Duration: 23.8 minutes\n",
            "\n",
            "ID: 355\n",
            "Title: Book Review - Machine Learning with scikit-learn and scientific python toolkits\n",
            "Difficulty: beginner\n",
            "Duration: 4.3 minutes\n",
            "\n",
            "ID: 371\n",
            "Title: 298 - What is k fold cross validation?\n",
            "Difficulty: beginner\n",
            "Duration: 19.2 minutes\n",
            "\n",
            "ID: 383\n",
            "Title: 308 - An introduction to language models with focus on GPT\n",
            "Difficulty: beginner\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 399\n",
            "Title: 321 - What is Particle Swarm Optimization PSO?\n",
            "Difficulty: beginner\n",
            "Duration: 9.7 minutes\n",
            "\n",
            "Found 2 videos\n",
            " for topic 'machine_learning'\n",
            " with intermediate difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 320\n",
            "Title: Book Review - Machine Learning in Biotechnology and Life Sciences\n",
            "Difficulty: intermediate\n",
            "Duration: 4.9 minutes\n",
            "\n",
            "ID: 357\n",
            "Title: How to get started with Data Science and Machine Learning​\n",
            "Difficulty: intermediate\n",
            "Duration: 21.5 minutes\n",
            "\n",
            "Found 118 videos\n",
            " for topic 'machine_learning'\n",
            " with advanced difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 45\n",
            "Title: 46 - Splitting data into training and testing sets for machine learning\n",
            "Difficulty: advanced\n",
            "Duration: 13.8 minutes\n",
            "\n",
            "ID: 50\n",
            "Title: 51 - Image Segmentation using K-means\n",
            "Difficulty: advanced\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 52\n",
            "Title: 53  - How to pick optimal number of parameters for your unsupervised machine learning model?\n",
            "Difficulty: advanced\n",
            "Duration: 13.7 minutes\n",
            "\n",
            "ID: 53\n",
            "Title: 54 - Unsupervised and supervised machine learning  - a reminder\n",
            "Difficulty: advanced\n",
            "Duration: 13.9 minutes\n",
            "\n",
            "ID: 55\n",
            "Title: 56 - What are features in machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 9.9 minutes\n",
            "\n",
            "ID: 56\n",
            "Title: 57 - How to generate features in Python for machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 17.7 minutes\n",
            "\n",
            "ID: 57\n",
            "Title: 58 - What are Gabor filters?\n",
            "Difficulty: advanced\n",
            "Duration: 26.0 minutes\n",
            "\n",
            "ID: 60\n",
            "Title: 61 - How to create Gabor feature banks for machine learning\n",
            "Difficulty: advanced\n",
            "Duration: 16.1 minutes\n",
            "\n",
            "ID: 61\n",
            "Title: 62 - Image Segmentation using traditional machine learning - The plan\n",
            "Difficulty: advanced\n",
            "Duration: 6.5 minutes\n",
            "\n",
            "ID: 62\n",
            "Title: 63 - Image Segmentation using traditional machine learning Part1 - FeatureExtraction\n",
            "Difficulty: advanced\n",
            "Duration: 22.9 minutes\n",
            "\n",
            "ID: 63\n",
            "Title: 64 - Image Segmentation using traditional machine learning - Part2 Training RF\n",
            "Difficulty: advanced\n",
            "Duration: 17.9 minutes\n",
            "\n",
            "ID: 64\n",
            "Title: 65 - Image Segmentation using traditional machine learning - Part3 Feature Ranking\n",
            "Difficulty: advanced\n",
            "Duration: 7.5 minutes\n",
            "\n",
            "ID: 65\n",
            "Title: 66 - Image Segmentation using traditional machine learning - Part4 Pickling Model\n",
            "Difficulty: advanced\n",
            "Duration: 7.4 minutes\n",
            "\n",
            "ID: 66\n",
            "Title: 67 - Image Segmentation using traditional machine learning - Part5 Segmenting Images\n",
            "Difficulty: advanced\n",
            "Duration: 17.7 minutes\n",
            "\n",
            "ID: 68\n",
            "Title: 68b - SVM vs. Random Forest for image segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 15.0 minutes\n",
            "\n",
            "ID: 69\n",
            "Title: 69 - Image classification using Bag of Visual Words (BOVW)\n",
            "Difficulty: advanced\n",
            "Duration: 38.1 minutes\n",
            "\n",
            "ID: 70\n",
            "Title: 70 - An overview of deep learning and neural networks\n",
            "Difficulty: advanced\n",
            "Duration: 33.8 minutes\n",
            "\n",
            "ID: 71\n",
            "Title: 71 - Malarial cell classification using CNN\n",
            "Difficulty: advanced\n",
            "Duration: 49.2 minutes\n",
            "\n",
            "ID: 72\n",
            "Title: 72 - Getting Windows10 system ready for GPU accelerated deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 76\n",
            "Title: 76 - Image Segmentation using U-Net - Part 4 (Model fitting, checkpoints, and callbacks)\n",
            "Difficulty: advanced\n",
            "Duration: 14.0 minutes\n",
            "\n",
            "ID: 86\n",
            "Title: 85a - What are Autoencoders and what are they used for?\n",
            "Difficulty: advanced\n",
            "Duration: 13.9 minutes\n",
            "\n",
            "ID: 93\n",
            "Title: 92 - Autoencoders using transfer learning - Image colorization\n",
            "Difficulty: advanced\n",
            "Duration: 26.2 minutes\n",
            "\n",
            "ID: 94\n",
            "Title: 93 - Do not waste your time with deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 95\n",
            "Title: 94 - Denoising MRI images (also CT & microscopy images)\n",
            "Difficulty: advanced\n",
            "Duration: 43.4 minutes\n",
            "\n",
            "ID: 96\n",
            "Title: 93 - Do not waste your time with deep learning (updated)\n",
            "Difficulty: advanced\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 130\n",
            "Title: 125 - What are Generative Adversarial Networks (GAN)?\n",
            "Difficulty: advanced\n",
            "Duration: 12.0 minutes\n",
            "\n",
            "ID: 131\n",
            "Title: 126 - Generative Adversarial Networks (GAN) using keras in python\n",
            "Difficulty: advanced\n",
            "Duration: 33.6 minutes\n",
            "\n",
            "ID: 133\n",
            "Title: 128 - Malarial cell classification using CNN and data augmentation\n",
            "Difficulty: advanced\n",
            "Duration: 12.9 minutes\n",
            "\n",
            "ID: 134\n",
            "Title: 129 - What are Callbacks, Checkpoints and Early Stopping in deep learning (Keras and TensorFlow)\n",
            "Difficulty: advanced\n",
            "Duration: 10.1 minutes\n",
            "\n",
            "ID: 135\n",
            "Title: 130 - Evaluating the deep learning trained model (Keras and TensorFlow)\n",
            "Difficulty: advanced\n",
            "Duration: 9.8 minutes\n",
            "\n",
            "ID: 136\n",
            "Title: 131 - How to load a partially trained deep learning model and continue training?\n",
            "Difficulty: advanced\n",
            "Duration: 5.9 minutes\n",
            "\n",
            "ID: 137\n",
            "Title: 132 - What are Activation functions in deep learning (Keras & Tensorflow)?\n",
            "Difficulty: advanced\n",
            "Duration: 7.1 minutes\n",
            "\n",
            "ID: 138\n",
            "Title: 133 - What are Loss functions in machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 6.8 minutes\n",
            "\n",
            "ID: 139\n",
            "Title: 134 - What are Optimizers in deep learning? (Keras & TensorFlow)\n",
            "Difficulty: advanced\n",
            "Duration: 8.6 minutes\n",
            "\n",
            "ID: 141\n",
            "Title: 136 understanding deep learning parameters batch size\n",
            "Difficulty: advanced\n",
            "Duration: 11.6 minutes\n",
            "\n",
            "ID: 143\n",
            "Title: 138 - The need for scaling, dropout, and batch normalization in deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 14.9 minutes\n",
            "\n",
            "ID: 144\n",
            "Title: 139 - The topology of deep neural networks, designing your model.\n",
            "Difficulty: advanced\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 145\n",
            "Title: 140 - What in the world is regression, multi-label, multi-class and binary classification?\n",
            "Difficulty: advanced\n",
            "Duration: 13.9 minutes\n",
            "\n",
            "ID: 146\n",
            "Title: 141 - Regression using Neural Networks and comparison to other models\n",
            "Difficulty: advanced\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 147\n",
            "Title: 142 - Multilabel classification using Keras\n",
            "Difficulty: advanced\n",
            "Duration: 19.4 minutes\n",
            "\n",
            "ID: 148\n",
            "Title: 143 - Multiclass classification using Keras\n",
            "Difficulty: advanced\n",
            "Duration: 11.6 minutes\n",
            "\n",
            "ID: 149\n",
            "Title: 144 - Binary classification using Keras\n",
            "Difficulty: advanced\n",
            "Duration: 14.6 minutes\n",
            "\n",
            "ID: 150\n",
            "Title: 145 - Confusion matrix,  ROC and AUC in machine learning\n",
            "Difficulty: advanced\n",
            "Duration: 25.0 minutes\n",
            "\n",
            "ID: 151\n",
            "Title: 67b - Feature based image segmentation using traditional machine learning. (Multi-training images)\n",
            "Difficulty: advanced\n",
            "Duration: 25.1 minutes\n",
            "\n",
            "ID: 152\n",
            "Title: 146 - Raspberry Pi - Learning python and deep learning on a tight budget\n",
            "Difficulty: advanced\n",
            "Duration: 7.4 minutes\n",
            "\n",
            "ID: 153\n",
            "Title: 147 - Getting started with Google Colaboratory for deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 15.1 minutes\n",
            "\n",
            "ID: 154\n",
            "Title: 148 - 7 techniques to work with imbalanced data for machine learning in python\n",
            "Difficulty: advanced\n",
            "Duration: 36.7 minutes\n",
            "\n",
            "ID: 158\n",
            "Title: 152 - How to visualize convolutional filter outputs in your deep learning model?\n",
            "Difficulty: advanced\n",
            "Duration: 11.1 minutes\n",
            "\n",
            "ID: 159\n",
            "Title: 153 - Artificial Neural Networks - Explanation for those who understand linear regression\n",
            "Difficulty: advanced\n",
            "Duration: 31.9 minutes\n",
            "\n",
            "ID: 160\n",
            "Title: 154 - Understanding the training and validation loss curves\n",
            "Difficulty: advanced\n",
            "Duration: 27.8 minutes\n",
            "\n",
            "ID: 163\n",
            "Title: 158 - Convolutional filters + Random Forest for image classification.\n",
            "Difficulty: advanced\n",
            "Duration: 27.2 minutes\n",
            "\n",
            "ID: 164\n",
            "Title: 159 - Convolutional filters + Random Forest for image segmentation.\n",
            "Difficulty: advanced\n",
            "Duration: 19.1 minutes\n",
            "\n",
            "ID: 165\n",
            "Title: 155 - How many hidden layers and neurons do you need in your artificial neural network?\n",
            "Difficulty: advanced\n",
            "Duration: 24.1 minutes\n",
            "\n",
            "ID: 173\n",
            "Title: 158b - Transfer learning using CNN (VGG16) as feature extractor and Random Forest classifier\n",
            "Difficulty: advanced\n",
            "Duration: 25.6 minutes\n",
            "\n",
            "ID: 177\n",
            "Title: 159b - Pretrained CNN (VGG16 - imagenet) features for semantic segmentation using Random Forest\n",
            "Difficulty: advanced\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 178\n",
            "Title: 169 - Deep Learning made easy with AutoKeras\n",
            "Difficulty: advanced\n",
            "Duration: 13.5 minutes\n",
            "\n",
            "ID: 179\n",
            "Title: 170 - AutoKeras for structured data classification using the Wisconsin breast cancer data set\n",
            "Difficulty: advanced\n",
            "Duration: 15.8 minutes\n",
            "\n",
            "ID: 180\n",
            "Title: 171 - AutoKeras for image classification using cifar10 data set\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 182\n",
            "Title: 172 - Top k accuracy for multiclass machine learning classification\n",
            "Difficulty: advanced\n",
            "Duration: 7.1 minutes\n",
            "\n",
            "ID: 183\n",
            "Title: 173 - Intersection over Union (IoU) for semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 14.9 minutes\n",
            "\n",
            "ID: 186\n",
            "Title: 176 -- Speeding up ML training using PCA - Multiclass image classification example\n",
            "Difficulty: advanced\n",
            "Duration: 12.6 minutes\n",
            "\n",
            "ID: 206\n",
            "Title: 194 - Semantic segmentation using XGBoost and VGG16 imagenet as feature extractor\n",
            "Difficulty: advanced\n",
            "Duration: 32.7 minutes\n",
            "\n",
            "ID: 207\n",
            "Title: 195 - Image classification using XGBoost and VGG16 imagenet as feature extractor\n",
            "Difficulty: advanced\n",
            "Duration: 17.2 minutes\n",
            "\n",
            "ID: 209\n",
            "Title: 197 - Light GBM vs XGBoost for semantic image segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 26.1 minutes\n",
            "\n",
            "ID: 213\n",
            "Title: 202 - Two ways to read HAM10000 dataset into python for skin cancer lesion classification\n",
            "Difficulty: advanced\n",
            "Duration: 26.7 minutes\n",
            "\n",
            "ID: 214\n",
            "Title: 203 - Skin cancer lesion classification using the HAM10000 dataset\n",
            "Difficulty: advanced\n",
            "Duration: 28.7 minutes\n",
            "\n",
            "ID: 215\n",
            "Title: 200 - Image classification using gray-level co-occurrence matrix (GLCM) features and LGBM classifier\n",
            "Difficulty: advanced\n",
            "Duration: 23.4 minutes\n",
            "\n",
            "ID: 218\n",
            "Title: 208 - Multiclass semantic segmentation using U-Net\n",
            "Difficulty: advanced\n",
            "Duration: 31.3 minutes\n",
            "\n",
            "ID: 219\n",
            "Title: 209 - Multiclass semantic segmentation using U-Net: Large images and 3D volumes (slice by slice)\n",
            "Difficulty: advanced\n",
            "Duration: 16.5 minutes\n",
            "\n",
            "ID: 220\n",
            "Title: 210 - Multiclass U-Net using VGG, ResNet, and Inception as backbones\n",
            "Difficulty: advanced\n",
            "Duration: 37.9 minutes\n",
            "\n",
            "ID: 221\n",
            "Title: 211 - U-Net vs LinkNet for multiclass semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 31.9 minutes\n",
            "\n",
            "ID: 222\n",
            "Title: 212 - Classification of mnist sign language alphabets using deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 22.2 minutes\n",
            "\n",
            "ID: 223\n",
            "Title: 213 - Ensemble of networks for improved accuracy in deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 25.5 minutes\n",
            "\n",
            "ID: 224\n",
            "Title: 214 - Improving semantic segmentation (U-Net) performance via ensemble of multiple trained networks\n",
            "Difficulty: advanced\n",
            "Duration: 29.6 minutes\n",
            "\n",
            "ID: 227\n",
            "Title: 215 - 3D U-Net for semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 50.0 minutes\n",
            "\n",
            "ID: 236\n",
            "Title: 217 - 9 steps to installing TensorFlow GPU on Windows 10\n",
            "Difficulty: advanced\n",
            "Duration: 14.2 minutes\n",
            "\n",
            "ID: 245\n",
            "Title: 224 - Recurrent and Residual U-net\n",
            "Difficulty: advanced\n",
            "Duration: 16.1 minutes\n",
            "\n",
            "ID: 258\n",
            "Title: 235 - Pre-training U-net using autoencoders - Part 1 - Autoencoders and visualizing features\n",
            "Difficulty: advanced\n",
            "Duration: 28.3 minutes\n",
            "\n",
            "ID: 264\n",
            "Title: 239 - Deep Learning training for facial emotion detection\n",
            "Difficulty: advanced\n",
            "Duration: 12.6 minutes\n",
            "\n",
            "ID: 265\n",
            "Title: 240 - Deep Learning training for age and gender detection\n",
            "Difficulty: advanced\n",
            "Duration: 10.6 minutes\n",
            "\n",
            "ID: 268\n",
            "Title: My review of the 'Automated Machine Learning with AutoKeras' book\n",
            "Difficulty: advanced\n",
            "Duration: 6.6 minutes\n",
            "\n",
            "ID: 287\n",
            "Title: What I am reading this week about Machine Learning and AI - 23 July 2021\n",
            "Difficulty: advanced\n",
            "Duration: 6.5 minutes\n",
            "\n",
            "ID: 296\n",
            "Title: 258 - Semi-supervised learning with GANs\n",
            "Difficulty: advanced\n",
            "Duration: 34.3 minutes\n",
            "\n",
            "ID: 297\n",
            "Title: 259 - Semi-supervised learning with GANs - in keras\n",
            "Difficulty: advanced\n",
            "Duration: 29.2 minutes\n",
            "\n",
            "ID: 299\n",
            "Title: 262 - Localizing anomalies in images\n",
            "Difficulty: advanced\n",
            "Duration: 26.4 minutes\n",
            "\n",
            "ID: 304\n",
            "Title: 265 - Feature engineering or deep learning (for semantic segmentation)\n",
            "Difficulty: advanced\n",
            "Duration: 31.0 minutes\n",
            "\n",
            "ID: 308\n",
            "Title: 268 - How to deploy your trained machine learning model into a local web application?\n",
            "Difficulty: advanced\n",
            "Duration: 29.2 minutes\n",
            "\n",
            "ID: 309\n",
            "Title: 269 - How to deploy your trained machine learning model as a web app on Heroku?\n",
            "Difficulty: advanced\n",
            "Duration: 25.7 minutes\n",
            "\n",
            "ID: 310\n",
            "Title: 270 - How to deploy your trained machine learning model as a web app on Heroku (No Docker)\n",
            "Difficulty: advanced\n",
            "Duration: 40.5 minutes\n",
            "\n",
            "ID: 311\n",
            "Title: 271 - How to deploy your trained machine learning model as a web app on Heroku (with docker)\n",
            "Difficulty: advanced\n",
            "Duration: 32.6 minutes\n",
            "\n",
            "ID: 313\n",
            "Title: Book Review - Deep Learning with fastai Cookbook\n",
            "Difficulty: advanced\n",
            "Duration: 13.8 minutes\n",
            "\n",
            "ID: 314\n",
            "Title: Lung cancer subclassification using fastai​ (Tips Tricks 22)\n",
            "Difficulty: advanced\n",
            "Duration: 28.8 minutes\n",
            "\n",
            "ID: 326\n",
            "Title: Random is not so random - understanding random in python\n",
            "Difficulty: advanced\n",
            "Duration: 26.2 minutes\n",
            "\n",
            "ID: 331\n",
            "Title: 277 - 3D object segmentation in python\n",
            "Difficulty: advanced\n",
            "Duration: 10.2 minutes\n",
            "\n",
            "ID: 352\n",
            "Title: 288 - Nuclei segmentation using StarDist and tracking using Trackpy in python\n",
            "Difficulty: advanced\n",
            "Duration: 24.8 minutes\n",
            "\n",
            "ID: 361\n",
            "Title: 290 - Deep Learning based edge detection using HED\n",
            "Difficulty: advanced\n",
            "Duration: 19.6 minutes\n",
            "\n",
            "ID: 362\n",
            "Title: 291 - Object segmentation using Deep Learning based edge detection (HED)​\n",
            "Difficulty: advanced\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 363\n",
            "Title: 292 - Denoising images using deep learning (Noise2Void)​\n",
            "Difficulty: advanced\n",
            "Duration: 16.9 minutes\n",
            "\n",
            "ID: 364\n",
            "Title: 293  - Denoising RGB images using deep learning (Noise2Void)\n",
            "Difficulty: advanced\n",
            "Duration: 24.0 minutes\n",
            "\n",
            "ID: 365\n",
            "Title: 294 - Denoising 3D multi-channel scientific images using Noise2Void deep learning approach\n",
            "Difficulty: advanced\n",
            "Duration: 22.4 minutes\n",
            "\n",
            "ID: 366\n",
            "Title: 296 - Converting keras trained model to ONNX format - Image Classification example\n",
            "Difficulty: advanced\n",
            "Duration: 21.1 minutes\n",
            "\n",
            "ID: 368\n",
            "Title: 295 - ONNX – open format for machine learning models​\n",
            "Difficulty: advanced\n",
            "Duration: 14.4 minutes\n",
            "\n",
            "ID: 370\n",
            "Title: 301 - Evaluating keras model using KFold cross validation​\n",
            "Difficulty: advanced\n",
            "Duration: 33.5 minutes\n",
            "\n",
            "ID: 372\n",
            "Title: 299 - Evaluating sklearn model using KFold cross validation​ in python\n",
            "Difficulty: advanced\n",
            "Duration: 27.7 minutes\n",
            "\n",
            "ID: 373\n",
            "Title: 302 - Tuning deep learning hyperparameters​ using GridSearchCV\n",
            "Difficulty: advanced\n",
            "Duration: 18.8 minutes\n",
            "\n",
            "ID: 376\n",
            "Title: 303 - Reinhard color transformation​\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 377\n",
            "Title: 304 - Augmentation of histology images​ to train stain-agnostic deep learning models\n",
            "Difficulty: advanced\n",
            "Duration: 20.7 minutes\n",
            "\n",
            "ID: 381\n",
            "Title: Feature engineering vs Feature Learning (tips tricks 46 )\n",
            "Difficulty: advanced\n",
            "Duration: 18.7 minutes\n",
            "\n",
            "ID: 387\n",
            "Title: 312 - What are genetic algorithms?\n",
            "Difficulty: advanced\n",
            "Duration: 13.1 minutes\n",
            "\n",
            "ID: 391\n",
            "Title: 316  - Optimizing Steel Strength using Metaheuristic algorithms (e.g., Genetic)\n",
            "Difficulty: advanced\n",
            "Duration: 16.5 minutes\n",
            "\n",
            "ID: 392\n",
            "Title: 317 - HyperParameter Optimization using Genetic algorithms\n",
            "Difficulty: advanced\n",
            "Duration: 14.4 minutes\n",
            "\n",
            "ID: 398\n",
            "Title: 320 - Understanding Simulated Annealing​ using steel optimization\n",
            "Difficulty: advanced\n",
            "Duration: 10.9 minutes\n",
            "\n",
            "ID: 400\n",
            "Title: 322 - PSO Using steel optimization\n",
            "Difficulty: advanced\n",
            "Duration: 14.6 minutes\n",
            "\n",
            "ID: 407\n",
            "Title: 330 - Fine tuning Detectron2 for instance segmentation using custom data\n",
            "Difficulty: advanced\n",
            "Duration: 50.4 minutes\n",
            "\n",
            "ID: 410\n",
            "Title: 334 - Training custom instance segmentation model using YOLO v8\n",
            "Difficulty: advanced\n",
            "Duration: 35.5 minutes\n",
            "\n",
            "ID: 420\n",
            "Title: Why GPUs Outpace CPUs?\n",
            "Difficulty: advanced\n",
            "Duration: 28.4 minutes\n",
            "\n",
            "ID: 427\n",
            "Title: 344 Color separation and nuclei segmentation in cores extracted from TMA\n",
            "Difficulty: advanced\n",
            "Duration: 12.5 minutes\n",
            "\n",
            "ID: 437\n",
            "Title: 350 - Efficient Image Retrieval with Vision Transformer (ViT) and FAISS\n",
            "Difficulty: advanced\n",
            "Duration: 18.9 minutes\n",
            "\n",
            "Found 56 videos\n",
            " for topic 'image_processing'\n",
            " with beginner difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 3\n",
            "Title: 04 - What is a digital image?\n",
            "Difficulty: beginner\n",
            "Duration: 10.7 minutes\n",
            "\n",
            "ID: 9\n",
            "Title: 10 - lists tuples and dictionaries\n",
            "Difficulty: beginner\n",
            "Duration: 21.4 minutes\n",
            "\n",
            "ID: 10\n",
            "Title: 11 - numpy arrays\n",
            "Difficulty: beginner\n",
            "Duration: 41.5 minutes\n",
            "\n",
            "ID: 11\n",
            "Title: 12 - Python Recap of lists and numpy arrays\n",
            "Difficulty: beginner\n",
            "Duration: 16.8 minutes\n",
            "\n",
            "ID: 13\n",
            "Title: 14 - Python Functions\n",
            "Difficulty: beginner\n",
            "Duration: 21.6 minutes\n",
            "\n",
            "ID: 15\n",
            "Title: 16 - Understanding digital images for Python processing\n",
            "Difficulty: beginner\n",
            "Duration: 18.5 minutes\n",
            "\n",
            "ID: 16\n",
            "Title: 17 - Reading images in Python\n",
            "Difficulty: beginner\n",
            "Duration: 55.0 minutes\n",
            "\n",
            "ID: 17\n",
            "Title: 18 - Image processing using pillow in Python\n",
            "Difficulty: beginner\n",
            "Duration: 31.2 minutes\n",
            "\n",
            "ID: 18\n",
            "Title: 19 - image processing using scipy in Python\n",
            "Difficulty: beginner\n",
            "Duration: 27.2 minutes\n",
            "\n",
            "ID: 19\n",
            "Title: 20 - Introduction to image processing using scikit-image in Python\n",
            "Difficulty: beginner\n",
            "Duration: 37.4 minutes\n",
            "\n",
            "ID: 35\n",
            "Title: 36 - Introduction to Pandas - Data reading and handling\n",
            "Difficulty: beginner\n",
            "Duration: 23.0 minutes\n",
            "\n",
            "ID: 40\n",
            "Title: 41 - Introduction to Pandas  - Plotting\n",
            "Difficulty: beginner\n",
            "Duration: 27.7 minutes\n",
            "\n",
            "ID: 41\n",
            "Title: 42 - Introduction to Seaborn Plotting in Python\n",
            "Difficulty: beginner\n",
            "Duration: 29.1 minutes\n",
            "\n",
            "ID: 51\n",
            "Title: 52 - What is GMM and how to use it for Image segmentation?\n",
            "Difficulty: beginner\n",
            "Duration: 29.5 minutes\n",
            "\n",
            "ID: 58\n",
            "Title: 59 - What is Random Forest classifier?\n",
            "Difficulty: beginner\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 67\n",
            "Title: 68 - Quick introduction to Support Vector Machines (SVM)\n",
            "Difficulty: beginner\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 73\n",
            "Title: 73 - Image Segmentation using U-Net - Part1 (What is U-net?)\n",
            "Difficulty: beginner\n",
            "Duration: 18.2 minutes\n",
            "\n",
            "ID: 80\n",
            "Title: 80 - What is Dockerfile, Docker Image, and Docker Container\n",
            "Difficulty: beginner\n",
            "Duration: 5.9 minutes\n",
            "\n",
            "ID: 81\n",
            "Title: 81 - Testing Docker on Windows and introduction to basic commands\n",
            "Difficulty: beginner\n",
            "Duration: 15.0 minutes\n",
            "\n",
            "ID: 85\n",
            "Title: 85b - An introduction to autoencoders - in Python\n",
            "Difficulty: beginner\n",
            "Duration: 21.3 minutes\n",
            "\n",
            "ID: 92\n",
            "Title: 91 - Introduction to transfer learning\n",
            "Difficulty: beginner\n",
            "Duration: 20.8 minutes\n",
            "\n",
            "ID: 97\n",
            "Title: 95 - What is digital image filtering and image convolution?\n",
            "Difficulty: beginner\n",
            "Duration: 24.3 minutes\n",
            "\n",
            "ID: 98\n",
            "Title: 96 - What is Gaussian Denoising Filter?\n",
            "Difficulty: beginner\n",
            "Duration: 15.4 minutes\n",
            "\n",
            "ID: 99\n",
            "Title: 97 - What is median denoising filter?\n",
            "Difficulty: beginner\n",
            "Duration: 9.8 minutes\n",
            "\n",
            "ID: 100\n",
            "Title: 98 - What is bilateral denoising filter?\n",
            "Difficulty: beginner\n",
            "Duration: 12.1 minutes\n",
            "\n",
            "ID: 101\n",
            "Title: 99 - What is Non-local means (NLM) denoising filter?\n",
            "Difficulty: beginner\n",
            "Duration: 10.5 minutes\n",
            "\n",
            "ID: 102\n",
            "Title: 100 - What is total variation (TV) denoising filter?\n",
            "Difficulty: beginner\n",
            "Duration: 10.6 minutes\n",
            "\n",
            "ID: 103\n",
            "Title: 101 - What is block matching and 3D filtering (BM3D)?\n",
            "Difficulty: beginner\n",
            "Duration: 11.0 minutes\n",
            "\n",
            "ID: 105\n",
            "Title: 102 - What is unsharp mask?\n",
            "Difficulty: beginner\n",
            "Duration: 9.8 minutes\n",
            "\n",
            "ID: 108\n",
            "Title: 105 - What is Fourier Transform?\n",
            "Difficulty: beginner\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 230\n",
            "Title: Python tips and tricks - 2: Downloading images from online search\n",
            "Difficulty: beginner\n",
            "Duration: 6.8 minutes\n",
            "\n",
            "ID: 232\n",
            "Title: Python tips and tricks - 3: Be conservative with image augmentation\n",
            "Difficulty: beginner\n",
            "Duration: 11.4 minutes\n",
            "\n",
            "ID: 233\n",
            "Title: Python tips and tricks - 4: Best free software for image visualization and processing\n",
            "Difficulty: beginner\n",
            "Duration: 9.1 minutes\n",
            "\n",
            "ID: 234\n",
            "Title: Python tips and tricks - 5: Extracting patches from large images and masks for semantic segmentation\n",
            "Difficulty: beginner\n",
            "Duration: 7.5 minutes\n",
            "\n",
            "ID: 246\n",
            "Title: 225 - Attention U-net. What is attention and why is it needed for U-Net?\n",
            "Difficulty: beginner\n",
            "Duration: 14.9 minutes\n",
            "\n",
            "ID: 249\n",
            "Title: Python tips and tricks - 8:  Working with RGB (and Hex) masks for semantic segmentation\n",
            "Difficulty: beginner\n",
            "Duration: 18.2 minutes\n",
            "\n",
            "ID: 252\n",
            "Title: Python tips and tricks - 9: Performing additional tasks during data augmentation in keras\n",
            "Difficulty: beginner\n",
            "Duration: 11.6 minutes\n",
            "\n",
            "ID: 254\n",
            "Title: 231 - Semantic Segmentation of BraTS2020 - Part 0 - Introduction (and plan)\n",
            "Difficulty: beginner\n",
            "Duration: 15.2 minutes\n",
            "\n",
            "ID: 260\n",
            "Title: Python tips and tricks - 10: Loading images and masks in the right order for semantic segmentation\n",
            "Difficulty: beginner\n",
            "Duration: 11.8 minutes\n",
            "\n",
            "ID: 262\n",
            "Title: 237 - What is Tensorflow Lite and how to convert keras model to tflite?\n",
            "Difficulty: beginner\n",
            "Duration: 30.7 minutes\n",
            "\n",
            "ID: 272\n",
            "Title: Tips Tricks 14 - EasyOCR for text detection in images (using python)\n",
            "Difficulty: beginner\n",
            "Duration: 12.0 minutes\n",
            "\n",
            "ID: 283\n",
            "Title: 253 - Unpaired image to image translation​ using cycleGAN - An introduction\n",
            "Difficulty: beginner\n",
            "Duration: 25.9 minutes\n",
            "\n",
            "ID: 291\n",
            "Title: Tips Tricks 16 - How much memory to train a DL model on large images\n",
            "Difficulty: beginner\n",
            "Duration: 16.8 minutes\n",
            "\n",
            "ID: 293\n",
            "Title: Tips Tricks 18 - Extracting faces from images for deep learning training\n",
            "Difficulty: beginner\n",
            "Duration: 6.2 minutes\n",
            "\n",
            "ID: 294\n",
            "Title: What I am reading this week about Machine Learning and AI - 13 August 2021\n",
            "Difficulty: beginner\n",
            "Duration: 7.5 minutes\n",
            "\n",
            "ID: 300\n",
            "Title: 261 - What is global average pooling in deep learning?\n",
            "Difficulty: beginner\n",
            "Duration: 15.2 minutes\n",
            "\n",
            "ID: 303\n",
            "Title: Tips Tricks 20 - Understanding transfer learning for different size and channel inputs\n",
            "Difficulty: beginner\n",
            "Duration: 47.5 minutes\n",
            "\n",
            "ID: 322\n",
            "Title: AMT2 - Extracting Emails from your Gmail Inbox using python\n",
            "Difficulty: beginner\n",
            "Duration: 16.0 minutes\n",
            "\n",
            "ID: 325\n",
            "Title: Labeling images using LabKit for semantic segmentation\n",
            "Difficulty: beginner\n",
            "Duration: 15.8 minutes\n",
            "\n",
            "ID: 341\n",
            "Title: 10 best annotation tools for computer vision​ applications\n",
            "Difficulty: beginner\n",
            "Duration: 13.5 minutes\n",
            "\n",
            "ID: 378\n",
            "Title: 305 - What is Cellpose algorithm for segmentation?\n",
            "Difficulty: beginner\n",
            "Duration: 30.1 minutes\n",
            "\n",
            "ID: 383\n",
            "Title: 308 - An introduction to language models with focus on GPT\n",
            "Difficulty: beginner\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 397\n",
            "Title: 319 - What is Simulated Annealing Optimization​?\n",
            "Difficulty: beginner\n",
            "Duration: 14.3 minutes\n",
            "\n",
            "ID: 399\n",
            "Title: 321 - What is Particle Swarm Optimization PSO?\n",
            "Difficulty: beginner\n",
            "Duration: 9.7 minutes\n",
            "\n",
            "ID: 403\n",
            "Title: Interpolation for resizing 3D volumetric data (Tips and Tricks 50)\n",
            "Difficulty: beginner\n",
            "Duration: 14.9 minutes\n",
            "\n",
            "ID: 404\n",
            "Title: 327 - An introduction to Single Molecule Fluorescence In Situ Hybridization (smFISH​)\n",
            "Difficulty: beginner\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "Found 5 videos\n",
            " for topic 'image_processing'\n",
            " with intermediate difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 316\n",
            "Title: Tips Tricks 24 - Interactive network visualization using pyviz\n",
            "Difficulty: intermediate\n",
            "Duration: 22.1 minutes\n",
            "\n",
            "ID: 317\n",
            "Title: Tips Tricks 25 - Locating objects in large images using template matching\n",
            "Difficulty: intermediate\n",
            "Duration: 13.0 minutes\n",
            "\n",
            "ID: 319\n",
            "Title: Tips Tricks 26 - How to properly convert 16 bit to 8 bit images in python\n",
            "Difficulty: intermediate\n",
            "Duration: 13.0 minutes\n",
            "\n",
            "ID: 324\n",
            "Title: Labeling images using QuPath for semantic segmentation\n",
            "Difficulty: intermediate\n",
            "Duration: 10.8 minutes\n",
            "\n",
            "ID: 393\n",
            "Title: Overlaying images for easy comparison (in python)\n",
            "Difficulty: intermediate\n",
            "Duration: 1.0 minutes\n",
            "\n",
            "Found 186 videos\n",
            " for topic 'image_processing'\n",
            " with advanced difficulty\n",
            ":\n",
            "==================================================\n",
            "\n",
            "ID: 20\n",
            "Title: 21 - Scratch assay analysis with just 5 lines code in Python\n",
            "Difficulty: advanced\n",
            "Duration: 28.1 minutes\n",
            "\n",
            "ID: 21\n",
            "Title: 22 - Denoising microscope images in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 22\n",
            "Title: 23 - Histogram based image segmentation in Python\n",
            "Difficulty: advanced\n",
            "Duration: 24.2 minutes\n",
            "\n",
            "ID: 23\n",
            "Title: 24 - Random Walker segmentation in Python\n",
            "Difficulty: advanced\n",
            "Duration: 27.0 minutes\n",
            "\n",
            "ID: 24\n",
            "Title: 25 - Reading Images, Splitting Channels, Resizing using openCV in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 25\n",
            "Title: 26 - Denoising and edge detection using opencv in Python\n",
            "Difficulty: advanced\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 26\n",
            "Title: 27 - CLAHE and Thresholding using opencv in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.5 minutes\n",
            "\n",
            "ID: 27\n",
            "Title: 28 - Thresholding and morphological operations using openCV in Python\n",
            "Difficulty: advanced\n",
            "Duration: 20.5 minutes\n",
            "\n",
            "ID: 28\n",
            "Title: 29 - Key points, detectors and descriptors in openCV\n",
            "Difficulty: advanced\n",
            "Duration: 30.4 minutes\n",
            "\n",
            "ID: 29\n",
            "Title: 30 - Image registration using homography in openCV\n",
            "Difficulty: advanced\n",
            "Duration: 46.7 minutes\n",
            "\n",
            "ID: 30\n",
            "Title: 31 - A few ways to read and write csv files in Python\n",
            "Difficulty: advanced\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 31\n",
            "Title: 32 - Grain size analysis in Python using a microscope image\n",
            "Difficulty: advanced\n",
            "Duration: 41.1 minutes\n",
            "\n",
            "ID: 32\n",
            "Title: 33 - Grain size analysis in Python using watershed\n",
            "Difficulty: advanced\n",
            "Duration: 38.8 minutes\n",
            "\n",
            "ID: 33\n",
            "Title: 34 - Grain size analysis in Python using watershed - multiple images\n",
            "Difficulty: advanced\n",
            "Duration: 18.4 minutes\n",
            "\n",
            "ID: 50\n",
            "Title: 51 - Image Segmentation using K-means\n",
            "Difficulty: advanced\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 54\n",
            "Title: 55 - How to read proprietary microscope images into Python\n",
            "Difficulty: advanced\n",
            "Duration: 14.9 minutes\n",
            "\n",
            "ID: 55\n",
            "Title: 56 - What are features in machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 9.9 minutes\n",
            "\n",
            "ID: 56\n",
            "Title: 57 - How to generate features in Python for machine learning?\n",
            "Difficulty: advanced\n",
            "Duration: 17.7 minutes\n",
            "\n",
            "ID: 57\n",
            "Title: 58 - What are Gabor filters?\n",
            "Difficulty: advanced\n",
            "Duration: 26.0 minutes\n",
            "\n",
            "ID: 59\n",
            "Title: 60 - How to use Random Forest in Python?\n",
            "Difficulty: advanced\n",
            "Duration: 32.3 minutes\n",
            "\n",
            "ID: 60\n",
            "Title: 61 - How to create Gabor feature banks for machine learning\n",
            "Difficulty: advanced\n",
            "Duration: 16.1 minutes\n",
            "\n",
            "ID: 61\n",
            "Title: 62 - Image Segmentation using traditional machine learning - The plan\n",
            "Difficulty: advanced\n",
            "Duration: 6.5 minutes\n",
            "\n",
            "ID: 62\n",
            "Title: 63 - Image Segmentation using traditional machine learning Part1 - FeatureExtraction\n",
            "Difficulty: advanced\n",
            "Duration: 22.9 minutes\n",
            "\n",
            "ID: 63\n",
            "Title: 64 - Image Segmentation using traditional machine learning - Part2 Training RF\n",
            "Difficulty: advanced\n",
            "Duration: 17.9 minutes\n",
            "\n",
            "ID: 64\n",
            "Title: 65 - Image Segmentation using traditional machine learning - Part3 Feature Ranking\n",
            "Difficulty: advanced\n",
            "Duration: 7.5 minutes\n",
            "\n",
            "ID: 65\n",
            "Title: 66 - Image Segmentation using traditional machine learning - Part4 Pickling Model\n",
            "Difficulty: advanced\n",
            "Duration: 7.4 minutes\n",
            "\n",
            "ID: 66\n",
            "Title: 67 - Image Segmentation using traditional machine learning - Part5 Segmenting Images\n",
            "Difficulty: advanced\n",
            "Duration: 17.7 minutes\n",
            "\n",
            "ID: 68\n",
            "Title: 68b - SVM vs. Random Forest for image segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 15.0 minutes\n",
            "\n",
            "ID: 69\n",
            "Title: 69 - Image classification using Bag of Visual Words (BOVW)\n",
            "Difficulty: advanced\n",
            "Duration: 38.1 minutes\n",
            "\n",
            "ID: 71\n",
            "Title: 71 - Malarial cell classification using CNN\n",
            "Difficulty: advanced\n",
            "Duration: 49.2 minutes\n",
            "\n",
            "ID: 74\n",
            "Title: 74 - Image Segmentation using U-Net - Part 2 (Defining U-Net in Python using Keras)\n",
            "Difficulty: advanced\n",
            "Duration: 19.2 minutes\n",
            "\n",
            "ID: 75\n",
            "Title: 75 - Image Segmentation using U-Net - Part 3 (What are trainable parameters?)\n",
            "Difficulty: advanced\n",
            "Duration: 6.8 minutes\n",
            "\n",
            "ID: 76\n",
            "Title: 76 - Image Segmentation using U-Net - Part 4 (Model fitting, checkpoints, and callbacks)\n",
            "Difficulty: advanced\n",
            "Duration: 14.0 minutes\n",
            "\n",
            "ID: 77\n",
            "Title: 77 - Image Segmentation using U-Net - Part 5 (Understanding the data)\n",
            "Difficulty: advanced\n",
            "Duration: 29.0 minutes\n",
            "\n",
            "ID: 78\n",
            "Title: 78 - Image Segmentation using U-Net - Part 6 (Running the code and understanding results)\n",
            "Difficulty: advanced\n",
            "Duration: 21.2 minutes\n",
            "\n",
            "ID: 82\n",
            "Title: 82 - Dockerizing your python application\n",
            "Difficulty: advanced\n",
            "Duration: 18.7 minutes\n",
            "\n",
            "ID: 83\n",
            "Title: 83 - Running your Docker in the cloud\n",
            "Difficulty: advanced\n",
            "Duration: 15.1 minutes\n",
            "\n",
            "ID: 84\n",
            "Title: 84 - How to build a Docker (module) with your code and run it on APEER?\n",
            "Difficulty: advanced\n",
            "Duration: 42.3 minutes\n",
            "\n",
            "ID: 86\n",
            "Title: 85a - What are Autoencoders and what are they used for?\n",
            "Difficulty: advanced\n",
            "Duration: 13.9 minutes\n",
            "\n",
            "ID: 87\n",
            "Title: 86 - Applications of Autoencoders - Denoising using MNIST dataset\n",
            "Difficulty: advanced\n",
            "Duration: 19.4 minutes\n",
            "\n",
            "ID: 88\n",
            "Title: 87 - Applications of Autoencoders - Denoising using custom images\n",
            "Difficulty: advanced\n",
            "Duration: 19.8 minutes\n",
            "\n",
            "ID: 89\n",
            "Title: 88 - Applications of Autoencoders - Anomaly Detection\n",
            "Difficulty: advanced\n",
            "Duration: 18.6 minutes\n",
            "\n",
            "ID: 90\n",
            "Title: 89 - Applications of Autoencoders - Domain Adaptation\n",
            "Difficulty: advanced\n",
            "Duration: 16.9 minutes\n",
            "\n",
            "ID: 91\n",
            "Title: 90 - Application of Autoencoders - Image colorization\n",
            "Difficulty: advanced\n",
            "Duration: 20.9 minutes\n",
            "\n",
            "ID: 93\n",
            "Title: 92 - Autoencoders using transfer learning - Image colorization\n",
            "Difficulty: advanced\n",
            "Duration: 26.2 minutes\n",
            "\n",
            "ID: 94\n",
            "Title: 93 - Do not waste your time with deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 95\n",
            "Title: 94 - Denoising MRI images (also CT & microscopy images)\n",
            "Difficulty: advanced\n",
            "Duration: 43.4 minutes\n",
            "\n",
            "ID: 96\n",
            "Title: 93 - Do not waste your time with deep learning (updated)\n",
            "Difficulty: advanced\n",
            "Duration: 21.0 minutes\n",
            "\n",
            "ID: 106\n",
            "Title: 103 - Edge filters for image processing\n",
            "Difficulty: advanced\n",
            "Duration: 22.9 minutes\n",
            "\n",
            "ID: 107\n",
            "Title: 104 - Ridge Filters to detect tube like structures in images\n",
            "Difficulty: advanced\n",
            "Duration: 5.4 minutes\n",
            "\n",
            "ID: 109\n",
            "Title: 106 - Image filters using discrete Fourier transform (DFT)\n",
            "Difficulty: advanced\n",
            "Duration: 15.2 minutes\n",
            "\n",
            "ID: 110\n",
            "Title: 112 - Averaging image stack in real and DCT space for denoising\n",
            "Difficulty: advanced\n",
            "Duration: 11.5 minutes\n",
            "\n",
            "ID: 111\n",
            "Title: 113 - Histogram equalization and CLAHE\n",
            "Difficulty: advanced\n",
            "Duration: 17.1 minutes\n",
            "\n",
            "ID: 112\n",
            "Title: 114 - Automatic image quality assessment using BRISQUE\n",
            "Difficulty: advanced\n",
            "Duration: 9.2 minutes\n",
            "\n",
            "ID: 113\n",
            "Title: 115 - Auto segmentation using multi-otsu\n",
            "Difficulty: advanced\n",
            "Duration: 7.7 minutes\n",
            "\n",
            "ID: 115\n",
            "Title: 107 - Analysis of COVID-19 data using Python - Part 1\n",
            "Difficulty: advanced\n",
            "Duration: 19.1 minutes\n",
            "\n",
            "ID: 116\n",
            "Title: 108 - Analysis of COVID-19 data using Python - Part 2\n",
            "Difficulty: advanced\n",
            "Duration: 26.8 minutes\n",
            "\n",
            "ID: 120\n",
            "Title: 116 - Measuring properties of labeled / segmented regions\n",
            "Difficulty: advanced\n",
            "Duration: 11.0 minutes\n",
            "\n",
            "ID: 121\n",
            "Title: 117 - Shading correction using rolling ball background subtraction\n",
            "Difficulty: advanced\n",
            "Duration: 9.5 minutes\n",
            "\n",
            "ID: 122\n",
            "Title: 118 - Object detection by template matching\n",
            "Difficulty: advanced\n",
            "Duration: 12.1 minutes\n",
            "\n",
            "ID: 123\n",
            "Title: 119 - Sub-pixel image registration in Python\n",
            "Difficulty: advanced\n",
            "Duration: 6.0 minutes\n",
            "\n",
            "ID: 124\n",
            "Title: 120 - Image registration methods in python\n",
            "Difficulty: advanced\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "ID: 126\n",
            "Title: 121 - Image registration using pystackreg library in Python\n",
            "Difficulty: advanced\n",
            "Duration: 16.3 minutes\n",
            "\n",
            "ID: 127\n",
            "Title: 122 - Normalizing H&E images and digitally separating Hematoxylin and Eosin components\n",
            "Difficulty: advanced\n",
            "Duration: 13.4 minutes\n",
            "\n",
            "ID: 128\n",
            "Title: 123 - Reference based image quality metrics\n",
            "Difficulty: advanced\n",
            "Duration: 12.9 minutes\n",
            "\n",
            "ID: 129\n",
            "Title: 124 - Image quality by estimating sharpness\n",
            "Difficulty: advanced\n",
            "Duration: 7.2 minutes\n",
            "\n",
            "ID: 130\n",
            "Title: 125 - What are Generative Adversarial Networks (GAN)?\n",
            "Difficulty: advanced\n",
            "Duration: 12.0 minutes\n",
            "\n",
            "ID: 131\n",
            "Title: 126 - Generative Adversarial Networks (GAN) using keras in python\n",
            "Difficulty: advanced\n",
            "Duration: 33.6 minutes\n",
            "\n",
            "ID: 133\n",
            "Title: 128 - Malarial cell classification using CNN and data augmentation\n",
            "Difficulty: advanced\n",
            "Duration: 12.9 minutes\n",
            "\n",
            "ID: 149\n",
            "Title: 144 - Binary classification using Keras\n",
            "Difficulty: advanced\n",
            "Duration: 14.6 minutes\n",
            "\n",
            "ID: 151\n",
            "Title: 67b - Feature based image segmentation using traditional machine learning. (Multi-training images)\n",
            "Difficulty: advanced\n",
            "Duration: 25.1 minutes\n",
            "\n",
            "ID: 156\n",
            "Title: 150 - Warning about keras' data augmentation when working with categorical labels\n",
            "Difficulty: advanced\n",
            "Duration: 11.0 minutes\n",
            "\n",
            "ID: 157\n",
            "Title: 151 Warning about JPG files when working with categorical labels\n",
            "Difficulty: advanced\n",
            "Duration: 6.5 minutes\n",
            "\n",
            "ID: 163\n",
            "Title: 158 - Convolutional filters + Random Forest for image classification.\n",
            "Difficulty: advanced\n",
            "Duration: 27.2 minutes\n",
            "\n",
            "ID: 164\n",
            "Title: 159 - Convolutional filters + Random Forest for image segmentation.\n",
            "Difficulty: advanced\n",
            "Duration: 19.1 minutes\n",
            "\n",
            "ID: 177\n",
            "Title: 159b - Pretrained CNN (VGG16 - imagenet) features for semantic segmentation using Random Forest\n",
            "Difficulty: advanced\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 180\n",
            "Title: 171 - AutoKeras for image classification using cifar10 data set\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 186\n",
            "Title: 176 -- Speeding up ML training using PCA - Multiclass image classification example\n",
            "Difficulty: advanced\n",
            "Duration: 12.6 minutes\n",
            "\n",
            "ID: 194\n",
            "Title: 182 - How to batch process multiple images in python?\n",
            "Difficulty: advanced\n",
            "Duration: 21.9 minutes\n",
            "\n",
            "ID: 203\n",
            "Title: 191 - Measuring image similarity in python\n",
            "Difficulty: advanced\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "ID: 204\n",
            "Title: 192 - Working with 3D and multi-dimensional images in python\n",
            "Difficulty: advanced\n",
            "Duration: 20.4 minutes\n",
            "\n",
            "ID: 206\n",
            "Title: 194 - Semantic segmentation using XGBoost and VGG16 imagenet as feature extractor\n",
            "Difficulty: advanced\n",
            "Duration: 32.7 minutes\n",
            "\n",
            "ID: 207\n",
            "Title: 195 - Image classification using XGBoost and VGG16 imagenet as feature extractor\n",
            "Difficulty: advanced\n",
            "Duration: 17.2 minutes\n",
            "\n",
            "ID: 209\n",
            "Title: 197 - Light GBM vs XGBoost for semantic image segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 26.1 minutes\n",
            "\n",
            "ID: 211\n",
            "Title: 199 - Detecting straight lines using Hough transform in python\n",
            "Difficulty: advanced\n",
            "Duration: 11.8 minutes\n",
            "\n",
            "ID: 212\n",
            "Title: 201 - Working with geotiff files using rasterio in python (also quick demo of NDVI calculation)\n",
            "Difficulty: advanced\n",
            "Duration: 24.3 minutes\n",
            "\n",
            "ID: 215\n",
            "Title: 200 - Image classification using gray-level co-occurrence matrix (GLCM) features and LGBM classifier\n",
            "Difficulty: advanced\n",
            "Duration: 23.4 minutes\n",
            "\n",
            "ID: 216\n",
            "Title: 206 - The right way to segment large images by applying a trained U-Net model on smaller patches\n",
            "Difficulty: advanced\n",
            "Duration: 27.0 minutes\n",
            "\n",
            "ID: 217\n",
            "Title: 207 - Using IoU (Jaccard) as loss function to train U-Net for semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 19.1 minutes\n",
            "\n",
            "ID: 218\n",
            "Title: 208 - Multiclass semantic segmentation using U-Net\n",
            "Difficulty: advanced\n",
            "Duration: 31.3 minutes\n",
            "\n",
            "ID: 219\n",
            "Title: 209 - Multiclass semantic segmentation using U-Net: Large images and 3D volumes (slice by slice)\n",
            "Difficulty: advanced\n",
            "Duration: 16.5 minutes\n",
            "\n",
            "ID: 220\n",
            "Title: 210 - Multiclass U-Net using VGG, ResNet, and Inception as backbones\n",
            "Difficulty: advanced\n",
            "Duration: 37.9 minutes\n",
            "\n",
            "ID: 221\n",
            "Title: 211 - U-Net vs LinkNet for multiclass semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 31.9 minutes\n",
            "\n",
            "ID: 222\n",
            "Title: 212 - Classification of mnist sign language alphabets using deep learning\n",
            "Difficulty: advanced\n",
            "Duration: 22.2 minutes\n",
            "\n",
            "ID: 224\n",
            "Title: 214 - Improving semantic segmentation (U-Net) performance via ensemble of multiple trained networks\n",
            "Difficulty: advanced\n",
            "Duration: 29.6 minutes\n",
            "\n",
            "ID: 225\n",
            "Title: 204 - U-Net for semantic segmentation of mitochondria\n",
            "Difficulty: advanced\n",
            "Duration: 24.6 minutes\n",
            "\n",
            "ID: 226\n",
            "Title: 205 - U-Net plus watershed for instance segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 27.8 minutes\n",
            "\n",
            "ID: 227\n",
            "Title: 215 - 3D U-Net for semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 50.0 minutes\n",
            "\n",
            "ID: 235\n",
            "Title: 216 - Semantic segmentation using a small dataset for training (& U-Net)\n",
            "Difficulty: advanced\n",
            "Duration: 37.2 minutes\n",
            "\n",
            "ID: 238\n",
            "Title: 219 - Understanding U-Net architecture and building it from scratch\n",
            "Difficulty: advanced\n",
            "Duration: 37.6 minutes\n",
            "\n",
            "ID: 240\n",
            "Title: 222 - Working with large data that doesn't fit your system memory - Semantic Segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 45.0 minutes\n",
            "\n",
            "ID: 241\n",
            "Title: 223 - Test time augmentation for semantic segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 19.0 minutes\n",
            "\n",
            "ID: 243\n",
            "Title: 221 - Easy way to split data on your disk into train, test, and validation?\n",
            "Difficulty: advanced\n",
            "Duration: 8.9 minutes\n",
            "\n",
            "ID: 244\n",
            "Title: 227 - Various U-Net models using keras unet collection library - for semantic image segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 9.1 minutes\n",
            "\n",
            "ID: 245\n",
            "Title: 224 - Recurrent and Residual U-net\n",
            "Difficulty: advanced\n",
            "Duration: 16.1 minutes\n",
            "\n",
            "ID: 247\n",
            "Title: 226 - U-Net vs Attention U-Net vs Attention Residual U-Net - should you care?\n",
            "Difficulty: advanced\n",
            "Duration: 27.1 minutes\n",
            "\n",
            "ID: 250\n",
            "Title: 228 - Semantic segmentation of aerial (satellite) imagery using U-net\n",
            "Difficulty: advanced\n",
            "Duration: 42.0 minutes\n",
            "\n",
            "ID: 251\n",
            "Title: 229 - Smooth blending of patches for semantic segmentation of large images (using U-Net)\n",
            "Difficulty: advanced\n",
            "Duration: 18.6 minutes\n",
            "\n",
            "ID: 253\n",
            "Title: 230 - Semantic Segmentation of Landcover Dataset using U-Net\n",
            "Difficulty: advanced\n",
            "Duration: 45.9 minutes\n",
            "\n",
            "ID: 255\n",
            "Title: 232 - Semantic Segmentation of BraTS2020 - Part 1 - Getting the data ready\n",
            "Difficulty: advanced\n",
            "Duration: 24.6 minutes\n",
            "\n",
            "ID: 258\n",
            "Title: 235 - Pre-training U-net using autoencoders - Part 1 - Autoencoders and visualizing features\n",
            "Difficulty: advanced\n",
            "Duration: 28.3 minutes\n",
            "\n",
            "ID: 275\n",
            "Title: 247 - Conditional GANs and their applications\n",
            "Difficulty: advanced\n",
            "Duration: 39.9 minutes\n",
            "\n",
            "ID: 278\n",
            "Title: 249 - keras implementation of Conditional GAN (cifar10 data set)\n",
            "Difficulty: advanced\n",
            "Duration: 29.9 minutes\n",
            "\n",
            "ID: 279\n",
            "Title: 248 - keras implementation of GAN to generate cifar10 images\n",
            "Difficulty: advanced\n",
            "Duration: 31.1 minutes\n",
            "\n",
            "ID: 280\n",
            "Title: 250 - Image to image translation using Pix2Pix GAN\n",
            "Difficulty: advanced\n",
            "Duration: 32.9 minutes\n",
            "\n",
            "ID: 281\n",
            "Title: 251 - Satellite image to maps translation using  pix2pix GAN\n",
            "Difficulty: advanced\n",
            "Duration: 22.8 minutes\n",
            "\n",
            "ID: 282\n",
            "Title: 252 - Generating realistic looking scientific images using pix2pix GAN\n",
            "Difficulty: advanced\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 284\n",
            "Title: 254 - Unpaired image to image translation​ using cycleGAN in keras\n",
            "Difficulty: advanced\n",
            "Duration: 38.5 minutes\n",
            "\n",
            "ID: 285\n",
            "Title: 255 - Single image super resolution​ using SRGAN\n",
            "Difficulty: advanced\n",
            "Duration: 29.4 minutes\n",
            "\n",
            "ID: 286\n",
            "Title: 256 - Super resolution GAN (SRGAN) in keras\n",
            "Difficulty: advanced\n",
            "Duration: 22.8 minutes\n",
            "\n",
            "ID: 288\n",
            "Title: 257 - Exploring GAN latent space to generate images with desired features​\n",
            "Difficulty: advanced\n",
            "Duration: 39.0 minutes\n",
            "\n",
            "ID: 296\n",
            "Title: 258 - Semi-supervised learning with GANs\n",
            "Difficulty: advanced\n",
            "Duration: 34.3 minutes\n",
            "\n",
            "ID: 297\n",
            "Title: 259 - Semi-supervised learning with GANs - in keras\n",
            "Difficulty: advanced\n",
            "Duration: 29.2 minutes\n",
            "\n",
            "ID: 298\n",
            "Title: 260 - Identifying anomaly images using convolutional autoencoders\n",
            "Difficulty: advanced\n",
            "Duration: 33.5 minutes\n",
            "\n",
            "ID: 299\n",
            "Title: 262 - Localizing anomalies in images\n",
            "Difficulty: advanced\n",
            "Duration: 26.4 minutes\n",
            "\n",
            "ID: 301\n",
            "Title: 263 - Object localization in images​ using GAP layer\n",
            "Difficulty: advanced\n",
            "Duration: 16.1 minutes\n",
            "\n",
            "ID: 302\n",
            "Title: 264 - Image outlier detection using alibi-detect\n",
            "Difficulty: advanced\n",
            "Duration: 30.8 minutes\n",
            "\n",
            "ID: 305\n",
            "Title: 267 - Processing whole slide images (as tiles)\n",
            "Difficulty: advanced\n",
            "Duration: 28.7 minutes\n",
            "\n",
            "ID: 306\n",
            "Title: 266 - Openslide library for whole slide images\n",
            "Difficulty: advanced\n",
            "Duration: 33.6 minutes\n",
            "\n",
            "ID: 310\n",
            "Title: 270 - How to deploy your trained machine learning model as a web app on Heroku (No Docker)\n",
            "Difficulty: advanced\n",
            "Duration: 40.5 minutes\n",
            "\n",
            "ID: 311\n",
            "Title: 271 - How to deploy your trained machine learning model as a web app on Heroku (with docker)\n",
            "Difficulty: advanced\n",
            "Duration: 32.6 minutes\n",
            "\n",
            "ID: 314\n",
            "Title: Lung cancer subclassification using fastai​ (Tips Tricks 22)\n",
            "Difficulty: advanced\n",
            "Duration: 28.8 minutes\n",
            "\n",
            "ID: 323\n",
            "Title: Labeling images for semantic segmentation using Label Studio\n",
            "Difficulty: advanced\n",
            "Duration: 27.1 minutes\n",
            "\n",
            "ID: 328\n",
            "Title: 272 - Instance segmentation via semantic segmentation by using border class\n",
            "Difficulty: advanced\n",
            "Duration: 33.8 minutes\n",
            "\n",
            "ID: 329\n",
            "Title: 275 - Object segmentation and analysis using voronoi otsu labeling\n",
            "Difficulty: advanced\n",
            "Duration: 20.2 minutes\n",
            "\n",
            "ID: 333\n",
            "Title: 274 - Object segmentation using voronoi and otsu\n",
            "Difficulty: advanced\n",
            "Duration: 14.6 minutes\n",
            "\n",
            "ID: 335\n",
            "Title: 278 - IHC color separation followed by nuclei segmentation using python\n",
            "Difficulty: advanced\n",
            "Duration: 14.2 minutes\n",
            "\n",
            "ID: 337\n",
            "Title: 280 - Custom object segmentation using StarDist library in python\n",
            "Difficulty: advanced\n",
            "Duration: 24.5 minutes\n",
            "\n",
            "ID: 338\n",
            "Title: 281 - Segmenting whole slide images (WSI) for nuclei using StarDist in python\n",
            "Difficulty: advanced\n",
            "Duration: 13.7 minutes\n",
            "\n",
            "ID: 344\n",
            "Title: 284 - Installing Mask RCNN and troubleshooting errors\n",
            "Difficulty: advanced\n",
            "Duration: 21.7 minutes\n",
            "\n",
            "ID: 345\n",
            "Title: 285 - Object detection using Mask RCNN (with XML annotated data)\n",
            "Difficulty: advanced\n",
            "Duration: 27.0 minutes\n",
            "\n",
            "ID: 349\n",
            "Title: 52b - Understanding Gaussian Mixture Model (GMM) using 1D, 2D, and 3D examples\n",
            "Difficulty: advanced\n",
            "Duration: 14.4 minutes\n",
            "\n",
            "ID: 351\n",
            "Title: 287 - Tracking particles and objects using Trackpy in python\n",
            "Difficulty: advanced\n",
            "Duration: 31.0 minutes\n",
            "\n",
            "ID: 352\n",
            "Title: 288 - Nuclei segmentation using StarDist and tracking using Trackpy in python\n",
            "Difficulty: advanced\n",
            "Duration: 24.8 minutes\n",
            "\n",
            "ID: 354\n",
            "Title: Installing napari library in python for scientific image visualization - Tips and Tricks 39\n",
            "Difficulty: advanced\n",
            "Duration: 12.4 minutes\n",
            "\n",
            "ID: 358\n",
            "Title: 23b - Image segmentation using color spaces​ - in python\n",
            "Difficulty: advanced\n",
            "Duration: 11.5 minutes\n",
            "\n",
            "ID: 359\n",
            "Title: How to remove text from images using python?\n",
            "Difficulty: advanced\n",
            "Duration: 7.0 minutes\n",
            "\n",
            "ID: 360\n",
            "Title: Color segmentation of images ​followed by text removal​ in python\n",
            "Difficulty: advanced\n",
            "Duration: 10.0 minutes\n",
            "\n",
            "ID: 361\n",
            "Title: 290 - Deep Learning based edge detection using HED\n",
            "Difficulty: advanced\n",
            "Duration: 19.6 minutes\n",
            "\n",
            "ID: 362\n",
            "Title: 291 - Object segmentation using Deep Learning based edge detection (HED)​\n",
            "Difficulty: advanced\n",
            "Duration: 18.3 minutes\n",
            "\n",
            "ID: 363\n",
            "Title: 292 - Denoising images using deep learning (Noise2Void)​\n",
            "Difficulty: advanced\n",
            "Duration: 16.9 minutes\n",
            "\n",
            "ID: 364\n",
            "Title: 293  - Denoising RGB images using deep learning (Noise2Void)\n",
            "Difficulty: advanced\n",
            "Duration: 24.0 minutes\n",
            "\n",
            "ID: 365\n",
            "Title: 294 - Denoising 3D multi-channel scientific images using Noise2Void deep learning approach\n",
            "Difficulty: advanced\n",
            "Duration: 22.4 minutes\n",
            "\n",
            "ID: 366\n",
            "Title: 296 - Converting keras trained model to ONNX format - Image Classification example\n",
            "Difficulty: advanced\n",
            "Duration: 21.1 minutes\n",
            "\n",
            "ID: 367\n",
            "Title: 297 - Converting keras trained model to ONNX format​ - Semantic Segmentation\n",
            "Difficulty: advanced\n",
            "Duration: 18.9 minutes\n",
            "\n",
            "ID: 375\n",
            "Title: White balancing your pictures using python\n",
            "Difficulty: advanced\n",
            "Duration: 14.2 minutes\n",
            "\n",
            "ID: 376\n",
            "Title: 303 - Reinhard color transformation​\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 377\n",
            "Title: 304 - Augmentation of histology images​ to train stain-agnostic deep learning models\n",
            "Difficulty: advanced\n",
            "Duration: 20.7 minutes\n",
            "\n",
            "ID: 379\n",
            "Title: 306 - Content based image retrieval​ via feature extraction in python\n",
            "Difficulty: advanced\n",
            "Duration: 28.2 minutes\n",
            "\n",
            "ID: 381\n",
            "Title: Feature engineering vs Feature Learning (tips tricks 46 )\n",
            "Difficulty: advanced\n",
            "Duration: 18.7 minutes\n",
            "\n",
            "ID: 382\n",
            "Title: 307 - Segment your images in python without training using Segment Anything Model (SAM)\n",
            "Difficulty: advanced\n",
            "Duration: 16.9 minutes\n",
            "\n",
            "ID: 400\n",
            "Title: 322 - PSO Using steel optimization\n",
            "Difficulty: advanced\n",
            "Duration: 14.6 minutes\n",
            "\n",
            "ID: 401\n",
            "Title: 325: Transcriptomics Unveiled – An In-Depth Exploration of Single Cell RNASeq Analysis using python\n",
            "Difficulty: advanced\n",
            "Duration: 69.5 minutes\n",
            "\n",
            "ID: 402\n",
            "Title: 326 - Cell type annotation for single cell RNA seq data​\n",
            "Difficulty: advanced\n",
            "Duration: 43.4 minutes\n",
            "\n",
            "ID: 405\n",
            "Title: 328 - smFISH Analysis using Big FISH library in python​\n",
            "Difficulty: advanced\n",
            "Duration: 49.8 minutes\n",
            "\n",
            "ID: 407\n",
            "Title: 330 - Fine tuning Detectron2 for instance segmentation using custom data\n",
            "Difficulty: advanced\n",
            "Duration: 50.4 minutes\n",
            "\n",
            "ID: 408\n",
            "Title: 331 - Fine-tune Segment Anything Model (SAM) using custom data\n",
            "Difficulty: advanced\n",
            "Duration: 44.1 minutes\n",
            "\n",
            "ID: 409\n",
            "Title: 332 - All about image annotations​\n",
            "Difficulty: advanced\n",
            "Duration: 26.6 minutes\n",
            "\n",
            "ID: 410\n",
            "Title: 334 - Training custom instance segmentation model using YOLO v8\n",
            "Difficulty: advanced\n",
            "Duration: 35.5 minutes\n",
            "\n",
            "ID: 412\n",
            "Title: A Holistic View of Software Languages, Databases, and Frameworks\n",
            "Difficulty: advanced\n",
            "Duration: 45.9 minutes\n",
            "\n",
            "ID: 413\n",
            "Title: 335 - Converting COCO JSON annotations to labeled mask images\n",
            "Difficulty: advanced\n",
            "Duration: 28.6 minutes\n",
            "\n",
            "ID: 416\n",
            "Title: 336 - Nuclei segmentation and analysis using Detectron2 & YOLOv8​\n",
            "Difficulty: advanced\n",
            "Duration: 57.1 minutes\n",
            "\n",
            "ID: 417\n",
            "Title: 337 - Whole Slide Image segmentation for nuclei​ using Detectron2 and YOLOv8\n",
            "Difficulty: advanced\n",
            "Duration: 29.5 minutes\n",
            "\n",
            "ID: 418\n",
            "Title: Exploring Metadata in Scientific Images\n",
            "Difficulty: advanced\n",
            "Duration: 43.3 minutes\n",
            "\n",
            "ID: 421\n",
            "Title: 338 - Understanding the Benford's Law of Probability\n",
            "Difficulty: advanced\n",
            "Duration: 20.9 minutes\n",
            "\n",
            "ID: 423\n",
            "Title: 340 - Comparing Top Large Language Models for Python Code Generation\n",
            "Difficulty: advanced\n",
            "Duration: 38.7 minutes\n",
            "\n",
            "ID: 424\n",
            "Title: 341 - Sholl Analysis using python coding\n",
            "Difficulty: advanced\n",
            "Duration: 21.8 minutes\n",
            "\n",
            "ID: 425\n",
            "Title: 342 Sholl Analysis: Aggregating Sholl Profiles from Multiple Soma\n",
            "Difficulty: advanced\n",
            "Duration: 13.8 minutes\n",
            "\n",
            "ID: 426\n",
            "Title: 343 De-arraying Tissue Microarrays (TMA) using Qupath and python code\n",
            "Difficulty: advanced\n",
            "Duration: 12.2 minutes\n",
            "\n",
            "ID: 427\n",
            "Title: 344 Color separation and nuclei segmentation in cores extracted from TMA\n",
            "Difficulty: advanced\n",
            "Duration: 12.5 minutes\n",
            "\n",
            "ID: 428\n",
            "Title: Annotate Images Like a Pro: Python Image Annotation Tool Walkthrough\n",
            "Difficulty: advanced\n",
            "Duration: 32.1 minutes\n",
            "\n",
            "ID: 429\n",
            "Title: Annotate Images Like a Pro: Python Image Annotation Tool Demo\n",
            "Difficulty: advanced\n",
            "Duration: 54.6 minutes\n",
            "\n",
            "ID: 430\n",
            "Title: How to install DigitalSreeni Image Annotator\n",
            "Difficulty: advanced\n",
            "Duration: 3.3 minutes\n",
            "\n",
            "ID: 433\n",
            "Title: 351 - Image Retrieval Made Easy With GUI. Uses ViT and FAISS\n",
            "Difficulty: advanced\n",
            "Duration: 11.3 minutes\n",
            "\n",
            "ID: 435\n",
            "Title: 348 - Image Similarity Search with VGG16 and Cosine Distance\n",
            "Difficulty: advanced\n",
            "Duration: 22.1 minutes\n",
            "\n",
            "ID: 437\n",
            "Title: 350 - Efficient Image Retrieval with Vision Transformer (ViT) and FAISS\n",
            "Difficulty: advanced\n",
            "Duration: 18.9 minutes\n",
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "Topic subgraph saved to /content/drive/MyDrive/recommender_systems/knowledge_graphs/visualizations/python_basics_subgraph.html\n",
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "Topic subgraph saved to /content/drive/MyDrive/recommender_systems/knowledge_graphs/visualizations/image_processing_subgraph.html\n",
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "Topic subgraph saved to /content/drive/MyDrive/recommender_systems/knowledge_graphs/visualizations/bio_applications_subgraph.html\n",
            "Prerequisites for Video 42:\n",
            "==================================================\n",
            "No prerequisites found for Video 42\n",
            "Prerequisites for Video 43:\n",
            "==================================================\n",
            "No prerequisites found for Video 43\n",
            "Prerequisites for Video 44:\n",
            "==================================================\n",
            "No prerequisites found for Video 44\n",
            "\n",
            "All operations completed successfully!\n"
          ]
        }
      ]
    }
  ]
}